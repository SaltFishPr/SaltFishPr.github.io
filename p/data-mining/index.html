<!doctype html><html lang=en-us>
<head><meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="《Python 数据挖掘入门与实践》读书笔记"><title>Data Mining</title>
<link rel=canonical href=https://saltfishpr.github.io/p/data-mining/>
<link rel=stylesheet href=/scss/style.min.css><meta property="og:title" content="Data Mining">
<meta property="og:description" content="《Python 数据挖掘入门与实践》读书笔记">
<meta property="og:url" content="https://saltfishpr.github.io/p/data-mining/">
<meta property="og:site_name" content="咸鱼硕的博客">
<meta property="og:type" content="article"><meta property="article:section" content="Post"><meta property="article:tag" content="data science"><meta property="article:published_time" content="2020-03-09T00:00:00+08:00"><meta property="article:modified_time" content="2020-03-23T00:00:00+08:00"><meta property="og:image" content="https://saltfishpr.github.io/p/data-mining/cover.jpg">
<meta name=twitter:site content="@saltfishpr">
<meta name=twitter:creator content="@saltfishpr"><meta name=twitter:title content="Data Mining">
<meta name=twitter:description content="《Python 数据挖掘入门与实践》读书笔记"><meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://saltfishpr.github.io/p/data-mining/cover.jpg">
<link rel="shortcut icon" href=favicon.ico>
</head>
<body class="article-page has-toc">
<script>(function(){const a='StackColorScheme';localStorage.getItem(a)||localStorage.setItem(a,"auto")})()</script><script>(function(){const b='StackColorScheme',a=localStorage.getItem(b),c=window.matchMedia('(prefers-color-scheme: dark)').matches===!0;a=='dark'||a==='auto'&&c?document.documentElement.dataset.scheme='dark':document.documentElement.dataset.scheme='light'})()</script>
<div class="container main-container flex
extended">
<div id=article-toolbar>
<a href=/ class=back-home><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-chevron-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="15 6 9 12 15 18"/></svg>
<span>Back</span>
</a>
</div>
<main class="main full-width">
<article class="has-image main-article">
<header class=article-header>
<div class=article-image>
<a href=/p/data-mining/>
<img src=/p/data-mining/cover_hu070ea85b747ec3ac952c2c1e3418996b_251504_800x0_resize_q75_box.jpg srcset="/p/data-mining/cover_hu070ea85b747ec3ac952c2c1e3418996b_251504_800x0_resize_q75_box.jpg 800w, /p/data-mining/cover_hu070ea85b747ec3ac952c2c1e3418996b_251504_1600x0_resize_q75_box.jpg 1600w" width=800 height=649 loading=lazy alt="Featured image of post Data Mining">
</a>
</div>
<div class=article-details>
<header class=article-category>
<a href=/categories/python/>
python
</a>
</header>
<h2 class=article-title>
<a href=/p/data-mining/>Data Mining</a>
</h2>
<h3 class=article-subtitle>
《Python 数据挖掘入门与实践》读书笔记
</h3>
<footer class=article-time>
<div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Mar 09, 2020</time>
</div>
<div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>
54 minute read
</time>
</div>
</footer>
</div>
</header>
<section class=article-content>
<h1 id=数据挖掘学习笔记>数据挖掘学习笔记</h1>
<p>书上的源码在<a class=link href=http://www.packtpub.com/support target=_blank rel=noopener>官网</a>上可以注册账号下载，这里只为记录自己的学习过程。</p>
<p>如果有侵权情况，请给我发邮件通知我删除 <a class=link href=mailto:526191197@qq.com>526191197@qq.com</a></p>
<p>此笔记的代码均在 <code>pycharm - python3.8</code> 中运行通过</p>
<p>学习数据挖掘，让数据服务于人类</p>
<h2 id=第一章>第一章</h2>
<h3 id=亲和性分析>亲和性分析</h3>
<p>亲和性分析根据样本个体（物体）之间的相似度，确定他们的关系亲疏。应用场景有以下几个方面：</p>
<ul>
<li>向用户投放定向广告</li>
<li>为用户提供推荐（如歌曲推荐，电影推荐等）</li>
</ul>
<p>名词：</p>
<ul>
<li>规则：一条规则由前提条件和结论两部分组成</li>
<li>支持度：数据集中规则应验的次数</li>
<li>置信度：规则（结果）出现的次数 / 条件出现的次数（条件相同的规则数量），衡量规则的准确率</li>
</ul>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># -*- coding: utf-8 -*-</span>
<span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
<span style=color:#f92672>from</span> collections <span style=color:#f92672>import</span> defaultdict
<span style=color:#f92672>from</span> operator <span style=color:#f92672>import</span> itemgetter

<span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;__main__&#39;</span>:
    dataset_filename <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;affinity_dataset.txt&#34;</span>
    X <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>loadtxt(dataset_filename)
    n_samples, n_features <span style=color:#f92672>=</span> X<span style=color:#f92672>.</span>shape  <span style=color:#75715e># 样本数，特征数</span>
    features <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#34;bread&#34;</span>, <span style=color:#e6db74>&#34;milk&#34;</span>, <span style=color:#e6db74>&#34;cheese&#34;</span>, <span style=color:#e6db74>&#34;apples&#34;</span>, <span style=color:#e6db74>&#34;bananas&#34;</span>]  <span style=color:#75715e># 商品名列表</span>

    <span style=color:#75715e># 如果xxx，那么xxx 就是一条规则。规则由前提条件和结论两部分组成</span>
    <span style=color:#75715e># 这里注意&#39;如果买A则他们会买B&#39;和&#39;如果买B则他们会买A&#39;不是一个规则，在下面的循环中体现出来</span>
    valid_rules <span style=color:#f92672>=</span> defaultdict(int)  <span style=color:#75715e># 规则应验</span>
    invalid_rules <span style=color:#f92672>=</span> defaultdict(int)  <span style=color:#75715e># 规则无效</span>
    num_occurences <span style=color:#f92672>=</span> defaultdict(int)  <span style=color:#75715e># 商品购买数量字典</span>

    <span style=color:#66d9ef>for</span> sample <span style=color:#f92672>in</span> X:  <span style=color:#75715e># 对数据集里的每个消费者</span>
        <span style=color:#66d9ef>for</span> premise <span style=color:#f92672>in</span> range(n_features):
            <span style=color:#66d9ef>if</span> sample[premise] <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>:  <span style=color:#75715e># 如果这个商品没有买，继续看下一个商品</span>
                <span style=color:#66d9ef>continue</span>
            num_occurences[premise] <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>  <span style=color:#75715e># 记录这个商品购买数量</span>
            <span style=color:#66d9ef>for</span> conclusion <span style=color:#f92672>in</span> range(n_features):
                <span style=color:#66d9ef>if</span> premise <span style=color:#f92672>==</span> conclusion:  <span style=color:#75715e># 跳过此商品</span>
                    <span style=color:#66d9ef>continue</span>
                <span style=color:#66d9ef>if</span> sample[conclusion] <span style=color:#f92672>==</span> <span style=color:#ae81ff>1</span>:
                    valid_rules[(premise, conclusion)] <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>  <span style=color:#75715e># 规则应验</span>
                <span style=color:#66d9ef>else</span>:
                    invalid_rules[(premise, conclusion)] <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>  <span style=color:#75715e># 规则无效</span>
    support <span style=color:#f92672>=</span> valid_rules  <span style=color:#75715e># 支持度字典，即规则应验次数</span>
    confidence <span style=color:#f92672>=</span> defaultdict(float)  <span style=color:#75715e># 置信度字典</span>
    <span style=color:#66d9ef>for</span> premise, conclusion <span style=color:#f92672>in</span> valid_rules<span style=color:#f92672>.</span>keys():  <span style=color:#75715e># 条件/结论</span>
        rule <span style=color:#f92672>=</span> (premise, conclusion)
        <span style=color:#75715e># 置信度 = 规则发生的次数/条件发生的次数</span>
        confidence[rule] <span style=color:#f92672>=</span> valid_rules[rule] <span style=color:#f92672>/</span> num_occurences[premise]

    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>print_rule</span>(premise, conclusion, support, confidence, features):
        premise_name <span style=color:#f92672>=</span> features[premise]
        conclusion_name <span style=color:#f92672>=</span> features[conclusion]
        print(
            <span style=color:#e6db74>&#34;Rule: If a person buys </span><span style=color:#e6db74>{0}</span><span style=color:#e6db74> they will also buy </span><span style=color:#e6db74>{1}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(
                premise_name,
                conclusion_name))
        print(
            <span style=color:#e6db74>&#34; - Confidence: </span><span style=color:#e6db74>{0:.3f}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(confidence[(premise, conclusion)]))
        print(<span style=color:#e6db74>&#34; - Support: </span><span style=color:#e6db74>{0}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(support[(premise, conclusion)]))
        print(<span style=color:#e6db74>&#34;&#34;</span>)

    <span style=color:#75715e># 得到支持度最高的规则，items()返回字典所有元素的列表，itemgetter(1)表示用支持度的值作为键，进行降序排列</span>
    sorted_support <span style=color:#f92672>=</span> sorted(support<span style=color:#f92672>.</span>items(), key<span style=color:#f92672>=</span>itemgetter(<span style=color:#ae81ff>1</span>), reverse<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
    <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>5</span>):
        print(<span style=color:#e6db74>&#34;Rule #</span><span style=color:#e6db74>{0}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(i <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>))
        premise, conclusion <span style=color:#f92672>=</span> sorted_support[i][<span style=color:#ae81ff>0</span>]
        print_rule(premise, conclusion, support, confidence, features)

    sorted_confidence <span style=color:#f92672>=</span> sorted(confidence<span style=color:#f92672>.</span>items(), key<span style=color:#f92672>=</span>itemgetter(<span style=color:#ae81ff>1</span>), reverse<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
    <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>5</span>):
        print(<span style=color:#e6db74>&#34;Rule #</span><span style=color:#e6db74>{0}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(i <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>))
        premise, conclusion <span style=color:#f92672>=</span> sorted_confidence[i][<span style=color:#ae81ff>0</span>]
        print_rule(premise, conclusion, support, confidence, features)
</code></pre></div><p>Output：</p>
<pre><code>Rule #1
Rule: If a person buys cheese they will also buy bananas
- Confidence: 0.659
- Support: 27
Rule #2
Rule: If a person buys bananas they will also buy cheese
- Confidence: 0.458
- Support: 27
Rule #3
Rule: If a person buys cheese they will also buy apples
- Confidence: 0.610
- Support: 25

Rule #1
Rule: If a person buys apples they will also buy cheese
- Confidence: 0.694
- Support: 25
Rule #2
Rule: If a person buys cheese they will also buy bananas
- Confidence: 0.659
- Support: 27
Rule #3
Rule: If a person buys bread they will also buy bananas
- Confidence: 0.630
- Support: 17
</code></pre>
<h3 id=one-rule-算法>One Rule 算法</h3>
<p><code>OneR</code>(One Rule)算法根据已有的数据中，具有相同特征值的个体最可能属于哪个类别进行分类。One Rule 就是从四个特征中选择分类效果最好的哪个作为分类依据。</p>
<blockquote>
<p>假如数据集的某一个特征可以取 0 或 1 两个值。数据集共有三个类别。特征值为 0 的情况下，A 类有 20 个这样的个体，B 类有 60 个，C 类也有 20 个。那么特征值为 0 的个体最可能属于 B 类,当然还有 40 个个体确实是特征值为 0，但是它们不属于 B 类。将特征值为 0 的个体分到 B 类的错误率就是 40%，因为有 40 个这样的个体分别属于 A 类和 C 类。特征值为 1 时，计算方法类似，不再赘述；其他各特征值最可能属于的类别及错误率的计算方法也一样。</p>
</blockquote>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># -*- coding: utf-8 -*-</span>
<span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
<span style=color:#f92672>from</span> sklearn.datasets <span style=color:#f92672>import</span> load_iris  <span style=color:#75715e># Iris植物分类数据集</span>
<span style=color:#f92672>from</span> collections <span style=color:#f92672>import</span> defaultdict  <span style=color:#75715e># 初始化数据字典</span>
<span style=color:#f92672>from</span> operator <span style=color:#f92672>import</span> itemgetter  <span style=color:#75715e># 得到一个列表的制定元素</span>
<span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> train_test_split  <span style=color:#75715e># 将一个数据集且分为训练集和测试集</span>
<span style=color:#f92672>from</span> sklearn.metrics <span style=color:#f92672>import</span> classification_report  <span style=color:#75715e># 分析预测结果</span>

<span style=color:#75715e># 这里保留函数的文档方便查阅</span>
<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>train</span>(X, y_true, feature):
    <span style=color:#e6db74>&#34;&#34;&#34;
</span><span style=color:#e6db74>    Computes the predictors and error for a given feature using the OneR algorithm
</span><span style=color:#e6db74>    Parameters
</span><span style=color:#e6db74>    ----------
</span><span style=color:#e6db74>    X: array [n_samples, n_features]
</span><span style=color:#e6db74>        The two dimensional array that holds the dataset. Each row is a sample, each column
</span><span style=color:#e6db74>        is a feature.
</span><span style=color:#e6db74>
</span><span style=color:#e6db74>    y_true: array [n_samples,]
</span><span style=color:#e6db74>        The one dimensional array that holds the class values. Corresponds to X, such that
</span><span style=color:#e6db74>        y_true[i] is the class value for sample X[i].
</span><span style=color:#e6db74>
</span><span style=color:#e6db74>    feature: int
</span><span style=color:#e6db74>        An integer corresponding to the index of the variable we wish to test.
</span><span style=color:#e6db74>        0 &lt;= variable &lt; n_features
</span><span style=color:#e6db74>
</span><span style=color:#e6db74>    Returns
</span><span style=color:#e6db74>    -------
</span><span style=color:#e6db74>    predictors: dictionary of tuples: (value, prediction)
</span><span style=color:#e6db74>        For each item in the array, if the variable has a given value, make the given prediction.
</span><span style=color:#e6db74>
</span><span style=color:#e6db74>    error: float
</span><span style=color:#e6db74>        The ratio of training data that this rule incorrectly predicts.
</span><span style=color:#e6db74>    &#34;&#34;&#34;</span>
    <span style=color:#75715e># 检查是否为有效数字</span>
    n_samples, n_features <span style=color:#f92672>=</span> X<span style=color:#f92672>.</span>shape
    <span style=color:#66d9ef>assert</span> <span style=color:#ae81ff>0</span> <span style=color:#f92672>&lt;=</span> feature <span style=color:#f92672>&lt;</span> n_features
    <span style=color:#75715e># X[:, feature]为numpy矩阵的索引用法，第一维：所有数组，第二维：feature，set去重得到value有几个取值</span>
    <span style=color:#75715e># 这个feature特征值在每个数据中有多少个取值</span>
    values <span style=color:#f92672>=</span> set(X[:, feature])
    <span style=color:#75715e># Stores the predictors array that is returned</span>
    predictors <span style=color:#f92672>=</span> dict()
    errors <span style=color:#f92672>=</span> []
    <span style=color:#75715e># 对每个特征值的每个取值调用train_feature_value函数获得该取值出现最多的类和错误率</span>
    <span style=color:#66d9ef>for</span> current_value <span style=color:#f92672>in</span> values:
        most_frequent_class, error <span style=color:#f92672>=</span> train_feature_value(
            X, y_true, feature, current_value)
        predictors[current_value] <span style=color:#f92672>=</span> most_frequent_class  <span style=color:#75715e># 该取值出现最多的类</span>
        errors<span style=color:#f92672>.</span>append(error)  <span style=color:#75715e># 存储错误率</span>
    total_error <span style=color:#f92672>=</span> sum(errors)
    <span style=color:#75715e># 返回预测方案（即feature的取值分别对应哪个类别）和总错误率</span>
    <span style=color:#66d9ef>return</span> predictors, total_error


<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>train_feature_value</span>(X, y_true, feature, value):
    class_counts <span style=color:#f92672>=</span> defaultdict(int)
    <span style=color:#75715e># Iterate through each sample and count the frequency of each class/value pair</span>
    <span style=color:#75715e># 第feature个特征的值为value的时候，在每个种类中出现的次数，这里的植物有三个种类</span>
    <span style=color:#75715e># 因此最终class_counts有三个键值对</span>
    <span style=color:#66d9ef>for</span> sample, y <span style=color:#f92672>in</span> zip(X, y_true):
        <span style=color:#66d9ef>if</span> sample[feature] <span style=color:#f92672>==</span> value:
            class_counts[y] <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
    <span style=color:#75715e># 对class_count以value由大到小排列</span>
    sorted_class_counts <span style=color:#f92672>=</span> sorted(
        class_counts<span style=color:#f92672>.</span>items(),
        key<span style=color:#f92672>=</span>itemgetter(<span style=color:#ae81ff>1</span>),
        reverse<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
    most_frequent_class <span style=color:#f92672>=</span> sorted_class_counts[<span style=color:#ae81ff>0</span>][<span style=color:#ae81ff>0</span>]  <span style=color:#75715e># 出现最多次的类</span>
    n_samples <span style=color:#f92672>=</span> X<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>1</span>]
    error <span style=color:#f92672>=</span> sum([class_count <span style=color:#66d9ef>for</span> class_value, class_count <span style=color:#f92672>in</span> class_counts<span style=color:#f92672>.</span>items(
    ) <span style=color:#66d9ef>if</span> class_value <span style=color:#f92672>!=</span> most_frequent_class])  <span style=color:#75715e># error就是除去上面那个类的其它value的和</span>
    <span style=color:#66d9ef>return</span> most_frequent_class, error  <span style=color:#75715e># 返回出现次数最多的类和错误率</span>


<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>predict</span>(X_test, model):
    variable <span style=color:#f92672>=</span> model[<span style=color:#e6db74>&#39;variable&#39;</span>]  <span style=color:#75715e># 使用哪个feature作为OneRule进行预测</span>
    predictor <span style=color:#f92672>=</span> model[<span style=color:#e6db74>&#39;predictor&#39;</span>]  <span style=color:#75715e># 一个字典，保存着feature取值对应哪一类</span>
    y_predicted <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([predictor[int(sample[variable])]
                            <span style=color:#66d9ef>for</span> sample <span style=color:#f92672>in</span> X_test])
    <span style=color:#66d9ef>return</span> y_predicted  <span style=color:#75715e># 返回预测结果</span>


<span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;__main__&#39;</span>:
    dataset <span style=color:#f92672>=</span> load_iris()
    X <span style=color:#f92672>=</span> dataset<span style=color:#f92672>.</span>data
    y <span style=color:#f92672>=</span> dataset<span style=color:#f92672>.</span>target
    n_samples, n_features <span style=color:#f92672>=</span> X<span style=color:#f92672>.</span>shape

    <span style=color:#75715e># 计算每个属性的均值</span>
    attribute_means <span style=color:#f92672>=</span> X<span style=color:#f92672>.</span>mean(axis<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
    <span style=color:#66d9ef>assert</span> attribute_means<span style=color:#f92672>.</span>shape <span style=color:#f92672>==</span> (n_features,)
    <span style=color:#75715e># 对数据集离散化</span>
    X_d <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array(X <span style=color:#f92672>&gt;=</span> attribute_means, dtype<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;int&#39;</span>)

    random_state <span style=color:#f92672>=</span> <span style=color:#ae81ff>14</span>
    X_train, X_test, y_train, y_test <span style=color:#f92672>=</span> train_test_split(
        X_d, y, random_state<span style=color:#f92672>=</span>random_state)  <span style=color:#75715e># 分割训练集和测试集</span>
    print(<span style=color:#e6db74>&#34;There are </span><span style=color:#e6db74>{}</span><span style=color:#e6db74> training samples&#34;</span><span style=color:#f92672>.</span>format(y_train<span style=color:#f92672>.</span>shape))  <span style=color:#75715e># 训练集数量</span>
    print(<span style=color:#e6db74>&#34;There are </span><span style=color:#e6db74>{}</span><span style=color:#e6db74> testing samples&#34;</span><span style=color:#f92672>.</span>format(y_test<span style=color:#f92672>.</span>shape))  <span style=color:#75715e># 测试集数量</span>

    <span style=color:#75715e># 对每个特征返回预测器和错误率[0：{0: x, 1: x}, sum_error， ...]</span>
    all_predictors <span style=color:#f92672>=</span> {
        variable: train(
            X_train,
            y_train,
            variable) <span style=color:#66d9ef>for</span> variable <span style=color:#f92672>in</span> range(
            X_train<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>1</span>])}

    errors <span style=color:#f92672>=</span> {variable: error <span style=color:#66d9ef>for</span> variable,
              (mapping, error) <span style=color:#f92672>in</span> all_predictors<span style=color:#f92672>.</span>items()}  <span style=color:#75715e># 把每个预测器的值提取出来</span>
    <span style=color:#75715e># 找出最好（错误最少）的那个feature构成的预测器</span>
    best_variable, best_error <span style=color:#f92672>=</span> sorted(errors<span style=color:#f92672>.</span>items(), key<span style=color:#f92672>=</span>itemgetter(<span style=color:#ae81ff>1</span>))[<span style=color:#ae81ff>0</span>]
    print(
        <span style=color:#e6db74>&#34;The best model is based on variable </span><span style=color:#e6db74>{0}</span><span style=color:#e6db74> and has error </span><span style=color:#e6db74>{1:.2f}</span><span style=color:#e6db74>%&#34;</span><span style=color:#f92672>.</span>format(
            best_variable,
            best_error))

    <span style=color:#75715e># Choose the bset model</span>
    model <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#39;variable&#39;</span>: best_variable,
             <span style=color:#e6db74>&#39;predictor&#39;</span>: all_predictors[best_variable][<span style=color:#ae81ff>0</span>]}
    y_predicted <span style=color:#f92672>=</span> predict(X_test, model)
    print(classification_report(y_test, y_predicted))  <span style=color:#75715e># 生成测试结果</span>
    print(np<span style=color:#f92672>.</span>mean(y_predicted <span style=color:#f92672>==</span> y_test) <span style=color:#f92672>*</span> <span style=color:#ae81ff>100</span>)  <span style=color:#75715e># 预测正确率</span>

</code></pre></div><p>Output：</p>
<pre><code>|              | precision | recall | f1-score | support |
|      0       |   0.94    |  1.00  |   0.97   |   17    |
|      1       |   0.00    |  0.00  |   0.00   |   13    |
|      2       |   0.40    |  1.00  |   0.57   |    8    |
|              |           |        |          |         |
|   accuracy   |           |        |   0.66   |   38    |
|  macro avg   |   0.45    |  0.67  |   0.51   |   38    |
| weighted avg |   0.51    |  0.66  |   0.55   |   38    |

正确率： 65.78947368421053%
</code></pre>
<h2 id=第二章>第二章</h2>
<p>主要学习数据挖掘通用框架的搭建方法</p>
<ul>
<li>估计器(Estimator)：用于分类、聚类和回归分析</li>
<li>转换器(Transformer)：用于数据预处理和数据转换</li>
<li>流水线(Pipline)：组合数据挖掘流程，便于再次使用</li>
</ul>
<h3 id=scikit-learn-估计器>scikit-learn 估计器</h3>
<p>估计器用于分类，主要包含下面两个函数：</p>
<ul>
<li><code>fit()</code>: 训练算法，设置内部参数。该函数接受训练集和类别两个参数</li>
<li><code>predict()</code>: 参数为测试集。预测测试集类别，返回一个包含测试集各条数据类别的数组</li>
</ul>
<p><strong>近邻算法</strong></p>
<ul>
<li>用途广泛</li>
<li>计算量很大</li>
</ul>
<p><strong>距离度量</strong></p>
<ul>
<li>欧氏距离：即真实距离</li>
<li>曼哈顿距离：两个特征在标准坐标系中绝对轴距之和(x1,y1),(x2,y2)即 abs(x1-x2)+abs(y1-y2)</li>
<li>余弦距离：指的是特征向量夹角的余弦值，更适合解决异常值和数据稀疏问题。</li>
</ul>
<p>电离层(Ionosphere)数据集分析</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># -*- coding: utf-8 -*-</span>
<span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
<span style=color:#f92672>import</span> csv
<span style=color:#f92672>from</span> matplotlib <span style=color:#f92672>import</span> pyplot <span style=color:#66d9ef>as</span> plt
<span style=color:#f92672>from</span> sklearn.neighbors <span style=color:#f92672>import</span> KNeighborsClassifier  <span style=color:#75715e># 导入K近邻分类器</span>
<span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> train_test_split
<span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> cross_val_score  <span style=color:#75715e># 导入交叉检验的</span>
<span style=color:#75715e># 把每个特征值的值域规范化到0，1之间，最小值用0代替，最大值用1代替</span>
<span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> MinMaxScaler
<span style=color:#f92672>from</span> sklearn.pipeline <span style=color:#f92672>import</span> Pipeline  <span style=color:#75715e># 流水线</span>


<span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;__main__&#39;</span>:
    <span style=color:#75715e># 数据集大小已知有351行，每行35个值前34个为天线采集的数据，最后一个 g/b 表示数据的好坏</span>
    X <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>zeros((<span style=color:#ae81ff>351</span>, <span style=color:#ae81ff>34</span>), dtype<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;float&#39;</span>)
    y <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>zeros((<span style=color:#ae81ff>351</span>,), dtype<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;bool&#39;</span>)

    <span style=color:#75715e># 打开根目录的数据集文件</span>
    <span style=color:#66d9ef>with</span> open(<span style=color:#e6db74>&#34;ionosphere.data&#34;</span>, <span style=color:#e6db74>&#39;r&#39;</span>, encoding<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;utf-8&#39;</span>) <span style=color:#66d9ef>as</span> input_file:
        <span style=color:#75715e># 创建csv阅读器对象</span>
        reader <span style=color:#f92672>=</span> csv<span style=color:#f92672>.</span>reader(input_file)
        <span style=color:#75715e># 使用枚举函数为每行数据创建索引</span>
        <span style=color:#66d9ef>for</span> i, row <span style=color:#f92672>in</span> enumerate(reader):
            <span style=color:#75715e># 获取行数据的前34个值，并将其转化为浮点型，保存在X中</span>
            data <span style=color:#f92672>=</span> [float(datum) <span style=color:#66d9ef>for</span> datum <span style=color:#f92672>in</span> row[:<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>]]
            <span style=color:#75715e># Set the appropriate row in our dataset</span>
            X[i] <span style=color:#f92672>=</span> data  <span style=color:#75715e># 数据集</span>
            <span style=color:#75715e># 1 if the class is &#39;g&#39;, 0 otherwise</span>
            y[i] <span style=color:#f92672>=</span> row[<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>] <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;g&#39;</span>  <span style=color:#75715e># 类别</span>

    <span style=color:#75715e># 创建训练集和测试集</span>
    X_train, X_test, y_train, y_test <span style=color:#f92672>=</span> train_test_split(X, y, random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>14</span>)
    print(
        <span style=color:#e6db74>&#34;There are </span><span style=color:#e6db74>{}</span><span style=color:#e6db74> samples in the training dataset&#34;</span><span style=color:#f92672>.</span>format(
            X_train<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>]))
    print(
        <span style=color:#e6db74>&#34;There are </span><span style=color:#e6db74>{}</span><span style=color:#e6db74> samples in the testing dataset&#34;</span><span style=color:#f92672>.</span>format(
            X_test<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>]))
    print(<span style=color:#e6db74>&#34;Each sample has </span><span style=color:#e6db74>{}</span><span style=color:#e6db74> features&#34;</span><span style=color:#f92672>.</span>format(X_train<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>1</span>]))
</code></pre></div><p>Output:</p>
<pre><code>There are 263 samples in the training dataset
There are 88 samples in the testing dataset
Each sample has 34 features
</code></pre>
<hr>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># 初始化一个K近邻分类器实例，该算法默认选择5个近邻作为分类依据</span>
    estimator <span style=color:#f92672>=</span> KNeighborsClassifier()
    <span style=color:#75715e># 用训练数据进行训练</span>
    estimator<span style=color:#f92672>.</span>fit(X_train, y_train)
    <span style=color:#75715e># 使用测试集测试算法，评价其表现</span>
    y_predicted <span style=color:#f92672>=</span> estimator<span style=color:#f92672>.</span>predict(X_test)
    <span style=color:#75715e># 准确性</span>
    accuracy <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>mean(y_test <span style=color:#f92672>==</span> y_predicted) <span style=color:#f92672>*</span> <span style=color:#ae81ff>100</span>
    print(<span style=color:#e6db74>&#34;The accuracy is </span><span style=color:#e6db74>{0:.1f}</span><span style=color:#e6db74>%&#34;</span><span style=color:#f92672>.</span>format(accuracy))

    <span style=color:#75715e># 使用交叉检验的方式获得平均准确性</span>
    scores <span style=color:#f92672>=</span> cross_val_score(estimator, X, y, scoring<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;accuracy&#39;</span>)
    average_accuracy <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>mean(scores) <span style=color:#f92672>*</span> <span style=color:#ae81ff>100</span>
    print(<span style=color:#e6db74>&#34;The average accuracy is </span><span style=color:#e6db74>{0:.1f}</span><span style=color:#e6db74>%&#34;</span><span style=color:#f92672>.</span>format(average_accuracy))
</code></pre></div><p>Output:</p>
<pre><code>The accuracy is 86.4%
The average accuracy is 82.6%
</code></pre>
<hr>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># 设置参数</span>
    <span style=color:#75715e># 参数的选取跟数据集的特征息息相关</span>
    avg_scores <span style=color:#f92672>=</span> []
    all_scores <span style=color:#f92672>=</span> []
    parameter_values <span style=color:#f92672>=</span> list(range(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>21</span>))
    <span style=color:#66d9ef>for</span> n_neighbors <span style=color:#f92672>in</span> parameter_values:
        estimator <span style=color:#f92672>=</span> KNeighborsClassifier(n_neighbors<span style=color:#f92672>=</span>n_neighbors)
        scores <span style=color:#f92672>=</span> cross_val_score(estimator, X, y, scoring<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;accuracy&#39;</span>)
        avg_scores<span style=color:#f92672>.</span>append(np<span style=color:#f92672>.</span>mean(scores))
        all_scores<span style=color:#f92672>.</span>append(scores)

    <span style=color:#75715e># 作出n_neighbors不同取值和分类正确率之间的关系的折线图</span>
    plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>32</span>, <span style=color:#ae81ff>20</span>))
    plt<span style=color:#f92672>.</span>plot(parameter_values, avg_scores, <span style=color:#e6db74>&#39;-o&#39;</span>, linewidth<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>, markersize<span style=color:#f92672>=</span><span style=color:#ae81ff>24</span>)
    plt<span style=color:#f92672>.</span>show()
</code></pre></div><p>Output:</p>
<p><figure>
<a href=/img/in-post/data-mining/ch2/result2.1.png>
<img src=/img/in-post/data-mining/ch2/result2.1.png loading=lazy alt=result2.1>
</a>
<figcaption>result2.1</figcaption>
</figure></p>
<p>经过上面的例子，可以总结数据挖掘最简单基本的流程如下：</p>
<ul>
<li>载入数据集，数据分类提取到内存中</li>
<li>创建训练集和测试集</li>
<li>选择合适的算法进行训练</li>
<li>使用测试集测试算法，评估其表现</li>
</ul>
<p>为了保证算法的准确性，可以将大数据集分为几个部分，通过交叉检验的方法测试算法。使用 cross_val_score 函数是一个不错的选择。</p>
<p>在参数的设置上，可以针对不同的参数进行交叉测试，使用图表直观地表示出参数的影响。</p>
<h3 id=流水线在预处理中的作用>流水线在预处理中的作用</h3>
<p>sckit-learn 的预处理工具叫做转换器<code>Transformer</code></p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># 模拟脏数据</span>
    X_broken <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array(X)
    X_broken[:, ::<span style=color:#ae81ff>2</span>] <span style=color:#f92672>/=</span> <span style=color:#ae81ff>10</span>
    <span style=color:#75715e># 对比两种情况下预测准确率</span>
    estimator <span style=color:#f92672>=</span> KNeighborsClassifier()
    original_scores <span style=color:#f92672>=</span> cross_val_score(estimator, X, y, scoring<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;accuracy&#39;</span>)
    print(
        <span style=color:#e6db74>&#34;The original average accuracy for is </span><span style=color:#e6db74>{0:.1f}</span><span style=color:#e6db74>%&#34;</span><span style=color:#f92672>.</span>format(
            np<span style=color:#f92672>.</span>mean(original_scores) <span style=color:#f92672>*</span> <span style=color:#ae81ff>100</span>))
    broken_scores <span style=color:#f92672>=</span> cross_val_score(estimator, X_broken, y, scoring<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;accuracy&#39;</span>)
    print(
        <span style=color:#e6db74>&#34;The broken average accuracy for is </span><span style=color:#e6db74>{0:.1f}</span><span style=color:#e6db74>%&#34;</span><span style=color:#f92672>.</span>format(
            np<span style=color:#f92672>.</span>mean(broken_scores) <span style=color:#f92672>*</span> <span style=color:#ae81ff>100</span>))
</code></pre></div><p>Output:</p>
<pre><code>The original average accuracy for is 82.6%
The broken average accuracy for is 73.8%
</code></pre>
<hr>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># 组合成为一个工作流</span>
    X_transformed <span style=color:#f92672>=</span> MinMaxScaler<span style=color:#f92672>.</span>fit_transform(X_broken)    <span style=color:#75715e># 完成训练和转换</span>
    estimator <span style=color:#f92672>=</span> KNeighborsClassifier()
    transformed_scores <span style=color:#f92672>=</span> cross_val_score(
        estimator, X_transformed, y, scoring<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;accuracy&#39;</span>)
    print(<span style=color:#e6db74>&#34;The average accuracy for is </span><span style=color:#e6db74>{0:.1f}</span><span style=color:#e6db74>%&#34;</span><span style=color:#f92672>.</span>format(
        np<span style=color:#f92672>.</span>mean(transformed_scores) <span style=color:#f92672>*</span> <span style=color:#ae81ff>100</span>))
</code></pre></div><p>Output:</p>
<pre><code>The average accuracy for is 82.9%
</code></pre>
<p>将数据经过规范化后，正确率再次提高</p>
<p>其它的规范化函数举例：</p>
<ul>
<li>为使每条数据各特征值的和为 1：<code>sklearn.preprocessing.Normalizer</code></li>
<li>为使各特征值的均值为 0，方差为 1：<code>sklearn.preprocessing.StandardScaler</code></li>
<li>为将数值型特征二值化：<code>sklearn.preprocessing.Binarizer</code></li>
</ul>
<h3 id=流水线>流水线</h3>
<p><code>sklearn.pipeline.Pipeline</code>用于创建流水线。流水线的输入为一连串的数据挖掘步骤，最后一步必须是估计器，前几步是转换器。</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># 创建流水线</span>
    <span style=color:#75715e># 流水线的每一步都用(&#39;名称&#39;,步骤)的元组表示</span>
    scaling_pipeline <span style=color:#f92672>=</span> Pipeline([(<span style=color:#e6db74>&#39;scale&#39;</span>, MinMaxScaler()),  <span style=color:#75715e># 规范特征取值</span>
                                 (<span style=color:#e6db74>&#39;predict&#39;</span>, KNeighborsClassifier())])  <span style=color:#75715e># 预测</span>

    <span style=color:#75715e># 调用流水线</span>
    scores <span style=color:#f92672>=</span> cross_val_score(scaling_pipeline, X_broken, y, scoring<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;accuracy&#39;</span>)
    print(
        <span style=color:#e6db74>&#34;The pipelin scored an average accuracy for is </span><span style=color:#e6db74>{0:.1f}</span><span style=color:#e6db74>%&#34;</span><span style=color:#f92672>.</span>format(
            np<span style=color:#f92672>.</span>mean(scores) <span style=color:#f92672>*</span> <span style=color:#ae81ff>100</span>))
</code></pre></div><p>Output:</p>
<pre><code>The pipelin scored an average accuracy for is 82.9%
</code></pre>
<h2 id=第三章>第三章</h2>
<p>决策树也是一种分类算法，它的优点如下：</p>
<ul>
<li>机器和人都能看懂</li>
<li>能够处理多种不同的特征</li>
</ul>
<h3 id=加载数据集>加载数据集</h3>
<p>pandas(Python Data Analysis 的简写)</p>
<p>逗号分隔值（Comma-Separated Values，CSV，有时也称为字符分隔值，因为分隔字符也可以不是逗号），其文件以纯文本形式存储表格数据（数字和文本），来源<a class=link href="https://baike.baidu.com/item/CSV/10739?fr=aladdin" target=_blank rel=noopener>百度百科</a>。</p>
<p>这里使用 <code>pandas</code> 导入.csv 文件，生成一个 <code>dataframe</code> （数据框）的类。导入使用 <code>read_csv()</code> 函数，常用参数如下：</p>
<ul>
<li><code>sep=','</code> 以,为数据分隔符</li>
<li><code>parse_dates='col_name'</code> 将某个特征值读取为日期格式</li>
<li><code>error_bad_lines=False</code> 当某行数据有问题时，跳过而不报错</li>
<li><code>skiprows=[&lt;param>]</code> 跳过列表中所包括的行，参数可以是 0,1,&mldr;的数字序列，也可以用切片表达式<code>[0:]</code></li>
<li><code>usecols=[&lt;param>]</code> 选择使用哪几个特征值，参数同上</li>
</ul>
<p>在使用 <code>dataframe.ix[]</code>获取 <code>dataframe</code> 中的某几行数据时，提示错误信息，原因是 <code>pandas</code> 在 0.20.0 版本后就废弃掉了这个函数。在这里我改为使用 <code>iloc</code> 函数。</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># -*- coding: utf-8 -*-</span>
<span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
<span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
<span style=color:#f92672>from</span> collections <span style=color:#f92672>import</span> defaultdict
<span style=color:#f92672>from</span> sklearn.tree <span style=color:#f92672>import</span> DecisionTreeClassifier  <span style=color:#75715e># 创建决策树的类</span>
<span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> cross_val_score
<span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> LabelEncoder  <span style=color:#75715e># 能将字符串类型的特征转化成整型</span>
<span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> OneHotEncoder  <span style=color:#75715e># 将特征转化为二进制数字</span>
<span style=color:#f92672>from</span> sklearn.ensemble <span style=color:#f92672>import</span> RandomForestClassifier  <span style=color:#75715e># 随机森林</span>
<span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> GridSearchCV  <span style=color:#75715e># 网格搜索，找到最佳参数</span>

<span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;__main__&#39;</span>:
    <span style=color:#75715e># 清洗数据集</span>
    results <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_csv(
        <span style=color:#e6db74>&#34;NBA_data.csv&#34;</span>, parse_dates<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;Date&#34;</span>], skiprows<span style=color:#f92672>=</span>[
            <span style=color:#ae81ff>0</span>, ], usecols<span style=color:#f92672>=</span>[
            <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>6</span>, <span style=color:#ae81ff>7</span>, <span style=color:#ae81ff>9</span>])  <span style=color:#75715e># 加载数据集</span>
    <span style=color:#75715e># 修复数据特征名</span>
    results<span style=color:#f92672>.</span>columns <span style=color:#f92672>=</span> [
        <span style=color:#e6db74>&#34;Date&#34;</span>,
        <span style=color:#e6db74>&#34;Visitor Team&#34;</span>,
        <span style=color:#e6db74>&#34;VisitorPts&#34;</span>,
        <span style=color:#e6db74>&#34;Home Team&#34;</span>,
        <span style=color:#e6db74>&#34;HomePts&#34;</span>,
        <span style=color:#e6db74>&#34;Score Type&#34;</span>,
        <span style=color:#e6db74>&#34;OT?&#34;</span>,
        <span style=color:#e6db74>&#34;Notes&#34;</span>]
    <span style=color:#75715e># results.ix[]已被弃用</span>
    print(results<span style=color:#f92672>.</span>loc[:<span style=color:#ae81ff>5</span>])  <span style=color:#75715e># 查看数据集前五行</span>
</code></pre></div><p>Output:</p>
<pre><code>        Date          Visitor Team  VisitorPts  ... Score Type  OT? Notes
0 2013-10-29         Orlando Magic          87  ...  Box Score  NaN   NaN
1 2013-10-29         Chicago Bulls          95  ...  Box Score  NaN   NaN
2 2013-10-29  Los Angeles Clippers         103  ...  Box Score  NaN   NaN
3 2013-10-30         Brooklyn Nets          94  ...  Box Score  NaN   NaN
4 2013-10-30        Boston Celtics          87  ...  Box Score  NaN   NaN
5 2013-10-30            Miami Heat         110  ...  Box Score  NaN   NaN
[6 rows x 8 columns]
</code></pre>
<h3 id=决策树>决策树</h3>
<p>创建新的特征列，可以从数据集中导入：</p>
<p><code>dataset["New Feature"] = feature_creator()</code></p>
<p>也可以一开始为新特征值设置默认的值：</p>
<p><code>dataset["My New Feature"] = 0</code></p>
<p>这里的 <code>X_previouswins = results[["HomeLastWin", "VisitorLastWin"]].values</code> 生成一个数据集，这个数据集有两个特征</p>
<p><code>DecisionTreeClassifier()</code> 用来创建决策树，常用参数如下：</p>
<ul>
<li><code>min_samples_split</code>: 指定了创建一个新节点至少需要多少个个体</li>
<li><code>min_samples_leaf</code>: 指定为了保留节点，每个节点至少应该包含的个体数量</li>
<li>创建决策的标准: 基尼不纯度/信息增益</li>
</ul>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># 提取新特征，值为这场中主场队伍是否胜利</span>
    results[<span style=color:#e6db74>&#34;HomeWin&#34;</span>] <span style=color:#f92672>=</span> results[<span style=color:#e6db74>&#34;VisitorPts&#34;</span>] <span style=color:#f92672>&lt;</span> results[<span style=color:#e6db74>&#34;HomePts&#34;</span>]
    y_true <span style=color:#f92672>=</span> results[<span style=color:#e6db74>&#34;HomeWin&#34;</span>]<span style=color:#f92672>.</span>values  <span style=color:#75715e># 胜负情况</span>
    <span style=color:#75715e># 创建两个新feature，初始值都设为0，保存这场比赛的两个队伍上场比赛的情况</span>
    results[<span style=color:#e6db74>&#34;HomeLastWin&#34;</span>] <span style=color:#f92672>=</span> <span style=color:#66d9ef>False</span>
    results[<span style=color:#e6db74>&#34;VisitorLastWin&#34;</span>] <span style=color:#f92672>=</span> <span style=color:#66d9ef>False</span>
    won_last <span style=color:#f92672>=</span> defaultdict(int)

    <span style=color:#66d9ef>for</span> index, row <span style=color:#f92672>in</span> results<span style=color:#f92672>.</span>iterrows():
        home_team <span style=color:#f92672>=</span> row[<span style=color:#e6db74>&#34;Home Team&#34;</span>]
        visitor_team <span style=color:#f92672>=</span> row[<span style=color:#e6db74>&#34;Visitor Team&#34;</span>]
        <span style=color:#75715e># 这场比赛之前两个球队上次是否获胜保存在result中</span>
        row[<span style=color:#e6db74>&#34;HomeLastWin&#34;</span>] <span style=color:#f92672>=</span> won_last[home_team]
        row[<span style=color:#e6db74>&#34;VisitorLastWin&#34;</span>] <span style=color:#f92672>=</span> won_last[visitor_team]
        results<span style=color:#f92672>.</span>iloc[index] <span style=color:#f92672>=</span> row
        <span style=color:#75715e># 这场比赛的结果更新won_last中的情况</span>
        won_last[home_team] <span style=color:#f92672>=</span> row[<span style=color:#e6db74>&#34;HomeWin&#34;</span>]
        won_last[visitor_team] <span style=color:#f92672>=</span> <span style=color:#f92672>not</span> row[<span style=color:#e6db74>&#34;HomeWin&#34;</span>]

    X_previouswins <span style=color:#f92672>=</span> results[[<span style=color:#e6db74>&#34;HomeLastWin&#34;</span>, <span style=color:#e6db74>&#34;VisitorLastWin&#34;</span>]]<span style=color:#f92672>.</span>values
    <span style=color:#75715e># 创建决策树生成器实例</span>
    clf <span style=color:#f92672>=</span> DecisionTreeClassifier(random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>14</span>)
    <span style=color:#75715e># 交叉训练</span>
    scores <span style=color:#f92672>=</span> cross_val_score(clf, X_previouswins, y_true, scoring<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;accuracy&#39;</span>)
    print(<span style=color:#e6db74>&#34;Using just the last result from the home and visitor teams&#34;</span>)
    print(<span style=color:#e6db74>&#34;Accuracy: </span><span style=color:#e6db74>{0:.1f}</span><span style=color:#e6db74>%&#34;</span><span style=color:#f92672>.</span>format(np<span style=color:#f92672>.</span>mean(scores) <span style=color:#f92672>*</span> <span style=color:#ae81ff>100</span>))
</code></pre></div><p>Output:</p>
<pre><code>Using just the last result from the home and visitor teams
Accuracy: 56.4%
</code></pre>
<hr>
<p>这里为了创建一个新的特征导入了上一年的 NBA 排名。</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    ladder <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_csv(<span style=color:#e6db74>&#34;NBA_standings.csv&#34;</span>, skiprows<span style=color:#f92672>=</span>[<span style=color:#ae81ff>0</span>, ])
    <span style=color:#75715e># 创建一个新特征，两个队伍在上个赛季的排名哪个比较高</span>
    results[<span style=color:#e6db74>&#34;HomeTeamRanksHigher&#34;</span>] <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
    <span style=color:#66d9ef>for</span> index, row <span style=color:#f92672>in</span> results<span style=color:#f92672>.</span>iterrows():
        home_team <span style=color:#f92672>=</span> row[<span style=color:#e6db74>&#34;Home Team&#34;</span>]
        visitor_team <span style=color:#f92672>=</span> row[<span style=color:#e6db74>&#34;Visitor Team&#34;</span>]
        <span style=color:#75715e># 这个球队改名了</span>
        <span style=color:#66d9ef>if</span> home_team <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;New Orleans Pelicans&#34;</span>:
            home_team <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;New Orleans Hornets&#34;</span>
        <span style=color:#66d9ef>elif</span> visitor_team <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;New Orleans Pelicans&#34;</span>:
            visitor_team <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;New Orleans Hornets&#34;</span>
        <span style=color:#75715e># 这里源代码无法运行，少加了一个括号 ladder[(ladder[&#34;Team&#34;] == home_team)] 表示根据条件获取这一行的数据</span>
        home_row <span style=color:#f92672>=</span> ladder[(ladder[<span style=color:#e6db74>&#34;Team&#34;</span>] <span style=color:#f92672>==</span> home_team)]
        visitor_row <span style=color:#f92672>=</span> ladder[(ladder[<span style=color:#e6db74>&#34;Team&#34;</span>] <span style=color:#f92672>==</span> visitor_team)]
        home_rank <span style=color:#f92672>=</span> home_row[<span style=color:#e6db74>&#34;Rk&#34;</span>]<span style=color:#f92672>.</span>values[<span style=color:#ae81ff>0</span>]
        visitor_rank <span style=color:#f92672>=</span> visitor_row[<span style=color:#e6db74>&#34;Rk&#34;</span>]<span style=color:#f92672>.</span>values[<span style=color:#ae81ff>0</span>]
        row[<span style=color:#e6db74>&#34;HomeTeamRanksHigher&#34;</span>] <span style=color:#f92672>=</span> int(home_rank <span style=color:#f92672>&gt;</span> visitor_rank)
        results<span style=color:#f92672>.</span>iloc[index] <span style=color:#f92672>=</span> row

    X_homehigher <span style=color:#f92672>=</span> results[[<span style=color:#e6db74>&#34;HomeLastWin&#34;</span>, <span style=color:#e6db74>&#34;VisitorLastWin&#34;</span>, <span style=color:#e6db74>&#34;HomeTeamRanksHigher&#34;</span>]]<span style=color:#f92672>.</span>values
    clf <span style=color:#f92672>=</span> DecisionTreeClassifier(random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>14</span>)
    scores <span style=color:#f92672>=</span> cross_val_score(clf, X_homehigher, y_true, scoring<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;accuracy&#39;</span>)
    print(<span style=color:#e6db74>&#34;Using whether the home team is ranked higher&#34;</span>)
    print(<span style=color:#e6db74>&#34;Accuracy: </span><span style=color:#e6db74>{0:.1f}</span><span style=color:#e6db74>%&#34;</span><span style=color:#f92672>.</span>format(np<span style=color:#f92672>.</span>mean(scores) <span style=color:#f92672>*</span> <span style=color:#ae81ff>100</span>))
</code></pre></div><p>Output:</p>
<pre><code>Using whether the home team is ranked higher
Accuracy: 60.0%
</code></pre>
<hr>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># 创建新特征，两个队伍上一次进行比赛时的获胜者</span>
    last_match_winner <span style=color:#f92672>=</span> defaultdict(int)
    results[<span style=color:#e6db74>&#34;HomeTeamWonLast&#34;</span>] <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
    <span style=color:#66d9ef>for</span> index, row <span style=color:#f92672>in</span> results<span style=color:#f92672>.</span>iterrows():
        home_team <span style=color:#f92672>=</span> row[<span style=color:#e6db74>&#34;Home Team&#34;</span>]
        visitor_team <span style=color:#f92672>=</span> row[<span style=color:#e6db74>&#34;Visitor Team&#34;</span>]
        <span style=color:#75715e># 按照英文字母表排序，不去考虑哪个是主场球队</span>
        teams <span style=color:#f92672>=</span> tuple(sorted([home_team, visitor_team]))
        <span style=color:#75715e># 找到两支球队上次比赛的赢家，更新框中的数据，初始为0</span>
        <span style=color:#75715e># 这里的HomeTeamWonLast跟主场客场没有什么关系，也可以叫WhichTeamWonLast，这里为了和源码尽量保持一致使用了源码</span>
        row[<span style=color:#e6db74>&#34;HomeTeamWonLast&#34;</span>] <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span> <span style=color:#66d9ef>if</span> last_match_winner[teams] <span style=color:#f92672>==</span> row[<span style=color:#e6db74>&#34;Home Team&#34;</span>] <span style=color:#66d9ef>else</span> <span style=color:#ae81ff>0</span>
        results<span style=color:#f92672>.</span>iloc[index] <span style=color:#f92672>=</span> row
        winner <span style=color:#f92672>=</span> row[<span style=color:#e6db74>&#34;Home Team&#34;</span>] <span style=color:#66d9ef>if</span> row[<span style=color:#e6db74>&#34;HomeWin&#34;</span>] <span style=color:#66d9ef>else</span> row[<span style=color:#e6db74>&#34;Visitor Team&#34;</span>]
        <span style=color:#75715e># 将两个球队上次遇见比赛的情况存到字典中去</span>
        last_match_winner[teams] <span style=color:#f92672>=</span> winner

    X_home_higher <span style=color:#f92672>=</span> results[[<span style=color:#e6db74>&#34;HomeTeamRanksHigher&#34;</span>, <span style=color:#e6db74>&#34;HomeTeamWonLast&#34;</span>]]<span style=color:#f92672>.</span>values
    clf <span style=color:#f92672>=</span> DecisionTreeClassifier(random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>14</span>)
    scores <span style=color:#f92672>=</span> cross_val_score(clf, X_home_higher, y_true, scoring<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;accuracy&#39;</span>)
    print(<span style=color:#e6db74>&#34;Using whether the home team is ranked higher&#34;</span>)
    print(<span style=color:#e6db74>&#34;Accuracy: </span><span style=color:#e6db74>{0:.1f}</span><span style=color:#e6db74>%&#34;</span><span style=color:#f92672>.</span>format(np<span style=color:#f92672>.</span>mean(scores) <span style=color:#f92672>*</span> <span style=color:#ae81ff>100</span>))
</code></pre></div><p>Output:</p>
<pre><code>Using whether the home team is ranked higher
Accuracy: 59.9%
</code></pre>
<h3 id=随机森林>随机森林</h3>
<p><code>LabelEncoder()</code> 用来将一个字符串型的特征转化为整型</p>
<p><code>OneHotEncoder()</code> 将整数转化成消除差异的二进制数字，即将 1,2,3 转换成 001,010,100</p>
<p>stacking （向量组合），这里 <code>np.vstack()</code> 将两个队伍名向量纵向组合成一个矩阵<code>.T</code>表示将矩阵转置</p>
<p>决策树存在的问题：</p>
<ol>
<li>创建的多颗决策树在很大程度上是相同的，训练集相同，则生成的决策树也相同。一个解决办法是<em>装袋</em>(bagging)</li>
<li>用于前几个决策节点的特征非常突出，即使采用不同的训练集，创建的决策树相似性依旧很大。解决办法是随机选取部分特征作为决策数据</li>
</ol>
<p><code>RandomForestClassifier()</code> 用来调用随机森林算法，因为它调用了 DecisionTreeClassifier 的大量实例，所以他们的参数有很多是一致的。其引入的一部分新参数如下：</p>
<ul>
<li><code>n_estimators</code> 用来指定创建决策树的数量，值越高，耗时越长，准确率(可能)越高</li>
<li><code>oob_score</code> 如果设置为真，测试时将不适用训练模型时用过的数据</li>
<li><code>n_jobs</code> 采用并行算法训练时所用到的内核数量，设置为 -1 则启用全部内核</li>
</ul>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># 创建一个转化器实例</span>
    encoding <span style=color:#f92672>=</span> LabelEncoder()
    <span style=color:#75715e># 将球队名转化为整型</span>
    encoding<span style=color:#f92672>.</span>fit(results[<span style=color:#e6db74>&#34;Home Team&#34;</span>]<span style=color:#f92672>.</span>values)
    <span style=color:#75715e># 抽取所有比赛中主客场球队的球队名，组合起来形成一个矩阵</span>
    home_teams <span style=color:#f92672>=</span> encoding<span style=color:#f92672>.</span>transform(results[<span style=color:#e6db74>&#34;Home Team&#34;</span>]<span style=color:#f92672>.</span>values)
    visitor_teams <span style=color:#f92672>=</span> encoding<span style=color:#f92672>.</span>transform(results[<span style=color:#e6db74>&#34;Visitor Team&#34;</span>]<span style=color:#f92672>.</span>values)
    <span style=color:#75715e># 建立训练集，[[&#34;Home Team Feature&#34;，&#34;Visitor Team Feature&#34;],[&#34;Home Team Feature&#34;，&#34;Visitor Team Feature&#34;]...]</span>
    X_teams <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>vstack([home_teams, visitor_teams])<span style=color:#f92672>.</span>T
    <span style=color:#75715e># 创建转化器实例</span>
    onehot <span style=color:#f92672>=</span> OneHotEncoder()
    <span style=color:#75715e># 生成转化后的特征</span>
    X_teams <span style=color:#f92672>=</span> onehot<span style=color:#f92672>.</span>fit_transform(X_teams)<span style=color:#f92672>.</span>todense()

    clf <span style=color:#f92672>=</span> DecisionTreeClassifier(random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>14</span>)
    scores <span style=color:#f92672>=</span> cross_val_score(clf, X_teams, y_true, scoring<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;accuracy&#39;</span>)
    print(<span style=color:#e6db74>&#34;Accuracy: </span><span style=color:#e6db74>{0:.1f}</span><span style=color:#e6db74>%&#34;</span><span style=color:#f92672>.</span>format(np<span style=color:#f92672>.</span>mean(scores) <span style=color:#f92672>*</span> <span style=color:#ae81ff>100</span>))

    clf <span style=color:#f92672>=</span> RandomForestClassifier(random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>14</span>, n_jobs<span style=color:#f92672>=-</span><span style=color:#ae81ff>1</span>)
    scores <span style=color:#f92672>=</span> cross_val_score(clf, X_teams, y_true, scoring<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;accuracy&#39;</span>)
    print(<span style=color:#e6db74>&#34;Using full team labels is ranked higher&#34;</span>)
    print(<span style=color:#e6db74>&#34;Accuracy: </span><span style=color:#e6db74>{0:.1f}</span><span style=color:#e6db74>%&#34;</span><span style=color:#f92672>.</span>format(np<span style=color:#f92672>.</span>mean(scores) <span style=color:#f92672>*</span> <span style=color:#ae81ff>100</span>))
</code></pre></div><p>Output:</p>
<pre><code>Accuracy: 60.5%
Using full team labels is ranked higher
Accuracy: 61.4%
</code></pre>
<hr>
<p>将上面生成的特征整合起来，创建新的决策方案</p>
<p>这里使用 <code>np.hstack()</code>横向拼接两个决策方案矩阵</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    X_all <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>hstack([X_home_higher, X_teams])  <span style=color:#75715e># 将上面计算的特征进行组合</span>
    print(X_all<span style=color:#f92672>.</span>shape)
    scores <span style=color:#f92672>=</span> cross_val_score(clf, X_all, y_true, scoring<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;accuracy&#39;</span>)
    print(<span style=color:#e6db74>&#34;Using whether the home team is ranked higher&#34;</span>)
    print(<span style=color:#e6db74>&#34;Accuracy: </span><span style=color:#e6db74>{0:.1f}</span><span style=color:#e6db74>%&#34;</span><span style=color:#f92672>.</span>format(np<span style=color:#f92672>.</span>mean(scores) <span style=color:#f92672>*</span> <span style=color:#ae81ff>100</span>))
</code></pre></div><p>Output:</p>
<pre><code>(1319, 62)
Using whether the home team is ranked higher
Accuracy: 61.6%
</code></pre>
<hr>
<p>使用 <code>GridSearchCV</code> （网格搜索）搜索最佳参数</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># 设置参数搜索范围</span>
    parameter_space <span style=color:#f92672>=</span> {
        <span style=color:#e6db74>&#34;max_features&#34;</span>: [<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>10</span>, <span style=color:#e6db74>&#39;auto&#39;</span>],
        <span style=color:#e6db74>&#34;n_estimators&#34;</span>: [<span style=color:#ae81ff>100</span>, ],
        <span style=color:#e6db74>&#34;criterion&#34;</span>: [<span style=color:#e6db74>&#34;gini&#34;</span>, <span style=color:#e6db74>&#34;entropy&#34;</span>],
        <span style=color:#e6db74>&#34;min_samples_leaf&#34;</span>: [<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>6</span>],
    }
    grid <span style=color:#f92672>=</span> GridSearchCV(clf, parameter_space)
    grid<span style=color:#f92672>.</span>fit(X_all, y_true)
    print(<span style=color:#e6db74>&#34;Accuracy: </span><span style=color:#e6db74>{0:.1f}</span><span style=color:#e6db74>%&#34;</span><span style=color:#f92672>.</span>format(grid<span style=color:#f92672>.</span>best_score_ <span style=color:#f92672>*</span> <span style=color:#ae81ff>100</span>))
    <span style=color:#75715e># 输出最佳方案</span>
    print(grid<span style=color:#f92672>.</span>best_estimator_)
</code></pre></div><p>Output:</p>
<pre><code>Accuracy: 65.6%
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                    criterion='gini', max_depth=None, max_features='auto',
                    max_leaf_nodes=None, max_samples=None,
                    min_impurity_decrease=0.0, min_impurity_split=None,
                    min_samples_leaf=2, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, n_estimators=100,
                    n_jobs=-1, oob_score=False, random_state=14, verbose=0,
                    warm_start=False)
</code></pre>
<h3 id=课后练习>课后练习</h3>
<p>拿到了数据，如何创建新的特征，如何在数据中发现其关键点，如何找出数据内部的联系，也是一个需要斟酌的方面</p>
<p>创建下述特征并看一下效果:</p>
<ul>
<li>球队上次打比赛距今有多长时间？</li>
<li>两支球队过去五场比赛结果如何？</li>
<li>球队是不是跟某支特定球队打比赛时发挥更好？</li>
</ul>
<p>在这里使用了上面书中的方法，完成了前两个点，第三个点实现起来有点麻烦，现在只有一个思路：建立一个字典，数据形式为 (两支球队建立一个元组:(前一个队伍获胜的次数，后一个队伍获胜的次数))</p>
<p>在处理 dataset 中的数据项时，对于 <code>pandas</code> 中的 <code>Timestamp</code> 类型没有了解，耗费了太长时间，查阅文档后发现可以用 <code>date()</code> 将其转化为 <code>datetime.date</code> 日期。</p>
<p>使用前两个特征作为决策标准时，效果还算可以，加上书上的所有特征后，准确率反而较上面的结果降低了。（不知道为什么）</p>
<p>这个“课后练习”使我对于标准库了解匮乏的短板显现出来，要抽出时间学习一下 <code>python</code>, <code>numpy</code> 和 <code>pandas</code> 标准库中常用函数及其参数。</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e>#!/usr/bin/env python3</span>
<span style=color:#75715e># -*- coding: utf-8 -*-</span>
<span style=color:#f92672>import</span> datetime
<span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
<span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
<span style=color:#f92672>from</span> collections <span style=color:#f92672>import</span> defaultdict
<span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> cross_val_score
<span style=color:#f92672>from</span> sklearn.tree <span style=color:#f92672>import</span> DecisionTreeClassifier
<span style=color:#f92672>from</span> sklearn.ensemble <span style=color:#f92672>import</span> RandomForestClassifier
<span style=color:#f92672>from</span> ch3.nba_test <span style=color:#f92672>import</span> X_all
<span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> GridSearchCV  <span style=color:#75715e># 网格搜索，找到最佳参数</span>


<span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;__main__&#39;</span>:
    <span style=color:#e6db74>&#34;&#34;&#34;
</span><span style=color:#e6db74>    - 球队上次打比赛距今有多长时间？
</span><span style=color:#e6db74>    - 两支球队过去五场比赛结果如何？
</span><span style=color:#e6db74>    - 球队是不是跟某支特定球队打比赛时发挥更好？
</span><span style=color:#e6db74>    &#34;&#34;&#34;</span>
    dataset <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_csv(
        <span style=color:#e6db74>&#34;NBA_data.csv&#34;</span>, parse_dates<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;Date&#34;</span>], skiprows<span style=color:#f92672>=</span>[
            <span style=color:#ae81ff>0</span>, ], usecols<span style=color:#f92672>=</span>[
            <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>6</span>, <span style=color:#ae81ff>7</span>, <span style=color:#ae81ff>9</span>])  <span style=color:#75715e># 加载数据集</span>
    dataset<span style=color:#f92672>.</span>columns <span style=color:#f92672>=</span> [
        <span style=color:#e6db74>&#34;Date&#34;</span>,
        <span style=color:#e6db74>&#34;Visitor Team&#34;</span>,
        <span style=color:#e6db74>&#34;VisitorPts&#34;</span>,
        <span style=color:#e6db74>&#34;Home Team&#34;</span>,
        <span style=color:#e6db74>&#34;HomePts&#34;</span>,
        <span style=color:#e6db74>&#34;Score Type&#34;</span>,
        <span style=color:#e6db74>&#34;OT?&#34;</span>,
        <span style=color:#e6db74>&#34;Notes&#34;</span>]
    dataset[<span style=color:#e6db74>&#34;HomeWin&#34;</span>] <span style=color:#f92672>=</span> dataset[<span style=color:#e6db74>&#34;VisitorPts&#34;</span>] <span style=color:#f92672>&lt;</span> dataset[<span style=color:#e6db74>&#34;HomePts&#34;</span>]
    y_true <span style=color:#f92672>=</span> dataset[<span style=color:#e6db74>&#34;HomeWin&#34;</span>]<span style=color:#f92672>.</span>values  <span style=color:#75715e># 胜负情况</span>

    <span style=color:#75715e># 保存上次打比赛的时间</span>
    last_played_date <span style=color:#f92672>=</span> defaultdict(datetime<span style=color:#f92672>.</span>date)
    <span style=color:#75715e># 手动为每个球队初始化</span>
    <span style=color:#66d9ef>for</span> team <span style=color:#f92672>in</span> set(dataset[<span style=color:#e6db74>&#34;Home Team&#34;</span>]):
        last_played_date[team] <span style=color:#f92672>=</span> datetime<span style=color:#f92672>.</span>date(year<span style=color:#f92672>=</span><span style=color:#ae81ff>2013</span>, month<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>, day<span style=color:#f92672>=</span><span style=color:#ae81ff>25</span>)
    <span style=color:#75715e># 两支球队过去的比赛结果，每个球队的数据是[True,False,,,]的序列</span>
    last_five_games <span style=color:#f92672>=</span> defaultdict(list)

    <span style=color:#75715e># 存放Home和Visitor前五次比赛的获胜次数</span>
    dataset[<span style=color:#e6db74>&#34;HWinTimes&#34;</span>] <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
    dataset[<span style=color:#e6db74>&#34;VWinTimes&#34;</span>] <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
    <span style=color:#75715e># 存放距离上次比赛的时间间隔，用天计数</span>
    dataset[<span style=color:#e6db74>&#34;HLastPlayedSpan&#34;</span>] <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
    dataset[<span style=color:#e6db74>&#34;VLastPlayedSpan&#34;</span>] <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
    <span style=color:#66d9ef>for</span> index, row <span style=color:#f92672>in</span> dataset<span style=color:#f92672>.</span>iterrows():
        home_team <span style=color:#f92672>=</span> row[<span style=color:#e6db74>&#34;Home Team&#34;</span>]
        visitor_team <span style=color:#f92672>=</span> row[<span style=color:#e6db74>&#34;Visitor Team&#34;</span>]

        row[<span style=color:#e6db74>&#34;HWinTimes&#34;</span>] <span style=color:#f92672>=</span> sum(last_five_games[home_team][<span style=color:#f92672>-</span><span style=color:#ae81ff>5</span>:])
        row[<span style=color:#e6db74>&#34;VWinTimes&#34;</span>] <span style=color:#f92672>=</span> sum(last_five_games[visitor_team][<span style=color:#f92672>-</span><span style=color:#ae81ff>5</span>:])
        row[<span style=color:#e6db74>&#34;HLastPlayedSpan&#34;</span>] <span style=color:#f92672>=</span> (
            row[<span style=color:#e6db74>&#34;Date&#34;</span>]<span style=color:#f92672>.</span>date() <span style=color:#f92672>-</span>
            last_played_date[home_team])<span style=color:#f92672>.</span>days
        row[<span style=color:#e6db74>&#34;VLastPlayedSpan&#34;</span>] <span style=color:#f92672>=</span> (
            row[<span style=color:#e6db74>&#34;Date&#34;</span>]<span style=color:#f92672>.</span>date() <span style=color:#f92672>-</span>
            last_played_date[visitor_team])<span style=color:#f92672>.</span>days

        dataset<span style=color:#f92672>.</span>iloc[index] <span style=color:#f92672>=</span> row

        last_played_date[home_team] <span style=color:#f92672>=</span> row[<span style=color:#e6db74>&#34;Date&#34;</span>]<span style=color:#f92672>.</span>date()
        last_played_date[visitor_team] <span style=color:#f92672>=</span> row[<span style=color:#e6db74>&#34;Date&#34;</span>]<span style=color:#f92672>.</span>date()
        last_five_games[home_team]<span style=color:#f92672>.</span>append(row[<span style=color:#e6db74>&#34;HomeWin&#34;</span>])
        last_five_games[visitor_team]<span style=color:#f92672>.</span>append(<span style=color:#f92672>not</span> row[<span style=color:#e6db74>&#34;HomeWin&#34;</span>])

    X_1 <span style=color:#f92672>=</span> dataset[[<span style=color:#e6db74>&#34;HLastPlayedSpan&#34;</span>,
                             <span style=color:#e6db74>&#34;VLastPlayedSpan&#34;</span>, <span style=color:#e6db74>&#34;HWinTimes&#34;</span>, <span style=color:#e6db74>&#34;VWinTimes&#34;</span>]]<span style=color:#f92672>.</span>values
    clf <span style=color:#f92672>=</span> DecisionTreeClassifier(random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>14</span>)
    scores <span style=color:#f92672>=</span> cross_val_score(clf, X_1, y_true, scoring<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;accuracy&#39;</span>)
    print(<span style=color:#e6db74>&#34;DecisionTree: Using time span and win times&#34;</span>)
    print(<span style=color:#e6db74>&#34;Accuracy: </span><span style=color:#e6db74>{0:.1f}</span><span style=color:#e6db74>%&#34;</span><span style=color:#f92672>.</span>format(np<span style=color:#f92672>.</span>mean(scores) <span style=color:#f92672>*</span> <span style=color:#ae81ff>100</span>))

    clf <span style=color:#f92672>=</span> RandomForestClassifier(random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>14</span>, n_jobs<span style=color:#f92672>=-</span><span style=color:#ae81ff>1</span>)
    scores <span style=color:#f92672>=</span> cross_val_score(clf, X_1, y_true, scoring<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;accuracy&#39;</span>)
    print(<span style=color:#e6db74>&#34;RandomForest: Using time span and win times&#34;</span>)
    print(<span style=color:#e6db74>&#34;Accuracy: </span><span style=color:#e6db74>{0:.1f}</span><span style=color:#e6db74>%&#34;</span><span style=color:#f92672>.</span>format(np<span style=color:#f92672>.</span>mean(scores) <span style=color:#f92672>*</span> <span style=color:#ae81ff>100</span>))
    print(<span style=color:#e6db74>&#34;---------------------------------&#34;</span>)

    X_all <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>hstack([X_1, X_all])

    clf <span style=color:#f92672>=</span> DecisionTreeClassifier(random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>14</span>)
    scores <span style=color:#f92672>=</span> cross_val_score(clf, X_all, y_true, scoring<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;accuracy&#39;</span>)
    print(<span style=color:#e6db74>&#34;DecisionTree: Using time span and win times&#34;</span>)
    print(<span style=color:#e6db74>&#34;Accuracy: </span><span style=color:#e6db74>{0:.1f}</span><span style=color:#e6db74>%&#34;</span><span style=color:#f92672>.</span>format(np<span style=color:#f92672>.</span>mean(scores) <span style=color:#f92672>*</span> <span style=color:#ae81ff>100</span>))

    clf <span style=color:#f92672>=</span> RandomForestClassifier(random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>14</span>, n_jobs<span style=color:#f92672>=-</span><span style=color:#ae81ff>1</span>)
    scores <span style=color:#f92672>=</span> cross_val_score(clf, X_all, y_true, scoring<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;accuracy&#39;</span>)
    print(<span style=color:#e6db74>&#34;RandomForest: Using time span and win times&#34;</span>)
    print(<span style=color:#e6db74>&#34;Accuracy: </span><span style=color:#e6db74>{0:.1f}</span><span style=color:#e6db74>%&#34;</span><span style=color:#f92672>.</span>format(np<span style=color:#f92672>.</span>mean(scores) <span style=color:#f92672>*</span> <span style=color:#ae81ff>100</span>))
    print(<span style=color:#e6db74>&#34;---------------------------------&#34;</span>)
    parameter_space <span style=color:#f92672>=</span> {
        <span style=color:#e6db74>&#34;max_features&#34;</span>: [<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>10</span>, <span style=color:#e6db74>&#39;auto&#39;</span>],
        <span style=color:#e6db74>&#34;n_estimators&#34;</span>: [<span style=color:#ae81ff>100</span>, ],
        <span style=color:#e6db74>&#34;criterion&#34;</span>: [<span style=color:#e6db74>&#34;gini&#34;</span>, <span style=color:#e6db74>&#34;entropy&#34;</span>],
        <span style=color:#e6db74>&#34;min_samples_leaf&#34;</span>: [<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>6</span>],
    }
    grid <span style=color:#f92672>=</span> GridSearchCV(clf, parameter_space)
    grid<span style=color:#f92672>.</span>fit(X_all, y_true)
    print(<span style=color:#e6db74>&#34;Accuracy: </span><span style=color:#e6db74>{0:.1f}</span><span style=color:#e6db74>%&#34;</span><span style=color:#f92672>.</span>format(grid<span style=color:#f92672>.</span>best_score_ <span style=color:#f92672>*</span> <span style=color:#ae81ff>100</span>))
    print(grid<span style=color:#f92672>.</span>best_estimator_)
</code></pre></div><p>Output:</p>
<pre><code>DecisionTree: Using time span and win times
Accuracy: 56.4%
RandomForest: Using time span and win times
Accuracy: 58.3%
---------------------------------
DecisionTree: Using time span and win times
Accuracy: 57.2%
RandomForest: Using time span and win times
Accuracy: 61.0%
---------------------------------
Accuracy: 64.6%
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                    criterion='entropy', max_depth=None, max_features=2,
                    max_leaf_nodes=None, max_samples=None,
                    min_impurity_decrease=0.0, min_impurity_split=None,
                    min_samples_leaf=4, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, n_estimators=100,
                    n_jobs=-1, oob_score=False, random_state=14, verbose=0,
                    warm_start=False)
</code></pre>
<p><figure>
<a href=/img/in-post/data-mining/ch3/homework.jpg>
<img src=/img/in-post/data-mining/ch3/homework.jpg loading=lazy alt=数据集情况>
</a>
<figcaption>数据集情况</figcaption>
</figure></p>
<h2 id=第四章>第四章</h2>
<p>本章重点：</p>
<ul>
<li>亲和性分析</li>
<li>用 Apriori 算法挖掘关联特征</li>
<li>数据稀疏问题</li>
</ul>
<h3 id=亲和性分析-1>亲和性分析</h3>
<p>Apriori 算法是经典的亲和性分析算法，它只从数据集中频繁出现的商品中选取出共同出现的商品组成频繁项集，避免了复杂度呈指数级增长的问题。一旦找到频繁项集，生成关联规则就变得容易了。</p>
<p>原理：确保了规则在数据集中有足够的支持度。Apriori 算法一个重要参数就是最小支持度，如果想要生成(A,B,C)的频繁项集，则其子集必须都要满足最小支持度标准。</p>
<p>其它亲和性算法还有 Eclat 和频繁项集挖掘算法(FP-growth)。这些算法比起基础的 Apriori 算法有很多改进，性能也有进一步提升。</p>
<p>第一阶段，为 Apriori 算法指定一个项集要成为频繁项集所需的最小支持度。第二阶段，根据置信度取关联规则，设定最小置信度，返回大于此值的规则。</p>
<h3 id=电影推荐问题>电影推荐问题</h3>
<p><a class=link href=http://files.grouplens.org/datasets/movielens/ml-100k.zip target=_blank rel=noopener>下载</a>并加载数据集</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> sys
<span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
<span style=color:#f92672>from</span> collections <span style=color:#f92672>import</span> defaultdict
<span style=color:#f92672>from</span> operator <span style=color:#f92672>import</span> itemgetter


<span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;__main__&#39;</span>:
    <span style=color:#75715e># header=None 不把第一行当做表头</span>
    all_ratings <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_csv(
        <span style=color:#e6db74>&#34;ml-100k/u.data&#34;</span>,
        delimiter<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\t</span><span style=color:#e6db74>&#34;</span>,
        header<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>,
        names<span style=color:#f92672>=</span>[
            <span style=color:#e6db74>&#34;UserID&#34;</span>,
            <span style=color:#e6db74>&#34;MovieID&#34;</span>,
            <span style=color:#e6db74>&#34;Rating&#34;</span>,
            <span style=color:#e6db74>&#34;Datetime&#34;</span>])
    <span style=color:#75715e># 转化时间戳为datetime</span>
    all_ratings[<span style=color:#e6db74>&#34;Datetime&#34;</span>] <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>to_datetime(all_ratings[<span style=color:#e6db74>&#34;Datetime&#34;</span>], unit<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;s&#39;</span>)
    <span style=color:#75715e># 输出用户-电影-评分稀疏矩阵</span>
    print(all_ratings[:<span style=color:#ae81ff>5</span>])
    print()
    <span style=color:#75715e># 创建Favorite特征，将评分属性二值化为是否喜欢</span>
    all_ratings[<span style=color:#e6db74>&#34;Favorable&#34;</span>] <span style=color:#f92672>=</span> all_ratings[<span style=color:#e6db74>&#34;Rating&#34;</span>] <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>3</span>
    <span style=color:#75715e># 取用户ID为前200的用户的打分数据</span>
    ratings <span style=color:#f92672>=</span> all_ratings[all_ratings[<span style=color:#e6db74>&#34;UserID&#34;</span>]<span style=color:#f92672>.</span>isin(range(<span style=color:#ae81ff>200</span>))]
    favorable_ratings <span style=color:#f92672>=</span> ratings[ratings[<span style=color:#e6db74>&#34;Favorable&#34;</span>]]
    <span style=color:#75715e># 创建用户喜欢哪些电影的字典</span>
    favorable_reviews_by_users <span style=color:#f92672>=</span> dict(
        (k,
         frozenset(
             v<span style=color:#f92672>.</span>values)) <span style=color:#66d9ef>for</span> k,
        v <span style=color:#f92672>in</span> favorable_ratings<span style=color:#f92672>.</span>groupby(<span style=color:#e6db74>&#34;UserID&#34;</span>)[<span style=color:#e6db74>&#34;MovieID&#34;</span>])
    <span style=color:#75715e># 创建一个数据框，了解每部电影的影迷数量</span>
    num_favorable_by_movie <span style=color:#f92672>=</span> ratings[[
        <span style=color:#e6db74>&#34;MovieID&#34;</span>, <span style=color:#e6db74>&#34;Favorable&#34;</span>]]<span style=color:#f92672>.</span>groupby(<span style=color:#e6db74>&#34;MovieID&#34;</span>)<span style=color:#f92672>.</span>sum()
    <span style=color:#75715e># 查看最受欢迎的五部电影</span>
    print(num_favorable_by_movie<span style=color:#f92672>.</span>sort_values(<span style=color:#e6db74>&#34;Favorable&#34;</span>, ascending<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)[:<span style=color:#ae81ff>5</span>])
</code></pre></div><p>Output:</p>
<pre><code>UserID  MovieID  Rating            Datetime
0     196      242       3 1997-12-04 15:55:49
1     186      302       3 1998-04-04 19:22:22
2      22      377       1 1997-11-07 07:18:36
3     244       51       2 1997-11-27 05:02:03
4     166      346       1 1998-02-02 05:33:16

        Favorable
MovieID
50           100.0
100           89.0
258           83.0
181           79.0
174           74.0
</code></pre>
<h3 id=apriori-算法的实现>Apriori 算法的实现</h3>
<ol>
<li>把各项目放到只包含自己的项集中，生成最初的频繁项集。只使用达到最小支持度的项目。</li>
<li>查找现有频繁项集的超集，发现新的频繁项集，并用其生成新的备选项集。</li>
<li>测试新生成的备选项集的频繁程度（与最小支持度比较），如果不够频繁则舍弃。如果没有新的频繁项集，就跳到最后一步。</li>
<li>存储新发现的频繁项集，跳到步骤 2</li>
<li>返回所有的频繁项集</li>
</ol>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># 字典保存最新发现的频繁项集</span>
    frequent_itemsets <span style=color:#f92672>=</span> {}
    min_support <span style=color:#f92672>=</span> <span style=color:#ae81ff>50</span>

    <span style=color:#75715e># 第一步，每一步电影生成只包含它自己的项集</span>
    <span style=color:#75715e># frozenset() 返回一个冻结的集合，冻结后集合不能再添加或删除任何元素</span>
    <span style=color:#75715e># 普通集合可变，集合中不能有可变的元素，因此普通集合不能被放在集合中；冻结集合不可变，因此可以被放入集合</span>
    frequent_itemsets[<span style=color:#ae81ff>1</span>] <span style=color:#f92672>=</span> dict((frozenset((movie_id,)),
         row[<span style=color:#e6db74>&#34;Favorable&#34;</span>]) <span style=color:#66d9ef>for</span> movie_id,
        row <span style=color:#f92672>in</span> num_favorable_by_movie<span style=color:#f92672>.</span>iterrows() <span style=color:#66d9ef>if</span> row[<span style=color:#e6db74>&#34;Favorable&#34;</span>] <span style=color:#f92672>&gt;</span> min_support)

    <span style=color:#75715e># 会有重复，导致喜欢电影1,50的人分别为50,100但是 {1,50} 的集合有100个</span>
    <span style=color:#75715e># 两个原因，第一在current_superset时项集有时候会突然调换位置</span>
    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>find_frequent_itemsets</span>(
            favorable_reviews_by_users,
            k_1_itemsets,
            min_support):
        counts <span style=color:#f92672>=</span> defaultdict(int)
        <span style=color:#75715e># 遍历每一个用户，获取其喜欢的电影</span>
        <span style=color:#66d9ef>for</span> user, reviews <span style=color:#f92672>in</span> favorable_reviews_by_users<span style=color:#f92672>.</span>items():
            <span style=color:#75715e># 遍历每个项集</span>
            <span style=color:#66d9ef>for</span> itemset <span style=color:#f92672>in</span> k_1_itemsets:
                <span style=color:#66d9ef>if</span> itemset<span style=color:#f92672>.</span>issubset(reviews):  <span style=color:#75715e># 判断itemset是否是用户喜欢的电影的子集</span>
                    <span style=color:#75715e># 对用户喜欢的电影中除了这个子集的电影进行遍历</span>
                    <span style=color:#66d9ef>for</span> other_reviewed_movie <span style=color:#f92672>in</span> reviews <span style=color:#f92672>-</span> itemset:
                        <span style=color:#75715e># 将该电影并入项集中</span>
                        current_superset <span style=color:#f92672>=</span> itemset <span style=color:#f92672>|</span> frozenset(
                            {other_reviewed_movie})
                        counts[current_superset] <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>  <span style=color:#75715e># 这个项集的支持度+1</span>
        <span style=color:#75715e># 返回元素数目+1的项集和数量</span>
        res <span style=color:#f92672>=</span> dict([(itemset, frequency) <span style=color:#66d9ef>for</span> itemset,
                                             frequency <span style=color:#f92672>in</span> counts<span style=color:#f92672>.</span>items() <span style=color:#66d9ef>if</span> frequency <span style=color:#f92672>&gt;=</span> min_support])
        <span style=color:#66d9ef>return</span> res

    <span style=color:#66d9ef>for</span> k <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>20</span>):
        cur_frequent_itemsets <span style=color:#f92672>=</span> find_frequent_itemsets(
            favorable_reviews_by_users, frequent_itemsets[k <span style=color:#f92672>-</span> <span style=color:#ae81ff>1</span>], min_support)
        frequent_itemsets[k] <span style=color:#f92672>=</span> cur_frequent_itemsets
        <span style=color:#66d9ef>if</span> len(cur_frequent_itemsets) <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>:
            print(<span style=color:#e6db74>&#34;Did not find any frequent itemsets of length </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(k))
            sys<span style=color:#f92672>.</span>stdout<span style=color:#f92672>.</span>flush()  <span style=color:#75715e># 将缓冲区内容输出到终端，不宜多用，输出操作带来的计算开销会拖慢程序运行速度</span>
            <span style=color:#66d9ef>break</span>
        <span style=color:#66d9ef>else</span>:
            print(
                <span style=color:#e6db74>&#34;I found </span><span style=color:#e6db74>{}</span><span style=color:#e6db74> frequent itemsets of length </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(
                    len(cur_frequent_itemsets), k))
            sys<span style=color:#f92672>.</span>stdout<span style=color:#f92672>.</span>flush()
    <span style=color:#75715e># 除去只包含一个元素的初始集合</span>
    <span style=color:#66d9ef>del</span> frequent_itemsets[<span style=color:#ae81ff>1</span>]
</code></pre></div><p>Output:</p>
<pre><code>I found 93 frequent itemsets of length 2
I found 295 frequent itemsets of length 3
I found 593 frequent itemsets of length 4
I found 785 frequent itemsets of length 5
I found 677 frequent itemsets of length 6
I found 373 frequent itemsets of length 7
I found 126 frequent itemsets of length 8
I found 24 frequent itemsets of length 9
I found 2 frequent itemsets of length 10
Did not find any frequent itemsets of length 11
</code></pre>
<h3 id=抽取关联规则>抽取关联规则</h3>
<p>对每个频繁项集，选出其中的一个元素当结论，剩下的元素都作为条件，生成规则。</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># 规则形式：如果用户喜欢前提中的所有电影，那么他们也会喜欢结论中的电影</span>
    candidate_rules <span style=color:#f92672>=</span> []
    <span style=color:#66d9ef>for</span> itemset_length, itemset_counts <span style=color:#f92672>in</span> frequent_itemsets<span style=color:#f92672>.</span>items():
        <span style=color:#66d9ef>for</span> itemset <span style=color:#f92672>in</span> itemset_counts<span style=color:#f92672>.</span>keys():
            <span style=color:#66d9ef>for</span> conclusion <span style=color:#f92672>in</span> itemset:
                premise <span style=color:#f92672>=</span> itemset <span style=color:#f92672>-</span> {conclusion}
                candidate_rules<span style=color:#f92672>.</span>append((premise, conclusion))
    print(candidate_rules[:<span style=color:#ae81ff>5</span>])
</code></pre></div><p>Output:</p>
<pre><code>[(frozenset({7}), 1), (frozenset({1}), 7), (frozenset({50}), 1), (frozenset({1}), 50), (frozenset({1}), 56)]
</code></pre>
<hr>
<p>置信度计算，方法与第一章类似。</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># 计算置信度</span>
    correct_counts <span style=color:#f92672>=</span> defaultdict(int)
    incorrect_counts <span style=color:#f92672>=</span> defaultdict(int)

    <span style=color:#75715e># 遍历每一个用户，获取其喜欢的电影</span>
    <span style=color:#66d9ef>for</span> user, reviews <span style=color:#f92672>in</span> favorable_reviews_by_users<span style=color:#f92672>.</span>items():
        <span style=color:#75715e># 遍历每个规则</span>
        <span style=color:#66d9ef>for</span> candidate_rule <span style=color:#f92672>in</span> candidate_rules:
            <span style=color:#75715e># 获取规则的条件和结论</span>
            premise, conclusion <span style=color:#f92672>=</span> candidate_rule
            <span style=color:#75715e># 如果条件是喜欢电影的子集（条件成立）</span>
            <span style=color:#66d9ef>if</span> premise<span style=color:#f92672>.</span>issubset(reviews):
                <span style=color:#75715e># 如果用户也喜欢结论的电影</span>
                <span style=color:#66d9ef>if</span> conclusion <span style=color:#f92672>in</span> reviews:
                    correct_counts[candidate_rule] <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
                <span style=color:#66d9ef>else</span>:
                    incorrect_counts[candidate_rule] <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
    <span style=color:#75715e># 计算置信度，结论发生的次数除以条件发生的次数</span>
    rule_confidence <span style=color:#f92672>=</span> {
        candidate_rule: correct_counts[candidate_rule] <span style=color:#f92672>/</span>
        float(
            correct_counts[candidate_rule] <span style=color:#f92672>+</span>
            incorrect_counts[candidate_rule]) <span style=color:#66d9ef>for</span> candidate_rule <span style=color:#f92672>in</span> candidate_rules}
    <span style=color:#75715e># 给置信度排序</span>
    sorted_confidence <span style=color:#f92672>=</span> sorted(
        rule_confidence<span style=color:#f92672>.</span>items(),
        key<span style=color:#f92672>=</span>itemgetter(<span style=color:#ae81ff>1</span>),
        reverse<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
    <span style=color:#66d9ef>for</span> index <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>5</span>):
        print(<span style=color:#e6db74>&#34;Rule #</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(index <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>))
        (premise, conclusion) <span style=color:#f92672>=</span> sorted_confidence[index][<span style=color:#ae81ff>0</span>]
        print(
            <span style=color:#e6db74>&#34;Rule: If a person recommends </span><span style=color:#e6db74>{}</span><span style=color:#e6db74> they will also recommand </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(
                premise,
                conclusion))
        print(
            <span style=color:#e6db74>&#34;- Confidence: </span><span style=color:#e6db74>{0:.3f}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(rule_confidence[(premise, conclusion)]))
        print(<span style=color:#e6db74>&#34;--------------------&#34;</span>)
</code></pre></div><p>Output:</p>
<pre><code>Rule #1
Rule: If a person recommends frozenset({98, 181}) they will also recommand 50
- Confidence: 1.000
--------------------
Rule #2
Rule: If a person recommends frozenset({172, 79}) they will also recommand 174
- Confidence: 1.000
--------------------
Rule #3
Rule: If a person recommends frozenset({258, 172}) they will also recommand 174
- Confidence: 1.000
--------------------
Rule #4
Rule: If a person recommends frozenset({1, 181, 7}) they will also recommand 50
- Confidence: 1.000
--------------------
Rule #5
Rule: If a person recommends frozenset({1, 172, 7}) they will also recommand 174
- Confidence: 1.000
--------------------
</code></pre>
<hr>
<p>调整输出，加上电影名</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    movie_name_data <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_csv(
        <span style=color:#e6db74>&#34;ml-100k/u.item&#34;</span>,
        delimiter<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;|&#39;</span>,
        header<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>,
        encoding<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;mac-roman&#34;</span>)
    movie_name_data<span style=color:#f92672>.</span>columns <span style=color:#f92672>=</span> [
        <span style=color:#e6db74>&#39;MovieID&#39;</span>,
        <span style=color:#e6db74>&#39;Title&#39;</span>,
        <span style=color:#e6db74>&#39;Release Date&#39;</span>,
        <span style=color:#e6db74>&#39;Video Release&#39;</span>,
        <span style=color:#e6db74>&#39;IMDB&#39;</span>,
        <span style=color:#e6db74>&#39;&lt;UNK&gt;&#39;</span>,
        <span style=color:#e6db74>&#39;Action&#39;</span>,
        <span style=color:#e6db74>&#39;Adventure&#39;</span>,
        <span style=color:#e6db74>&#39;Animation&#39;</span>,
        <span style=color:#e6db74>&#34;Children&#39;s&#34;</span>,
        <span style=color:#e6db74>&#39;Comedy&#39;</span>,
        <span style=color:#e6db74>&#39;Crime&#39;</span>,
        <span style=color:#e6db74>&#39;Documentary&#39;</span>,
        <span style=color:#e6db74>&#39;Drama&#39;</span>,
        <span style=color:#e6db74>&#39;Fantasy&#39;</span>,
        <span style=color:#e6db74>&#39;Film-Noir&#39;</span>,
        <span style=color:#e6db74>&#39;Horror&#39;</span>,
        <span style=color:#e6db74>&#39;Musical&#39;</span>,
        <span style=color:#e6db74>&#39;Mystery&#39;</span>,
        <span style=color:#e6db74>&#39;Romance&#39;</span>,
        <span style=color:#e6db74>&#39;Sci-Fi&#39;</span>,
        <span style=color:#e6db74>&#39;Thriller&#39;</span>,
        <span style=color:#e6db74>&#39;War&#39;</span>,
        <span style=color:#e6db74>&#39;Western&#39;</span>]

    <span style=color:#66d9ef>for</span> index <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>5</span>):
        print(<span style=color:#e6db74>&#39;Rule #</span><span style=color:#e6db74>{0}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(index <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>))
        (premise, conclusion) <span style=color:#f92672>=</span> sorted_confidence[index][<span style=color:#ae81ff>0</span>]
        premise_names <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;, &#39;</span><span style=color:#f92672>.</span>join(get_movie_name(idx) <span style=color:#66d9ef>for</span> idx <span style=color:#f92672>in</span> premise)
        conclusion_name <span style=color:#f92672>=</span> get_movie_name(conclusion)
        print(
            <span style=color:#e6db74>&#39;Rule: if a person recommends </span><span style=color:#e6db74>{0}</span><span style=color:#e6db74> they will also recommend </span><span style=color:#e6db74>{1}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(
                premise_names,
                conclusion_name))
        print(
            <span style=color:#e6db74>&#39; - Confidence: </span><span style=color:#e6db74>{0:.3f}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(rule_confidence[(premise, conclusion)]))
        print(<span style=color:#e6db74>&#34;--------------------&#34;</span>)
</code></pre></div><p>Output:</p>
<pre><code>Rule #1
Rule: if a person recommends Silence of the Lambs, The (1991), Return of the Jedi (1983) they will also recommend Star Wars (1977)
- Confidence: 1.000
--------------------
Rule #2
Rule: if a person recommends Empire Strikes Back, The (1980), Fugitive, The (1993) they will also recommend Raiders of the Lost Ark (1981)
- Confidence: 1.000
--------------------
Rule #3
Rule: if a person recommends Contact (1997), Empire Strikes Back, The (1980) they will also recommend Raiders of the Lost Ark (1981)
- Confidence: 1.000
--------------------
Rule #4
Rule: if a person recommends Toy Story (1995), Return of the Jedi (1983), Twelve Monkeys (1995) they will also recommend Star Wars (1977)
- Confidence: 1.000
--------------------
Rule #5
Rule: if a person recommends Toy Story (1995), Empire Strikes Back, The (1980), Twelve Monkeys (1995) they will also recommend Raiders of the Lost Ark (1981)
- Confidence: 1.000
--------------------
</code></pre>
<h3 id=评估测试>评估测试</h3>
<p>使用剩下的数据集计算规则的置信度，也是查看每条规则表现的一个方法。</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># 评估测试</span>
    test_dataset <span style=color:#f92672>=</span> all_ratings[<span style=color:#f92672>~</span>all_ratings[<span style=color:#e6db74>&#39;UserID&#39;</span>]<span style=color:#f92672>.</span>isin(range(<span style=color:#ae81ff>200</span>))]
    test_favorable <span style=color:#f92672>=</span> test_dataset[test_dataset[<span style=color:#e6db74>&#34;Favorable&#34;</span>]]
    test_favorable_by_users <span style=color:#f92672>=</span> dict((k, frozenset(v<span style=color:#f92672>.</span>values))
                                   <span style=color:#66d9ef>for</span> k, v <span style=color:#f92672>in</span> test_favorable<span style=color:#f92672>.</span>groupby(<span style=color:#e6db74>&#34;UserID&#34;</span>)[<span style=color:#e6db74>&#34;MovieID&#34;</span>])

    correct_counts <span style=color:#f92672>=</span> defaultdict(int)
    incorrect_counts <span style=color:#f92672>=</span> defaultdict(int)
    <span style=color:#66d9ef>for</span> user, reviews <span style=color:#f92672>in</span> test_favorable_by_users<span style=color:#f92672>.</span>items():
        <span style=color:#66d9ef>for</span> candidate_rule <span style=color:#f92672>in</span> candidate_rules:
            premise, conclusion <span style=color:#f92672>=</span> candidate_rule
            <span style=color:#66d9ef>if</span> premise<span style=color:#f92672>.</span>issubset(reviews):
                <span style=color:#66d9ef>if</span> conclusion <span style=color:#f92672>in</span> reviews:
                    correct_counts[candidate_rule] <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
                <span style=color:#66d9ef>else</span>:
                    incorrect_counts[candidate_rule] <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>

    test_confidence <span style=color:#f92672>=</span> {
        candidate_rule: correct_counts[candidate_rule] <span style=color:#f92672>/</span>
        float(
            correct_counts[candidate_rule] <span style=color:#f92672>+</span>
            incorrect_counts[candidate_rule]) <span style=color:#66d9ef>for</span> candidate_rule <span style=color:#f92672>in</span> rule_confidence}
    <span style=color:#66d9ef>for</span> index <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>5</span>):
        print(<span style=color:#e6db74>&#34;Rule #</span><span style=color:#e6db74>{0}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(index <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>))
        (premise, conclusion) <span style=color:#f92672>=</span> sorted_confidence[index][<span style=color:#ae81ff>0</span>]
        premise_names <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;, &#34;</span><span style=color:#f92672>.</span>join(get_movie_name(idx) <span style=color:#66d9ef>for</span> idx <span style=color:#f92672>in</span> premise)
        conclusion_name <span style=color:#f92672>=</span> get_movie_name(conclusion)
        print(
            <span style=color:#e6db74>&#39;Rule: if a person recommends </span><span style=color:#e6db74>{0}</span><span style=color:#e6db74> they will also recommend </span><span style=color:#e6db74>{1}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(
                premise_names,
                conclusion_name))
        print(
            <span style=color:#e6db74>&#39; - Confidence: </span><span style=color:#e6db74>{0:.3f}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(rule_confidence[(premise, conclusion)]))
        print(<span style=color:#e6db74>&#34;--------------------&#34;</span>)
</code></pre></div><p>Output:</p>
<pre><code>Rule #1
Rule: if a person recommends Silence of the Lambs, The (1991), Return of the Jedi (1983) they will also recommend Star Wars (1977)
- Confidence: 1.000
--------------------
Rule #2
Rule: if a person recommends Empire Strikes Back, The (1980), Fugitive, The (1993) they will also recommend Raiders of the Lost Ark (1981)
- Confidence: 1.000
--------------------
Rule #3
Rule: if a person recommends Contact (1997), Empire Strikes Back, The (1980) they will also recommend Raiders of the Lost Ark (1981)
- Confidence: 1.000
--------------------
Rule #4
Rule: if a person recommends Toy Story (1995), Return of the Jedi (1983), Twelve Monkeys (1995) they will also recommend Star Wars (1977)
- Confidence: 1.000
--------------------
Rule #5
Rule: if a person recommends Toy Story (1995), Empire Strikes Back, The (1980), Twelve Monkeys (1995) they will also recommend Raiders of the Lost Ark (1981)
- Confidence: 1.000
--------------------
</code></pre>
<p>这一章用电影进行亲和度分析，由于元素的数量变多了，时间复杂度呈指数级增长，遍历的笨方法已经不适用。需要寻找更加巧妙地解决方案。</p>
<p>在用集合计算电影的项集时，<code>{1, 2}</code> 与 <code>{2, 1}</code> 是同一个事件，但在遍历的时候会被多次计算，可能这是一个错误的点。</p>
<h2 id=第五章>第五章</h2>
<p>本章讨论如何从数据集中抽取数值和类别型特征，并选出最佳特征。还会介绍特征抽取的常用模式和技巧。</p>
<h3 id=特征抽取>特征抽取</h3>
<p>把实体用特征表示出来，通过特征建模，再通过机器挖掘算法能够理解的近似方式来表示现实。</p>
<p>特征可以是数值型或类别型。数值特征可以离散化生成类别特征。</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
<span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd

<span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;__main__&#39;</span>:
    adult <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_csv(<span style=color:#e6db74>&#34;adult.data&#34;</span>, header<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>, names<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;Age&#34;</span>, <span style=color:#e6db74>&#34;Work-Class&#34;</span>, <span style=color:#e6db74>&#34;fnlwgt&#34;</span>, <span style=color:#e6db74>&#34;Education&#34;</span>,
                                                          <span style=color:#e6db74>&#34;Education-Num&#34;</span>, <span style=color:#e6db74>&#34;Marital-Status&#34;</span>, <span style=color:#e6db74>&#34;Occupation&#34;</span>,
                                                          <span style=color:#e6db74>&#34;Relationship&#34;</span>, <span style=color:#e6db74>&#34;Race&#34;</span>, <span style=color:#e6db74>&#34;Sex&#34;</span>, <span style=color:#e6db74>&#34;Capital-gain&#34;</span>,
                                                          <span style=color:#e6db74>&#34;Capital-loss&#34;</span>, <span style=color:#e6db74>&#34;Hours-per-week&#34;</span>, <span style=color:#e6db74>&#34;Native-Country&#34;</span>,
                                                          <span style=color:#e6db74>&#34;Earnings-Raw&#34;</span>])
    <span style=color:#75715e># 去除空值</span>
    adult<span style=color:#f92672>.</span>dropna(how<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;all&#39;</span>, inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
    <span style=color:#75715e># 输出详细描述</span>
    print(adult[<span style=color:#e6db74>&#34;Hours-per-week&#34;</span>]<span style=color:#f92672>.</span>describe())
    <span style=color:#75715e># 输出中位数</span>
    print(adult[<span style=color:#e6db74>&#34;Education-Num&#34;</span>]<span style=color:#f92672>.</span>median())
    <span style=color:#75715e># 输出工作的种类</span>
    print(adult[<span style=color:#e6db74>&#34;Work-Class&#34;</span>]<span style=color:#f92672>.</span>unique())
    <span style=color:#75715e># 将工作时长二值化为是否超过40h</span>
    adult[<span style=color:#e6db74>&#34;LongHours&#34;</span>] <span style=color:#f92672>=</span> adult[<span style=color:#e6db74>&#34;Hours-per-week&#34;</span>] <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>40</span>
</code></pre></div><p>Output:</p>
<pre><code>count    32561.000000
mean        40.437456
std         12.347429
min          1.000000
25%         40.000000
50%         40.000000
75%         45.000000
max         99.000000
Name: Hours-per-week, dtype: float64
10.0
[' State-gov' ' Self-emp-not-inc' ' Private' ' Federal-gov' ' Local-gov'
' ?' ' Self-emp-inc' ' Without-pay' ' Never-worked']
</code></pre>
<h3 id=特征选择>特征选择</h3>
<p>实物的特征有很多，我们只选择其中一小部分。</p>
<ul>
<li>降低复杂度，提高算法运行速度</li>
<li>减低噪音，增加无关的特征会干扰算法的工作</li>
<li>增加模型可读性，特征较少，人们易于理解</li>
</ul>
<p>拿到数据后，先进行简单直接的分析，了解数据的特点。</p>
<p><code>sklearn.feature_selection.VarianceThreshold</code> 转换器可以用来删除特征值的方差达不到最低标准的特征。</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># 构造测试数据集</span>
    X <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>arange(<span style=color:#ae81ff>30</span>)<span style=color:#f92672>.</span>reshape((<span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>3</span>))
    X[:, <span style=color:#ae81ff>1</span>] <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
    print(X)
    print(<span style=color:#e6db74>&#34;----------------&#34;</span>)
    vt <span style=color:#f92672>=</span> VarianceThreshold()
    Xt <span style=color:#f92672>=</span> vt<span style=color:#f92672>.</span>fit_transform(X)
    <span style=color:#75715e># 第二列消失了，因为第二列都是1，方差为0，不包括具有区别意义的信息</span>
    print(Xt)
    print(<span style=color:#e6db74>&#34;----------------&#34;</span>)
    print(vt<span style=color:#f92672>.</span>variances_)
</code></pre></div><p>Output:</p>
<pre><code>[[ 0  1  2]
[ 3  1  5]
[ 6  1  8]
[ 9  1 11]
[12  1 14]
[15  1 17]
[18  1 20]
[21  1 23]
[24  1 26]
[27  1 29]]
----------------
[[ 0  2]
[ 3  5]
[ 6  8]
[ 9 11]
[12 14]
[15 17]
[18 20]
[21 23]
[24 26]
[27 29]]
----------------
[27.  0. 27.]
</code></pre>
<hr>
<p>选择最佳特征</p>
<p>随着特征数量的增加，寻找最佳特征组合的任务复杂度呈指数级增长。分类任务通常的做法是寻找表现好的单个特征，依据是他们能达到的精确度。</p>
<p>scikit-learn 提供了几个用于选择单变量特征的转换器。</p>
<ul>
<li>SelectKBest 返回 k 个最佳特征</li>
<li>SelectPercentile 返回表现最佳的 r%个特征</li>
</ul>
<p>这两个转换器都提供计算特征表现的一系列方法。</p>
<p>单个特征和某一类别之间的相关性计算方法有卡方检验(x²)、互信息和信息熵等。</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># 构造数据集</span>
    X <span style=color:#f92672>=</span> adult[[<span style=color:#e6db74>&#34;Age&#34;</span>,
               <span style=color:#e6db74>&#34;Education-Num&#34;</span>,
               <span style=color:#e6db74>&#34;Capital-gain&#34;</span>,
               <span style=color:#e6db74>&#34;Capital-loss&#34;</span>,
               <span style=color:#e6db74>&#34;Hours-per-week&#34;</span>]]
    y <span style=color:#f92672>=</span> (adult[<span style=color:#e6db74>&#34;Earnings-Raw&#34;</span>] <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39; &gt;50K&#39;</span>)<span style=color:#f92672>.</span>values
    <span style=color:#75715e># 使用SelectKBest转换器，用卡方打分</span>
    transformer <span style=color:#f92672>=</span> SelectKBest(score_func<span style=color:#f92672>=</span>chi2, k<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>)
    <span style=color:#75715e># 调用fit_transform方法对相同的数据集进行预处理和转换</span>
    Xt_chi2 <span style=color:#f92672>=</span> transformer<span style=color:#f92672>.</span>fit_transform(X, y)
    <span style=color:#75715e># 输出每个特征的得分</span>
    print(transformer<span style=color:#f92672>.</span>scores_)
    print(<span style=color:#e6db74>&#34;----------------&#34;</span>)

    <span style=color:#75715e># 用皮尔逊相关系数计算相关性,创建包装函数</span>
    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>mutivariate_pearsonr</span>(X, y):
        scores, pvalues <span style=color:#f92672>=</span> [], []
        <span style=color:#66d9ef>for</span> column <span style=color:#f92672>in</span> range(X<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>1</span>]):
            cur_score, cur_p <span style=color:#f92672>=</span> pearsonr(X[:, column], y)
            scores<span style=color:#f92672>.</span>append(abs(cur_score))
            pvalues<span style=color:#f92672>.</span>append(cur_p)
        <span style=color:#66d9ef>return</span> np<span style=color:#f92672>.</span>array(scores), np<span style=color:#f92672>.</span>array(pvalues)

    transformer <span style=color:#f92672>=</span> SelectKBest(score_func<span style=color:#f92672>=</span>mutivariate_pearsonr, k<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>)
    Xt_pearson <span style=color:#f92672>=</span> transformer<span style=color:#f92672>.</span>fit_transform(X, y)
    print(transformer<span style=color:#f92672>.</span>scores_)
    print(<span style=color:#e6db74>&#34;----------------&#34;</span>)

    clf <span style=color:#f92672>=</span> DecisionTreeClassifier(random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>14</span>)
    scores_chi2 <span style=color:#f92672>=</span> cross_val_score(clf, Xt_chi2, y, scoring<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;accuracy&#39;</span>)
    scores_pearson <span style=color:#f92672>=</span> cross_val_score(clf, Xt_pearson, y, scoring<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;accuracy&#39;</span>)
    print(<span style=color:#e6db74>&#39;卡方: </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(np<span style=color:#f92672>.</span>mean(scores_chi2)))
    print(<span style=color:#e6db74>&#34;----------------&#34;</span>)
    print(<span style=color:#e6db74>&#34;pearson:  </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(np<span style=color:#f92672>.</span>mean(scores_pearson)))
</code></pre></div><p>Output:</p>
<pre><code>[8.60061182e+03 2.40142178e+03 8.21924671e+07 1.37214589e+06 6.47640900e+03]
----------------
[0.2340371  0.33515395 0.22332882 0.15052631 0.22968907]
----------------
卡方: 0.8291514400795839
----------------
pearson:  0.7721507467016449
</code></pre>
<h3 id=创建特征>创建特征</h3>
<p>特征之间相关性很强，或者特征冗余，会增加算法处理难度。</p>
<p>这里在加载 ad 数据集之前先创建了一个转换器，用于在加载时转换数据集中的值。</p>
<p>源码运行会产生报错，第一个原因是，用函数初始化转换器并没有把函数名传入，因此将 defaultdict 中每一个索引都进行了初始化。第二个原因是，PCA 转换器无法对 NaN 数据进行处理，于是我在处生成数据集之前将所有含有 NaN 的行删掉。</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># -*- coding: utf-8 -*-</span>
<span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
<span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
<span style=color:#f92672>from</span> collections <span style=color:#f92672>import</span> defaultdict
<span style=color:#f92672>from</span> sklearn.decomposition <span style=color:#f92672>import</span> PCA
<span style=color:#f92672>from</span> sklearn.tree <span style=color:#f92672>import</span> DecisionTreeClassifier
<span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> cross_val_score
<span style=color:#f92672>from</span> matplotlib <span style=color:#f92672>import</span> pyplot <span style=color:#66d9ef>as</span> plt


<span style=color:#75715e># 创建转换函数</span>
<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>convert_number</span>(x):
    <span style=color:#66d9ef>try</span>:
        res <span style=color:#f92672>=</span> float(x)
        <span style=color:#66d9ef>return</span> res
    <span style=color:#66d9ef>except</span> <span style=color:#a6e22e>ValueError</span>:
        <span style=color:#66d9ef>return</span> np<span style=color:#f92672>.</span>nan


<span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;__main__&#39;</span>:
    <span style=color:#75715e># 创建数据加载的转换器</span>
    converters <span style=color:#f92672>=</span> defaultdict(convert_number, {i: convert_number <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>1588</span>)})
    converters[<span style=color:#ae81ff>1558</span>] <span style=color:#f92672>=</span> <span style=color:#66d9ef>lambda</span> x: <span style=color:#ae81ff>1</span> <span style=color:#66d9ef>if</span> x<span style=color:#f92672>.</span>strip() <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;ad.&#34;</span> <span style=color:#66d9ef>else</span> <span style=color:#ae81ff>0</span>
    <span style=color:#75715e># 使用转换器读取数据集</span>
    temp <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_csv(<span style=color:#e6db74>&#34;ad.data&#34;</span>, header<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>, converters<span style=color:#f92672>=</span>converters)
    <span style=color:#75715e># 删除所有含有nan的行,axis=0是数据索引(index)，axis=1是列标签(column)</span>
    ads <span style=color:#f92672>=</span> temp<span style=color:#f92672>.</span>dropna(axis<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>, how<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;any&#39;</span>)
    print(ads[<span style=color:#ae81ff>10</span>:<span style=color:#ae81ff>15</span>])
</code></pre></div><p>Output:</p>
<pre><code>       0      1       2     3     4     5  ...  1553  1554  1555  1556  1557  1558
11  90.0   52.0  0.5777   1.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0     1
12  90.0   60.0  0.6666   1.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0     1
13  90.0   60.0  0.6666   1.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0     1
14  33.0  230.0  6.9696   1.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0     1
15  60.0  468.0  7.8000   1.0   0.0   0.0  ...   0.0   1.0   1.0   0.0   0.0     1
[5 rows x 1559 columns]
</code></pre>
<hr>
<p>主成分分析(PCA)</p>
<p>目的是找到能用较少信息描述数据集的特征组合。主成分的方差跟整体方差没有多大差距。经过分析主成分，第一个特征的方差对数据集方差的贡献率为 85.4%，第二个为 14.5%，后面越来越少。</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    X <span style=color:#f92672>=</span> ads<span style=color:#f92672>.</span>drop(<span style=color:#ae81ff>1558</span>, axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)<span style=color:#f92672>.</span>values
    y <span style=color:#f92672>=</span> ads[<span style=color:#ae81ff>1558</span>]
    <span style=color:#75715e># 参数为主成分数量</span>
    pca <span style=color:#f92672>=</span> PCA(n_components<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>)
    Xd <span style=color:#f92672>=</span> pca<span style=color:#f92672>.</span>fit_transform(X)
    <span style=color:#75715e># 设置输出选项</span>
    <span style=color:#75715e># 第一个参数为输出精度位数，第二个参数是使用定点表示法打印浮点数</span>
    np<span style=color:#f92672>.</span>set_printoptions(precision<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, suppress<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
    print(pca<span style=color:#f92672>.</span>explained_variance_ratio_)
</code></pre></div><p>Output:</p>
<pre><code>[0.854 0.145 0.001 0.    0.   ]
</code></pre>
<hr>
<p>使用随机森林验证模型正确率，并将 pca 转换结果绘制出来。</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    clf <span style=color:#f92672>=</span> DecisionTreeClassifier(random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>14</span>)
    scores_reduced <span style=color:#f92672>=</span> cross_val_score(clf, Xd, y, scoring<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;accuracy&#39;</span>)
    print(np<span style=color:#f92672>.</span>mean(scores_reduced))

    <span style=color:#75715e># 获取数据集类别的所有取值</span>
    classes <span style=color:#f92672>=</span> set(y)
    <span style=color:#75715e># 指定在图形中用什么颜色表示这两个类别</span>
    colors <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;red&#39;</span>, <span style=color:#e6db74>&#39;green&#39;</span>]
    <span style=color:#75715e># 同时遍历这两个容器</span>
    <span style=color:#66d9ef>for</span> cur_class, color <span style=color:#f92672>in</span> zip(classes, colors):
        <span style=color:#75715e># 为属于当前类别的所有个体创建遮罩层</span>
        mask <span style=color:#f92672>=</span> (y <span style=color:#f92672>==</span> cur_class)<span style=color:#f92672>.</span>values
        plt<span style=color:#f92672>.</span>scatter(Xd[mask, <span style=color:#ae81ff>0</span>], Xd[mask, <span style=color:#ae81ff>1</span>], marker<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;o&#39;</span>,
                    color<span style=color:#f92672>=</span>color, label<span style=color:#f92672>=</span>int(cur_class))
    plt<span style=color:#f92672>.</span>legend()
    plt<span style=color:#f92672>.</span>show()
</code></pre></div><p>Output:</p>
<pre><code>0.936405592140775
</code></pre>
<p><figure>
<a href=/img/in-post/data-mining/ch5/pca.png>
<img src=/img/in-post/data-mining/ch5/pca.png loading=lazy alt=pca>
</a>
<figcaption>pca</figcaption>
</figure></p>
<h3 id=创建自己的转换器>创建自己的转换器</h3>
<p>转换器有两个关键函数</p>
<ul>
<li><code>fit()</code> 接收训练数据，设置内部参数</li>
<li><code>transform()</code> 转换过程。接收训练数据集或相同格式的新数据集</li>
</ul>
<p>接口要与 scikit-learn 接口一致，便于在流水线中使用。</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># -*- coding: utf-8 -*-</span>
<span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
<span style=color:#f92672>from</span> sklearn.base <span style=color:#f92672>import</span> TransformerMixin
<span style=color:#f92672>from</span> sklearn.utils <span style=color:#f92672>import</span> as_float_array
<span style=color:#f92672>from</span> numpy.testing <span style=color:#f92672>import</span> assert_array_equal


<span style=color:#66d9ef>class</span> <span style=color:#a6e22e>MeanDiscrete</span>(TransformerMixin):
    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>fit</span>(self, X):
        <span style=color:#75715e># 尝试对X进行转换，数据转换成float类型</span>
        X <span style=color:#f92672>=</span> as_float_array(X)
        <span style=color:#75715e># 计算数据集的均值</span>
        self<span style=color:#f92672>.</span>mean <span style=color:#f92672>=</span> X<span style=color:#f92672>.</span>mean(axis<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
        <span style=color:#75715e># 返回它本身，进行链式调用transformer.fit(X).transform(X)</span>
        <span style=color:#66d9ef>return</span> self

    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>transform</span>(self, X):
        X <span style=color:#f92672>=</span> as_float_array(X)
        <span style=color:#75715e># 检查输入是否合法</span>
        <span style=color:#66d9ef>assert</span> X<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>1</span>] <span style=color:#f92672>==</span> self<span style=color:#f92672>.</span>mean<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>]
        <span style=color:#75715e># 返回X中大于均值的数据</span>
        <span style=color:#66d9ef>return</span> X <span style=color:#f92672>&gt;</span> self<span style=color:#f92672>.</span>mean


<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>test_meandiscrete</span>():
    X_test <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>2</span>], [<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>5</span>], [<span style=color:#ae81ff>6</span>, <span style=color:#ae81ff>8</span>], [<span style=color:#ae81ff>9</span>, <span style=color:#ae81ff>11</span>], [<span style=color:#ae81ff>12</span>, <span style=color:#ae81ff>14</span>], [<span style=color:#ae81ff>15</span>, <span style=color:#ae81ff>17</span>], [<span style=color:#ae81ff>18</span>, <span style=color:#ae81ff>20</span>], [<span style=color:#ae81ff>21</span>, <span style=color:#ae81ff>23</span>], [<span style=color:#ae81ff>24</span>, <span style=color:#ae81ff>26</span>], [<span style=color:#ae81ff>27</span>, <span style=color:#ae81ff>29</span>]])
    mean_discrete <span style=color:#f92672>=</span> MeanDiscrete()
    mean_discrete<span style=color:#f92672>.</span>fit(X_test)
    <span style=color:#75715e># 与正确的计算结果进行比较，检查内部参数是否正确设置</span>
    assert_array_equal(mean_discrete<span style=color:#f92672>.</span>mean, np<span style=color:#f92672>.</span>array([<span style=color:#ae81ff>13.5</span>, <span style=color:#ae81ff>15.5</span>]))
    <span style=color:#75715e># 转换后的X</span>
    X_transfromed <span style=color:#f92672>=</span> mean_discrete<span style=color:#f92672>.</span>transform(X_test)
    <span style=color:#75715e># 验证数据</span>
    X_expected <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>], [<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>], [<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>], [<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>], [<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>], [<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>], [<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>], [<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>], [<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>], [<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>]])
    assert_array_equal(X_transfromed, X_expected)


<span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;__main__&#39;</span>:
    test_meandiscrete()
</code></pre></div><p>Output:</p>
<pre><code># 没有输出，说明测试通过
</code></pre>
<h2 id=第六章>第六章</h2>
<p>本章介绍如何从文本数据中提取特征。通过强大却简单的朴素贝叶斯算法消除社会媒体用语的歧义。</p>
<p>朴素贝叶斯算法在计算用于分类的概率时，为了简化计算，假定各特征间是相互独立的，因此名字中含有<em>朴素</em>二字。</p>
<h3 id=消歧>消歧</h3>
<p>由于无法申请到 Twitter app 暂时搁置。。。%>_&lt;%</p>
<h3 id=文本转换器>文本转换器</h3>
<p>词袋：一种最简单却非常有效的模型就是只统计数据集中每个单词的出现次数。模型主要分为以下三种</p>
<ul>
<li>使用词语实际出现的次数作为词频。缺点是当文章长度明显差异时，词频差距会非常大。</li>
<li>使用归一化后的词频，每篇文章中所有词语的词频之和为 1</li>
<li>直接使用二值特征来表示，单词在文档中出现值为 1，不出现值为 0</li>
</ul>
<p>还有一种更通用的规范化方法叫做<em>词频-逆文档频率法</em>，该加权方法用词频来代替词的出现次数，然后再用词频除以包含该词的文档的数量。</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># -*- coding: utf-8 -*-</span>
<span style=color:#f92672>from</span> collections <span style=color:#f92672>import</span> Counter

<span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;__main__&#39;</span>:
    s <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;&#34;&#34;Three Rings for the Elven-kings under the sky,
</span><span style=color:#e6db74>Seven for the Dwarf-lords in halls of stone,
</span><span style=color:#e6db74>Nine for Mortal Men, doomed to die,
</span><span style=color:#e6db74>One for the Dark Lord on his dark throne
</span><span style=color:#e6db74>In the Land of Mordor where the Shadows lie.
</span><span style=color:#e6db74>One Ring to rule them all, One Ring to find them,
</span><span style=color:#e6db74>One Ring to bring them all and in the darkness bind them.
</span><span style=color:#e6db74>In the Land of Mordor where the Shadows lie&#34;&#34;&#34;</span><span style=color:#f92672>.</span>lower()
    words <span style=color:#f92672>=</span> s<span style=color:#f92672>.</span>split()
    c <span style=color:#f92672>=</span> Counter(words)
    <span style=color:#75715e># 输出出现次数最多的前5个词</span>
    print(c<span style=color:#f92672>.</span>most_common(<span style=color:#ae81ff>5</span>))
</code></pre></div><p>Output:</p>
<pre><code>[('the', 9), ('for', 4), ('in', 4), ('to', 4), ('one', 4)]
</code></pre>
<hr>
<p>N 元语法是指由几个连续的词组成的子序列。</p>
<h3 id=朴素贝叶斯>朴素贝叶斯</h3>
<p>我们用 C 表示某种类别，用 D 表示数据集中一篇文档，来计算贝叶斯公式所要用到的各种统计量，对于不好计算，出朴素假设，简化计算。朴素贝叶斯分类算法使用贝叶斯定理计算个体从属于某一类别的概率。</p>
<p><code>P(C)</code> 为某一类别的概率，可以从训练集中计算得到（方法跟上文检测垃圾邮件例子所用到的一致）。统计训练集所有文档从属于给定类别的百分比。</p>
<p><code>P(D)</code> 为某一文档的概率，它牵扯到各种特征，计算起来很困难，但是在计算文档属于哪个类别时，对于所有类别来说，P(D)相同，因此根本就不用计算它。稍后我们来看下怎么处理。</p>
<p><code>P(D|C)</code> 为文档 D 属于 C 类的概率。由于 D 包含多个特征，计算起来可能很困难，这时朴素贝叶斯算法就派上用场了。我们朴素地假定各个特征之间是相互独立的，分别计算每个特征（D1、D2、D3 等）在给定类别出现的概率，再求它们的积。</p>
<p><code>P(D|C) = P(D1|C) x P(D2|C) ... x P(Dn|C)</code></p>
<p>举例说明下计算过程，假如数据集中有以下一条用二值特征表示的数据：[1, 0, 0, 1]</p>
<p>训练集中有 75% 的数据属于类别 0， 25% 属于类别 1，且每个特征属于每个类别的似然度如下。</p>
<ul>
<li>类别 0：[0.3, 0.4, 0.4, 0.7]</li>
<li>类别 1：[0.7, 0.3, 0.4, 0.9]</li>
</ul>
<p>拿类别 0 中特征 1 的似然度举例子，上面这两行数据可以这样理解：类别 0 中有 30%的数据，特征 1 的值为 1。</p>
<p>我们来计算一下这条数据属于类别 0 的概率。类别为 0 时，P(C=0) = 0.75。</p>
<p>朴素贝叶斯算法用不到 P(D)，因此我们不用计算它。</p>
<p>P(D|C=0) = P(D1|C=0) x P(D2|C=0) x P(D3|C=0) x P(D4|C=0)
= 0.3 x 0.6 x 0.6 x 0.7
= 0.0756</p>
<p>我们就可以计算该条数据从属于每个类别的概率。我们没有计算 P(D)，因此，计算结果不是实际的概率。由于两次都不计算 P(D)，结果具有可比较性，能够区分出大小就足够了。来看下计算结果。</p>
<p>P(C=0|D) = P(C=0) P(D|C=0)
= 0.75 * 0.0756
= 0.0567</p>
<p>P(D|C=1) = P(D1|C=1) x P(D2|C=1) x P(D3|C=1) x P(D4|C=1)
= 0.7 x 0.7 x 0.6 x 0.9
= 0.2646</p>
<p>P(C=1|D) = P(C=1)P(D|C=1)
= 0.25 * 0.2646
= 0.06615</p>
<p>因此这条数据属于类别 1 的概率大于属于类别 2 的概率</p>
<h3 id=应用>应用</h3>
<p>创建流水线，接收一条消息，仅根据消息内容，确定它与编程语言 Python 是否相关。</p>
<ul>
<li>用 NLTK 的 word_tokenize 函数，将原始文档转换为由单词及其是否出现组成的字典。</li>
<li>用 scikit-learn 中的 DictVectorizer 转换器将字典转换为向量矩阵，这样朴素贝叶斯分类器就能使用第一步中抽取的特征。</li>
<li>正如前几章做过的那样，训练朴素贝叶斯分类器。</li>
<li>还需要新建一个笔记本文件 ch6_classify_twitter（本章最后一个），用于分类。</li>
</ul>
<p>F1 值来评估算法</p>
<p>F1 值是以每个类别为基础进行定义的，包括两大概念：准确率（precision）和召回率（recall）。准确率是指预测结果属于某一类的个体，实际属于该类的比例。召回率是指被正确预测为某个类别的个体数量与数据集中该类别个体总量的比例</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># -*- coding: utf-8 -*-</span>
<span style=color:#f92672>import</span> json
<span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
<span style=color:#f92672>from</span> sklearn.base <span style=color:#f92672>import</span> TransformerMixin
<span style=color:#f92672>from</span> nltk <span style=color:#f92672>import</span> word_tokenize
<span style=color:#f92672>from</span> sklearn.feature_extraction <span style=color:#f92672>import</span> DictVectorizer  <span style=color:#75715e># 接受元素为字典的列表，将其转换为矩阵</span>
<span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> cross_val_score
<span style=color:#f92672>from</span> sklearn.naive_bayes <span style=color:#f92672>import</span> BernoulliNB  <span style=color:#75715e># 用于二值特征分类的 BernoulliNB 分类器，</span>
<span style=color:#f92672>from</span> sklearn.pipeline <span style=color:#f92672>import</span> Pipeline


<span style=color:#75715e># 创建转换器类</span>
<span style=color:#66d9ef>class</span> <span style=color:#a6e22e>NLTKBOW</span>(TransformerMixin):
    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>fit</span>(self, X, y<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>):
        <span style=color:#66d9ef>return</span> self

    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>transform</span>(self, X):
        <span style=color:#66d9ef>return</span> [{word: <span style=color:#66d9ef>True</span> <span style=color:#66d9ef>for</span> word <span style=color:#f92672>in</span> word_tokenize(document)} <span style=color:#66d9ef>for</span> document <span style=color:#f92672>in</span> X]


<span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;__main__&#39;</span>:
    tweets <span style=color:#f92672>=</span> []
    input_filename <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;&#34;</span>
    classes_filename <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;&#34;</span>
    <span style=color:#66d9ef>with</span> open(input_filename) <span style=color:#66d9ef>as</span> inf:
        <span style=color:#66d9ef>for</span> line <span style=color:#f92672>in</span> inf:
            <span style=color:#66d9ef>if</span> len(line<span style=color:#f92672>.</span>strip()) <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>:
                <span style=color:#66d9ef>continue</span>
            tweets<span style=color:#f92672>.</span>append(json<span style=color:#f92672>.</span>loads(line)[<span style=color:#e6db74>&#39;text&#39;</span>])

    <span style=color:#66d9ef>with</span> open(classes_filename, <span style=color:#e6db74>&#39;r&#39;</span>) <span style=color:#66d9ef>as</span> inf:
        labels <span style=color:#f92672>=</span> json<span style=color:#f92672>.</span>load(inf)

    <span style=color:#75715e># 组装流水线</span>
    pipline <span style=color:#f92672>=</span> Pipeline([(<span style=color:#e6db74>&#39;bag-of-words&#39;</span>, NLTKBOW()), (<span style=color:#e6db74>&#39;vectorizer&#39;</span>, DictVectorizer()), (<span style=color:#e6db74>&#39;naive-bayes&#39;</span>, BernoulliNB())])
    <span style=color:#75715e># 用F1值来评估</span>
    scores <span style=color:#f92672>=</span> cross_val_score(pipline, tweets, labels, scoring<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;f1&#39;</span>)
    print(<span style=color:#e6db74>&#34;Score: </span><span style=color:#e6db74>{:.3f}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(np<span style=color:#f92672>.</span>mean(scores)))

    model <span style=color:#f92672>=</span> pipline<span style=color:#f92672>.</span>fit(tweets, labels)
    nb <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>named_steps[<span style=color:#e6db74>&#39;naive-bayes&#39;</span>]
    feature_probabilities <span style=color:#f92672>=</span> nb<span style=color:#f92672>.</span>feature_log_prob_
    top_features <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>argsort(<span style=color:#f92672>-</span>feature_probabilities[<span style=color:#ae81ff>1</span>])[:<span style=color:#ae81ff>50</span>]
    dv <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>named_steps[<span style=color:#e6db74>&#39;vectorizer&#39;</span>]
    <span style=color:#66d9ef>for</span> i, feature_index <span style=color:#f92672>in</span> enumerate(top_features):
        print(i, dv<span style=color:#f92672>.</span>feature_names_[feature_index], np<span style=color:#f92672>.</span>exp(feature_probabilities[<span style=color:#ae81ff>1</span>][feature_index]))
</code></pre></div><p>Output:</p>
<pre><code>暂时没有数据集
</code></pre>
<h2 id=第七章>第七章</h2>
<p>本章介绍的算法引入聚类分析概念&ndash;根据相似度，把大数据集划分为几个子集。</p>
<h3 id=加载数据集-1>加载数据集</h3>
<p>由于申请不到 Twitter 开发者账号，我想办法爬了一些 b 站用户关注数据，做成了本次试验相仿的形式</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># -*- coding: utf-8 -*-</span>
<span style=color:#f92672>import</span> json
<span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
<span style=color:#f92672>import</span> networkx <span style=color:#66d9ef>as</span> nx
<span style=color:#f92672>from</span> matplotlib <span style=color:#f92672>import</span> pyplot <span style=color:#66d9ef>as</span> plt
<span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
<span style=color:#f92672>from</span> scipy.optimize <span style=color:#f92672>import</span> minimize
<span style=color:#f92672>from</span> sklearn.metrics <span style=color:#f92672>import</span> silhouette_score

<span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;__main__&#39;</span>:
    <span style=color:#66d9ef>with</span> open(<span style=color:#e6db74>&#39;bili.txt&#39;</span>, mode<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;r&#39;</span>) <span style=color:#66d9ef>as</span> fin:
        temp <span style=color:#f92672>=</span> json<span style=color:#f92672>.</span>load(fin)
    users <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>DataFrame(temp)
    users<span style=color:#f92672>.</span>columns <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;Id&#39;</span>, <span style=color:#e6db74>&#39;Friends&#39;</span>]
    print(users[:<span style=color:#ae81ff>5</span>])
</code></pre></div><p>Output:</p>
<pre><code>        Id                                            Friends
0  214582845  [4370617, 259345180, 186334806, 546195, 477132...
1    4370617                    [74507, 883968, 122879, 585267]
2  259345180                                                 []
3  186334806                                                 []
4     546195                                                 []
</code></pre>
<hr>
<p>将每个记录的用户左右 main_users，把他们关注的人作为边，生成有向图</p>
<p>由于对 matplotlib 库和 networkx 库了解太少，在作图时遇到了许多困难（根基不牢，地动山摇。(>_&lt;)）</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    G <span style=color:#f92672>=</span> nx<span style=color:#f92672>.</span>DiGraph()
    main_users <span style=color:#f92672>=</span> list(users[<span style=color:#e6db74>&#39;Id&#39;</span>]<span style=color:#f92672>.</span>values)
    <span style=color:#66d9ef>for</span> u <span style=color:#f92672>in</span> main_users:
        G<span style=color:#f92672>.</span>add_node(u, label<span style=color:#f92672>=</span>u)
    <span style=color:#66d9ef>for</span> user <span style=color:#f92672>in</span> users<span style=color:#f92672>.</span>values:
        friends <span style=color:#f92672>=</span> user[<span style=color:#ae81ff>1</span>]
        <span style=color:#66d9ef>for</span> friend <span style=color:#f92672>in</span> friends:
            <span style=color:#66d9ef>if</span> friend <span style=color:#f92672>in</span> main_users:
                G<span style=color:#f92672>.</span>add_edge(user[<span style=color:#ae81ff>0</span>], int(friend))
    print(<span style=color:#e6db74>&#39;graph finished&#39;</span>)
    plt<span style=color:#f92672>.</span>figure(<span style=color:#ae81ff>3</span>, figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>100</span>, <span style=color:#ae81ff>100</span>))
    nx<span style=color:#f92672>.</span>draw(G, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.1</span>, edge_color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;b&#39;</span>, with_labels<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, font_size<span style=color:#f92672>=</span><span style=color:#ae81ff>16</span>, node_size<span style=color:#f92672>=</span><span style=color:#ae81ff>30</span>, node_color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;r&#39;</span>)
    plt<span style=color:#f92672>.</span>savefig(<span style=color:#e6db74>&#39;fix1.png&#39;</span>)
</code></pre></div><p>Output:</p>
<p><figure>
<a href=/img/in-post/data-mining/ch7/fix1.png>
<img src=/img/in-post/data-mining/ch7/fix1.png loading=lazy alt=fix1>
</a>
<figcaption>fix1</figcaption>
</figure></p>
<hr>
<p>创建用户相似度图</p>
<p>由于每个用户关注的人数可能相差很大，因此使用杰卡德相似系数（两个用户关注的集合的交集除以并集），该系数在 0 到 1 之间，代表两者重合的比例。</p>
<p>规范化是数据挖掘的一个重要方法，要坚持使用（除非有充足的理由不这样做）</p>
<p>访问<a class=link href=http://networkx.lanl.gov/reference/drawing/html target=_blank rel=noopener>http://networkx.lanl.gov/reference/drawing/html</a>了解 networkx 的布局方法</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    friends <span style=color:#f92672>=</span> {user: set(friends) <span style=color:#66d9ef>for</span> user, friends <span style=color:#f92672>in</span> users<span style=color:#f92672>.</span>values}

    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>compute_similarity</span>(friends1, friends2):
        <span style=color:#66d9ef>return</span> len(friends1 <span style=color:#f92672>&amp;</span> friends2) <span style=color:#f92672>/</span> len(friends1 <span style=color:#f92672>|</span> friends2)

    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>create_graph</span>(followers, threshold<span style=color:#f92672>=</span><span style=color:#ae81ff>0.0</span>):
        G <span style=color:#f92672>=</span> nx<span style=color:#f92672>.</span>Graph()
        <span style=color:#66d9ef>for</span> user1 <span style=color:#f92672>in</span> friends<span style=color:#f92672>.</span>keys():
            <span style=color:#66d9ef>if</span> len(friends[user1]) <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>:
                <span style=color:#66d9ef>continue</span>
            <span style=color:#66d9ef>for</span> user2 <span style=color:#f92672>in</span> friends<span style=color:#f92672>.</span>keys():
                <span style=color:#66d9ef>if</span> len(friends[user2]) <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>:
                    <span style=color:#66d9ef>continue</span>
                <span style=color:#66d9ef>if</span> user1 <span style=color:#f92672>==</span> user2:
                    <span style=color:#66d9ef>continue</span>
                weight <span style=color:#f92672>=</span> compute_similarity(friends[user1], friends[user2])
                <span style=color:#66d9ef>if</span> weight <span style=color:#f92672>&gt;=</span> threshold:
                    G<span style=color:#f92672>.</span>add_node(user1, lable<span style=color:#f92672>=</span>user1)
                    G<span style=color:#f92672>.</span>add_node(user2, lable<span style=color:#f92672>=</span>user2)
                    G<span style=color:#f92672>.</span>add_edge(user1, user2, weight<span style=color:#f92672>=</span>weight)
        <span style=color:#66d9ef>return</span> G

    G <span style=color:#f92672>=</span> create_graph(friends)
    plt<span style=color:#f92672>.</span>figure(<span style=color:#ae81ff>3</span>, figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>100</span>, <span style=color:#ae81ff>100</span>))
    pos <span style=color:#f92672>=</span> nx<span style=color:#f92672>.</span>spring_layout(G)
    nx<span style=color:#f92672>.</span>draw_networkx_nodes(G, pos, node_size<span style=color:#f92672>=</span><span style=color:#ae81ff>30</span>)
    edgewidth <span style=color:#f92672>=</span> [d[<span style=color:#e6db74>&#39;weight&#39;</span>] <span style=color:#66d9ef>for</span> (u, v, d) <span style=color:#f92672>in</span> G<span style=color:#f92672>.</span>edges(data<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)]
    nx<span style=color:#f92672>.</span>draw_networkx_edges(G, pos, width<span style=color:#f92672>=</span>edgewidth)
    plt<span style=color:#f92672>.</span>savefig(<span style=color:#e6db74>&#39;fix2.png&#39;</span>)
</code></pre></div><p>Output:</p>
<p><figure>
<a href=/img/in-post/data-mining/ch7/fix2.png>
<img src=/img/in-post/data-mining/ch7/fix2.png loading=lazy alt=fix2>
</a>
<figcaption>fix2</figcaption>
</figure></p>
<h3 id=寻找子图>寻找子图</h3>
<p>networkx 的 <code>connected_component_subgraphs()</code> 函数在 2.1 版本中被移除了（代码过时的比较多，并且使用 Twitter 作为演示数据集让我这两章做的很头疼），我查看官方文档后发现可以使用 <code>connected_components()</code> 替代，但是此函数返回的是一个生成器，一次生成一组连通顶点，可以配合 G.subgraph(nodes) 使用获得连通分支</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># 生成新图，指定最低阈值为0.1</span>
    G <span style=color:#f92672>=</span> create_graph(friends, <span style=color:#ae81ff>0.1</span>)
    sub_graphs <span style=color:#f92672>=</span> nx<span style=color:#f92672>.</span>connected_components(G)
    <span style=color:#66d9ef>for</span> i, sub_graphs <span style=color:#f92672>in</span> enumerate(sub_graphs):
        n_nodes <span style=color:#f92672>=</span> len(sub_graphs)
        print(<span style=color:#e6db74>&#34;Subgraph</span><span style=color:#e6db74>{}</span><span style=color:#e6db74> has </span><span style=color:#e6db74>{}</span><span style=color:#e6db74> nodes&#34;</span><span style=color:#f92672>.</span>format(i, n_nodes))
    print(<span style=color:#e6db74>&#39;---------------------&#39;</span>)
    G <span style=color:#f92672>=</span> create_graph(friends, <span style=color:#ae81ff>0.15</span>)
    sub_graphs <span style=color:#f92672>=</span> nx<span style=color:#f92672>.</span>connected_components(G)
    <span style=color:#66d9ef>for</span> i, sub_graphs <span style=color:#f92672>in</span> enumerate(sub_graphs):
        n_nodes <span style=color:#f92672>=</span> len(sub_graphs)
        print(<span style=color:#e6db74>&#34;Subgraph</span><span style=color:#e6db74>{}</span><span style=color:#e6db74> has </span><span style=color:#e6db74>{}</span><span style=color:#e6db74> nodes&#34;</span><span style=color:#f92672>.</span>format(i, n_nodes))

    sub_graphs <span style=color:#f92672>=</span> [c <span style=color:#66d9ef>for</span> c <span style=color:#f92672>in</span> sorted(nx<span style=color:#f92672>.</span>connected_components(G), key<span style=color:#f92672>=</span>len, reverse<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)]
    n_subgraphs <span style=color:#f92672>=</span> nx<span style=color:#f92672>.</span>number_connected_components(G)
    fig <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>20</span>, (n_subgraphs<span style=color:#f92672>*</span><span style=color:#ae81ff>3</span>)))
    <span style=color:#66d9ef>for</span> i, sub_graph <span style=color:#f92672>in</span> enumerate(sub_graphs):
        <span style=color:#75715e># sub_graph是一个连通分支顶点的集合</span>
        ax <span style=color:#f92672>=</span> fig<span style=color:#f92672>.</span>add_subplot(int(n_subgraphs <span style=color:#f92672>/</span> <span style=color:#ae81ff>3</span>) <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>3</span>, i <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>)
        <span style=color:#75715e># 将坐标轴标签关掉</span>
        ax<span style=color:#f92672>.</span>get_xaxis()<span style=color:#f92672>.</span>set_visible(<span style=color:#66d9ef>False</span>)
        ax<span style=color:#f92672>.</span>get_yaxis()<span style=color:#f92672>.</span>set_visible(<span style=color:#66d9ef>False</span>)
        pos <span style=color:#f92672>=</span> nx<span style=color:#f92672>.</span>spring_layout(G)
        nx<span style=color:#f92672>.</span>draw(G<span style=color:#f92672>=</span>G<span style=color:#f92672>.</span>subgraph(sub_graph), alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.1</span>, edge_color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;b&#39;</span>, with_labels<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, font_size<span style=color:#f92672>=</span><span style=color:#ae81ff>16</span>, node_size<span style=color:#f92672>=</span><span style=color:#ae81ff>30</span>, node_color<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;r&#39;</span>, ax<span style=color:#f92672>=</span>ax)
    plt<span style=color:#f92672>.</span>show()
</code></pre></div><p>Output:</p>
<p><figure>
<a href=/img/in-post/data-mining/ch7/fix3.png>
<img src=/img/in-post/data-mining/ch7/fix3.png loading=lazy alt=fix3>
</a>
<figcaption>fix3</figcaption>
</figure></p>
<hr>
<p>轮廓系数定义： <code>s = (b - a) / max(a, b)</code></p>
<p>其中 a 为簇内距离，表示与簇内其它个体之间的平均距离。b 为簇间距离，也就是最近簇内各个个体之间的平均距离</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>compute_silhouette</span>(threshold, friends):
        G <span style=color:#f92672>=</span> create_graph(friends, threshold<span style=color:#f92672>=</span>threshold)\
        <span style=color:#75715e># 图是否至少有两个顶点</span>
        <span style=color:#66d9ef>if</span> len(G<span style=color:#f92672>.</span>nodes()) <span style=color:#f92672>&lt;</span> <span style=color:#ae81ff>2</span>:
            <span style=color:#75715e># 返回-99表示问题无效</span>
            <span style=color:#66d9ef>return</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>99</span>
        <span style=color:#75715e># 抽取连通分支</span>
        sub_graphs <span style=color:#f92672>=</span> nx<span style=color:#f92672>.</span>connected_components(G)
        <span style=color:#75715e># 至少有两个连通分支</span>
        <span style=color:#66d9ef>if</span> <span style=color:#f92672>not</span> (<span style=color:#ae81ff>2</span> <span style=color:#f92672>&lt;=</span> nx<span style=color:#f92672>.</span>number_connected_components(G) <span style=color:#f92672>&lt;</span> len(G<span style=color:#f92672>.</span>nodes()) <span style=color:#f92672>-</span> <span style=color:#ae81ff>1</span>):
            <span style=color:#66d9ef>return</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>99</span>
        label_dict <span style=color:#f92672>=</span> {}
        <span style=color:#66d9ef>for</span> i, sub_graph <span style=color:#f92672>in</span> enumerate(sub_graphs):
            <span style=color:#66d9ef>for</span> node <span style=color:#f92672>in</span> sub_graph:
                <span style=color:#75715e># 给不同连通分支的顶点分配不同的标签</span>
                label_dict[node] <span style=color:#f92672>=</span> i
        labels <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([label_dict[node] <span style=color:#66d9ef>for</span> node <span style=color:#f92672>in</span> G<span style=color:#f92672>.</span>nodes()])
        X <span style=color:#f92672>=</span> nx<span style=color:#f92672>.</span>to_scipy_sparse_matrix(G)<span style=color:#f92672>.</span>todense()
        <span style=color:#75715e># 这里要将相似度转换为距离，所以用最大相似度减去现有相似度，把相似度转化为距离</span>
        X <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span> <span style=color:#f92672>-</span> X
        <span style=color:#75715e># 这里将距离矩阵的对角线处理为0，因为自己到自己的距离为0</span>
        np<span style=color:#f92672>.</span>fill_diagonal(X, <span style=color:#ae81ff>0</span>)
        <span style=color:#66d9ef>return</span> silhouette_score(X, labels, metric<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;precomputed&#39;</span>)


    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>inverted_silhouette</span>(threshold, friends):
        <span style=color:#75715e># 对轮廓系数取反，将打分函数转化成损失函数</span>
        res <span style=color:#f92672>=</span> compute_silhouette(threshold, friends<span style=color:#f92672>=</span>friends)
        <span style=color:#66d9ef>return</span> <span style=color:#f92672>-</span> res
    <span style=color:#75715e># minimize函数是一个损失函数，值越小越好</span>
    <span style=color:#75715e># 参数：inverted_silhouette要寻找的函数；0.1开始时猜测的阈值；options={&#39;maxiter&#39;: 10} 只进行10轮迭代，增加迭代次数，效果可能更好，但运行时间会增加，method=&#39;nelder-mead&#39;使用&#34;下山单纯形法&#34;优化方法</span>
    result <span style=color:#f92672>=</span> minimize(inverted_silhouette, <span style=color:#ae81ff>0.1</span>, args<span style=color:#f92672>=</span>(friends,), options<span style=color:#f92672>=</span>{<span style=color:#e6db74>&#39;maxiter&#39;</span>: <span style=color:#ae81ff>10</span>})
    print(result<span style=color:#f92672>.</span>x)
</code></pre></div><p>Output:</p>
<pre><code>[0.10005086]
</code></pre>
<hr>
<p>本章探讨了社交网络和图以及如何对其进行聚类分析。目标是推荐用户，使用聚类分析方法能够找到不同的用户簇，主要步骤有根据相似度创建加权图，从图中寻找连通分支。创建图时用到了 NetworkX 库。</p>
<p>还比较了几对意义相反的概念。对于两者之间的相似度这个概念，值越大，表明两者之间更相像。相反，对于距离而言，值越小，两者更相像。另外一对是损失函数和打分函数。对于损失函数，值越小，效果越好（也就是损失越少）。而对于打分函数，值越大，效果越好。</p>
<h2 id=第八章>第八章</h2>
<p>本章使用神经网络分析自己生成的验证码图像</p>
<h3 id=人工神经网络>人工神经网络</h3>
<p><em>神经网络</em>算法最初是根据人类大脑的工作机制设计的。神经网络由一系列相互连接的神经元组成。每个神经元都是一个简单的函数，接收一定输入，给出相应输出。</p>
<p>神经元可以使用任何标准函数来处理数据，比如线性函数，这些函数统称为激活函数（activation function）。一般来说，神经网络学习算法要能正常工作，激活函数应当是可导（derivable）和光滑的。常用的激活函数有<em>逻辑斯谛</em>函数，函数表达式如下（x 为神经元的输入，k、L 通常为 1，这时函数达到最大值）。</p>
<p>$$
f(x) = \frac{L}{1+e^{-k(x-x_{0})}}
$$</p>
<p>每个神经元接收几个输入，根据这几个输入，计算输出。这样的一个个神经元连接在一起组成了神经网络，对数据挖掘应用来说，它非常强大。这些神经元紧密连接，密切配合，能够通过学习得到一个模型，使得神经网络成为机器学习领域最强大的概念之一。</p>
<p>数据挖掘应用的神经网络，神经元按照层级进行排列，至少有三层</p>
<ol>
<li>第一层：输入层。用来接收数据集的输入。第一层中的每个神经元对输入进行计算，把得到的结果传给第二层的神经元。这种叫作<em>前向神经网络</em></li>
<li>隐含层：数据表现方式令人难以理解，一层或多层</li>
<li>最后一层：输出层。输出结果表示的是神经网络分类器给出的分类结果</li>
</ol>
<p>神经元激活函数通常使用逻辑斯谛函数，每层神经元之间为全连接，创建和训练神经网络还需要用到其他几个参数。</p>
<p>创建过程，指定神经网络的规模需要用到两个参数：神经网络共有多少层，隐含层每层有多少个神经元（输入层和输出层神经元数量通常由数据集来定）。</p>
<h3 id=创建数据集>创建数据集</h3>
<p>使用长度为 4 个字母的英文单词作为验证码</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># -*- coding: utf-8 -*-</span>
<span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
<span style=color:#f92672>from</span> PIL <span style=color:#f92672>import</span> Image, ImageDraw, ImageFont
<span style=color:#f92672>from</span> skimage <span style=color:#f92672>import</span> transform <span style=color:#66d9ef>as</span> tf
<span style=color:#f92672>from</span> skimage.transform <span style=color:#f92672>import</span> resize
<span style=color:#f92672>from</span> matplotlib <span style=color:#f92672>import</span> pyplot <span style=color:#66d9ef>as</span> plt
<span style=color:#f92672>from</span> skimage.measure <span style=color:#f92672>import</span> label, regionprops  <span style=color:#75715e># 用于图像分割</span>
<span style=color:#f92672>from</span> sklearn.utils <span style=color:#f92672>import</span> check_random_state
<span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> OneHotEncoder
<span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> train_test_split
<span style=color:#f92672>from</span> pybrain.datasets.supervised <span style=color:#f92672>import</span> SupervisedDataSet  <span style=color:#75715e># 神经网络数据集</span>
<span style=color:#f92672>from</span> pybrain.tools.shortcuts <span style=color:#f92672>import</span> buildNetwork  <span style=color:#75715e># 构建神经网络</span>
<span style=color:#f92672>from</span> pybrain.supervised.trainers.backprop <span style=color:#f92672>import</span> BackpropTrainer  <span style=color:#75715e># 反向传播算法</span>
<span style=color:#f92672>from</span> sklearn.metrics <span style=color:#f92672>import</span> f1_score
<span style=color:#f92672>from</span> nltk.corpus <span style=color:#f92672>import</span> words  <span style=color:#75715e># 导入语料库 用于生成单词</span>
<span style=color:#f92672>from</span> sklearn.metrics <span style=color:#f92672>import</span> confusion_matrix  <span style=color:#75715e># 混淆矩阵</span>
<span style=color:#f92672>from</span> nltk.metrics <span style=color:#f92672>import</span> edit_distance  <span style=color:#75715e># 编辑距离</span>
<span style=color:#f92672>from</span> operator <span style=color:#f92672>import</span> itemgetter


<span style=color:#75715e># 用于生成验证码，接收一个单词和错切值，返回用numpy数组格式表示的图像</span>
<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>create_captcha</span>(text, shear<span style=color:#f92672>=</span><span style=color:#ae81ff>0.0</span>, size<span style=color:#f92672>=</span>(<span style=color:#ae81ff>100</span>, <span style=color:#ae81ff>26</span>)):
    im <span style=color:#f92672>=</span> Image<span style=color:#f92672>.</span>new(<span style=color:#e6db74>&#34;L&#34;</span>, size, <span style=color:#e6db74>&#34;black&#34;</span>)
    draw <span style=color:#f92672>=</span> ImageDraw<span style=color:#f92672>.</span>Draw(im)
    <span style=color:#75715e># 验证码文字所用字体，该开源字体可在github下载</span>
    font <span style=color:#f92672>=</span> ImageFont<span style=color:#f92672>.</span>truetype(<span style=color:#e6db74>&#34;FiraCode-Medium.otf&#34;</span>, <span style=color:#ae81ff>22</span>)
    draw<span style=color:#f92672>.</span>text((<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>), text, fill<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, font<span style=color:#f92672>=</span>font)
    <span style=color:#75715e># 将PIL图像转换为numpy数组，以便用scikit-image库为图像添加错切变化效果</span>
    image <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array(im)
    <span style=color:#75715e># 应用错切变化效果</span>
    affine_tf <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>AffineTransform(shear<span style=color:#f92672>=</span>shear)
    image <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>warp(image, affine_tf)
    <span style=color:#75715e># 对图像进行归一化处理，确保特征值落在0到1之间</span>
    <span style=color:#66d9ef>return</span> image <span style=color:#f92672>/</span> image<span style=color:#f92672>.</span>max()


<span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;__main__&#39;</span>:
    image <span style=color:#f92672>=</span> create_captcha(<span style=color:#e6db74>&#39;GENE&#39;</span>, shear<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>)
    plt<span style=color:#f92672>.</span>imshow(image, cmap<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;Greys&#39;</span>)
    plt<span style=color:#f92672>.</span>show()
</code></pre></div><p>Output:</p>
<p><figure>
<a href=/img/in-post/data-mining/ch8/myplot1.png>
<img src=/img/in-post/data-mining/ch8/myplot1.png loading=lazy alt=8.1>
</a>
<figcaption>8.1</figcaption>
</figure></p>
<hr>
<p>将图像切分为单个的字母</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>segment_image</span>(image):
        <span style=color:#e6db74>&#34;&#34;&#34;
</span><span style=color:#e6db74>        接收图像，返回小图像列表
</span><span style=color:#e6db74>        :param image:
</span><span style=color:#e6db74>        :return:
</span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
        <span style=color:#75715e># 找出像素值相同又连接在一起的像素块，类似上一章的连通分支</span>
        labeled_image <span style=color:#f92672>=</span> label(image <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>0</span>)
        subimages <span style=color:#f92672>=</span> []
        <span style=color:#66d9ef>for</span> region <span style=color:#f92672>in</span> regionprops(labeled_image):
            <span style=color:#75715e># 获取当前位置的起始和结束坐标</span>
            start_x, start_y, end_x, end_y <span style=color:#f92672>=</span> region<span style=color:#f92672>.</span>bbox
            subimages<span style=color:#f92672>.</span>append(image[start_x:end_x, start_y:end_y])
        <span style=color:#75715e># 如果没有找到小图像，则将原图像作为子图返回</span>
        <span style=color:#66d9ef>if</span> len(subimages) <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>:
            <span style=color:#66d9ef>return</span> [image, ]
        <span style=color:#66d9ef>return</span> subimages


    subimages <span style=color:#f92672>=</span> segment_image(image)
    f, axes <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>subplots(<span style=color:#ae81ff>1</span>, len(subimages), figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>3</span>))
    <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(len(subimages)):
        axes[i]<span style=color:#f92672>.</span>imshow(subimages[i], cmap<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;gray&#39;</span>)
    plt<span style=color:#f92672>.</span>show()
</code></pre></div><p>Output:</p>
<p><figure>
<a href=/img/in-post/data-mining/ch8/myplot2.png>
<img src=/img/in-post/data-mining/ch8/myplot2.png loading=lazy alt=8.2>
</a>
<figcaption>8.2</figcaption>
</figure></p>
<hr>
<p>创建训练集</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># 指定随机状态值</span>
    random_state <span style=color:#f92672>=</span> check_random_state(<span style=color:#ae81ff>14</span>)
    letters <span style=color:#f92672>=</span> list(<span style=color:#e6db74>&#34;ABCDEFGHIJKLMNOPQRSTUVWXYZ&#34;</span>)
    shear_values <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>arange(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0.5</span>, <span style=color:#ae81ff>0.05</span>)

    <span style=color:#75715e># 用来生成一条训练数据</span>
    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>generate_sample</span>(random_state<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>):
        random_state <span style=color:#f92672>=</span> check_random_state(random_state)
        letter <span style=color:#f92672>=</span> random_state<span style=color:#f92672>.</span>choice(letters)
        shear <span style=color:#f92672>=</span> random_state<span style=color:#f92672>.</span>choice(shear_values)
        <span style=color:#66d9ef>return</span> create_captcha(letter, shear<span style=color:#f92672>=</span>shear, size<span style=color:#f92672>=</span>(<span style=color:#ae81ff>25</span>, <span style=color:#ae81ff>25</span>)), letters<span style=color:#f92672>.</span>index(letter)

    image, target <span style=color:#f92672>=</span> generate_sample(random_state)
    plt<span style=color:#f92672>.</span>imshow(image, cmap<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;Greys&#39;</span>)
    print(<span style=color:#e6db74>&#34;The target for this image is </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(target))
    plt<span style=color:#f92672>.</span>show()

    <span style=color:#75715e># 调用3000次此函数，生成训练数据传到numpy的数组里</span>
    dataset, targets <span style=color:#f92672>=</span> zip(<span style=color:#f92672>*</span>(generate_sample(random_state) <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>3000</span>)))
    dataset <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array(dataset, dtype<span style=color:#f92672>=</span>float)
    targets <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array(targets)

    <span style=color:#75715e># 对26个字母类别进行编码</span>
    onehot <span style=color:#f92672>=</span> OneHotEncoder()
    y <span style=color:#f92672>=</span> onehot<span style=color:#f92672>.</span>fit_transform(targets<span style=color:#f92672>.</span>reshape(targets<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>], <span style=color:#ae81ff>1</span>))
    <span style=color:#75715e># 将稀疏矩阵转换为密集矩阵</span>
    y <span style=color:#f92672>=</span> y<span style=color:#f92672>.</span>todense()

    <span style=color:#75715e># 调整图像大小</span>
    dataset <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([resize(segment_image(sample)[<span style=color:#ae81ff>0</span>], (<span style=color:#ae81ff>20</span>, <span style=color:#ae81ff>20</span>)) <span style=color:#66d9ef>for</span> sample <span style=color:#f92672>in</span> dataset])
    <span style=color:#75715e># 将最后三维的dataset的后二维扁平化</span>
    X <span style=color:#f92672>=</span> dataset<span style=color:#f92672>.</span>reshape((dataset<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>], dataset<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>1</span>] <span style=color:#f92672>*</span> dataset<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>2</span>]))
    X_train, X_test, y_train, y_test <span style=color:#f92672>=</span> train_test_split(X, y, train_size<span style=color:#f92672>=</span><span style=color:#ae81ff>0.9</span>)
</code></pre></div><p>Output:</p>
<pre><code>The target for this image is 11
</code></pre>
<p><figure>
<a href=/img/in-post/data-mining/ch8/myplot3.png>
<img src=/img/in-post/data-mining/ch8/myplot3.png loading=lazy alt=8.3>
</a>
<figcaption>8.3</figcaption>
</figure></p>
<h3 id=训练和分类>训练和分类</h3>
<p>反向传播算法（back propagation，backprop）的工作机制为对预测错误的神经元施以惩罚。从输出层开始，向上层层查找预测错误的神经元，微调这些神经元输入值的权重，以达到修复输出错误的目的。</p>
<p>神经元之所以给出错误的预测，原因在于它前面为其提供输入的神经元，更确切来说是由这两个神经元之间边的权重及输入值决定的。我们可以尝试对权重进行微调。每次调整的幅度取决于以下两个方面</p>
<ul>
<li>神经元各边权重的误差函数的偏导数</li>
<li>一个叫作学习速率的参数（通常使用很小的值）</li>
</ul>
<p>计算出函数误差的梯度，再乘以学习速率，用总权重减去得到的值。梯度的符号由误差决定，每次对权重的修正都是朝着给出正确的预测值努力。有时候，修正结果为局部最优（local optima），比起其他权重组合要好，但所得到的各权重还不是最优组合。</p>
<p>反向传播算法从输出层开始，层层向上回溯到输入层。到达输入层后，所有边的权重更新完毕。</p>
<p>这里在导入 <code>SupervisedDataSet</code> 时发生了错误，使用 <code>pip install pybrain</code> 安装的包会有找不到方法的现象，因此我从 github-pybrain 下载了源码包，在解压后的文件夹中输入 <code>python setup.py install</code> 进行安装，解决了这个问题。还有一个问题是原文使用 <code>from pybrain.datasets import SupervisedDataSet</code> 来导入 <code>SupervisedDataSet</code> 但是我在导入时发现并没有这个类，于是看了项目结构后使用 <code>from pybrain.datasets.supervised import SupervisedDataSet</code> 进行导入。还有几处相同的问题均是这样解决的。</p>
<p>这里在使用 f1_score 进行评估时也出现了错误，原因见代码注释。</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># 为pybrain库创建格式适配的数据集</span>
    training <span style=color:#f92672>=</span> SupervisedDataSet(X<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>1</span>], y<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>1</span>])
    <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(X_train<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>]):
        training<span style=color:#f92672>.</span>addSample(X_train[i], y_train[i])
    testing <span style=color:#f92672>=</span> SupervisedDataSet(X<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>1</span>], y<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>1</span>])
    <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(X_test<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>]):
        testing<span style=color:#f92672>.</span>addSample(X_test[i], y_test[i])
    <span style=color:#75715e># 指定维度，创建神经网络，第一个参数为输入层神经元数量，第二个参数隐含层神经元数量，第三个参数为输出层神经元数量</span>
    <span style=color:#75715e># bias在每一层使用一个一直处于激活状态的偏置神经元</span>
    net <span style=color:#f92672>=</span> buildNetwork(X<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>1</span>], <span style=color:#ae81ff>100</span>, y<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>1</span>], bias<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)

    <span style=color:#75715e># 使用反向传播算法调整权重</span>
    trainer <span style=color:#f92672>=</span> BackpropTrainer(net, training, learningrate<span style=color:#f92672>=</span><span style=color:#ae81ff>0.01</span>, weightdecay<span style=color:#f92672>=</span><span style=color:#ae81ff>0.01</span>)
    <span style=color:#75715e># 设定代码的运行步数</span>
    trainer<span style=color:#f92672>.</span>trainEpochs(epochs<span style=color:#f92672>=</span><span style=color:#ae81ff>20</span>)
    <span style=color:#75715e># 预测值</span>
    predictions <span style=color:#f92672>=</span> trainer<span style=color:#f92672>.</span>testOnClassData(dataset<span style=color:#f92672>=</span>testing)
    <span style=color:#75715e># f1_score的average默认值为&#39;binary&#39;，如果不指定average则会发生ValueError</span>
    print(<span style=color:#e6db74>&#34;F-score:</span><span style=color:#e6db74>{0:.2f}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(f1_score(y_test<span style=color:#f92672>.</span>argmax(axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), predictions, average<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;weighted&#39;</span>)))
    print(<span style=color:#e6db74>&#34;F-score:</span><span style=color:#e6db74>{0:.2f}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(f1_score(y_test<span style=color:#f92672>.</span>argmax(axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), predictions, average<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;micro&#39;</span>)))
    print(<span style=color:#e6db74>&#34;F-score:</span><span style=color:#e6db74>{0:.2f}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(f1_score(y_test<span style=color:#f92672>.</span>argmax(axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), predictions, average<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;macro&#39;</span>)))
</code></pre></div><p>Output:</p>
<pre><code>F-score:1.00
F-score:1.00
F-score:1.00
</code></pre>
<hr>
<p>预测单词</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># 接收验证码，用神经网络进行训练，返回单词预测结果</span>
    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>predict_captcha</span>(captcha_image, neural_network):
        subimages <span style=color:#f92672>=</span> segment_image(captcha_image)
        predicted_word <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;&#34;</span>
        <span style=color:#75715e># 遍历四张小图像</span>
        <span style=color:#66d9ef>for</span> subimage <span style=color:#f92672>in</span> subimages:
            <span style=color:#75715e># 调整每张小图像的大小为20*20像素</span>
            subimage <span style=color:#f92672>=</span> resize(subimage, (<span style=color:#ae81ff>20</span>,<span style=color:#ae81ff>20</span>))
            <span style=color:#75715e># 把小图像数据传入神经网络的输入层，激活神经网络。这些数据将在神经网络中进行传播，返回输出结果</span>
            outputs <span style=color:#f92672>=</span> net<span style=color:#f92672>.</span>activate(subimage<span style=color:#f92672>.</span>flatten())
            <span style=color:#75715e># 神经网络输出26个值，每个值都有索引号，分别对应letters列表中有着相同索引的字母，每个值的大小表示与对应字母的相似度。为了获得实际的预测值，我们取到最大值的索引，再通过letters列表找到对应的字母</span>
            prediction <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>argmax(outputs)
            <span style=color:#75715e># 把上面得到的字母添加到正在预测的单词中</span>
            predicted_word <span style=color:#f92672>+=</span> letters[prediction]
        <span style=color:#66d9ef>return</span> predicted_word

    word <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;GENE&#34;</span>
    captcha <span style=color:#f92672>=</span> create_captcha(word, shear<span style=color:#f92672>=</span><span style=color:#ae81ff>0.2</span>)
    print(predict_captcha(captcha, net))
</code></pre></div><p>Output:</p>
<pre><code>GENE
</code></pre>
<hr>
<p>nltk 下载语料库时可能会很慢，需要的可以在这里<a class=link href=https://pan.baidu.com/s/1mYm_1CdkNrVScHyiCyIdnQ title=e3pw target=_blank rel=noopener>下载</a>。如何离线安装 nltk 语料库自行百度。</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>test_prediction</span>(word, net, shear<span style=color:#f92672>=</span><span style=color:#ae81ff>0.2</span>):
        captcha <span style=color:#f92672>=</span> create_captcha(word, shear<span style=color:#f92672>=</span>shear)
        prediction <span style=color:#f92672>=</span> predict_captcha(captcha, net)
        prediction <span style=color:#f92672>=</span> prediction[:<span style=color:#ae81ff>4</span>]
        <span style=color:#75715e># 返回预测结果是否正确，验证码中的单词和预测结果的前四个字符</span>
        <span style=color:#66d9ef>return</span> word <span style=color:#f92672>==</span> prediction, word, prediction

    <span style=color:#75715e># 语料库中字长为4的单词列表</span>
    valid_words <span style=color:#f92672>=</span> [word<span style=color:#f92672>.</span>upper() <span style=color:#66d9ef>for</span> word <span style=color:#f92672>in</span> words<span style=color:#f92672>.</span>words() <span style=color:#66d9ef>if</span> len(word) <span style=color:#f92672>==</span> <span style=color:#ae81ff>4</span>]
    num_correct <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
    num_incorrect <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
    <span style=color:#66d9ef>for</span> word <span style=color:#f92672>in</span> valid_words:
        correct, word, prediction <span style=color:#f92672>=</span> test_prediction(word, net, shear<span style=color:#f92672>=</span><span style=color:#ae81ff>0.2</span>)
        <span style=color:#66d9ef>if</span> correct:
            num_correct <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
        <span style=color:#66d9ef>else</span>:
            num_incorrect <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
    print(<span style=color:#e6db74>&#34;Number correct is </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(num_correct))
    print(<span style=color:#e6db74>&#34;Number incorrect is </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(num_incorrect))

    <span style=color:#75715e># 二维混淆矩阵， 每行每列均为一个类别</span>
    cm <span style=color:#f92672>=</span> confusion_matrix(np<span style=color:#f92672>.</span>argmax(y_test,axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), predictions)
    <span style=color:#75715e># 混淆矩阵作图</span>
    plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>20</span>, <span style=color:#ae81ff>20</span>))
    plt<span style=color:#f92672>.</span>imshow(cm)
    tick_marks <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>arange(len(letters))
    plt<span style=color:#f92672>.</span>xticks(tick_marks, letters)
    plt<span style=color:#f92672>.</span>yticks(tick_marks, letters)
    plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#39;Actual&#39;</span>)
    plt<span style=color:#f92672>.</span>xlabel(<span style=color:#e6db74>&#39;Predicted&#39;</span>)
    plt<span style=color:#f92672>.</span>show()
</code></pre></div><p>Output:</p>
<pre><code>Number correct is 3738
Number incorrect is 1775
</code></pre>
<p><figure>
<a href=/img/in-post/data-mining/ch8/myplot4.png>
<img src=/img/in-post/data-mining/ch8/myplot4.png loading=lazy alt=8.4>
</a>
<figcaption>8.4</figcaption>
</figure></p>
<h3 id=用词典提升准确率>用词典提升准确率</h3>
<p>假设验证码全部都是英语单词</p>
<p><em>列文斯坦编辑距离</em>（Levenshtein edit distance）是一种通过比较两个短字符串，确定它们相似度的方法。它不太适合扩展，字符串很长时通常不用这种方法。编辑距离需要计算从一个单词变为另一个单词所需要的步骤数。以下操作都算一步</p>
<ul>
<li>在单词的任意位置插入一个新字母</li>
<li>从单词中删除任意一个字母</li>
<li>把一个字母替换为另外一个字母</li>
</ul>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># 获得两个单词的编辑距离</span>
    steps <span style=color:#f92672>=</span> edit_distance(<span style=color:#e6db74>&#34;STEP&#34;</span>, <span style=color:#e6db74>&#34;STOP&#34;</span>)
    print(<span style=color:#e6db74>&#34;The num of steps needed is: </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(steps))

    <span style=color:#75715e># 用词长4减去同等位置上相同的字母数量，得到的值越小表示两个词相似度越高</span>
    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>compute_distance</span>(prediction, word):
        <span style=color:#66d9ef>return</span> len(prediction) <span style=color:#f92672>-</span> sum(prediction[i] <span style=color:#f92672>==</span> word[i] <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(len(prediction)))

    <span style=color:#75715e># 改进预测函数</span>
    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>improved_prediction</span>(word, net, dictionary, shear<span style=color:#f92672>=</span><span style=color:#ae81ff>0.2</span>):
        captcha <span style=color:#f92672>=</span> create_captcha(word, shear<span style=color:#f92672>=</span>shear)
        prediction <span style=color:#f92672>=</span> predict_captcha(captcha, net)
        prediction <span style=color:#f92672>=</span> prediction[:<span style=color:#ae81ff>4</span>]
        <span style=color:#75715e># 如果单词不在词典中则比较取词典中距离最小的单词</span>
        <span style=color:#66d9ef>if</span> prediction <span style=color:#f92672>not</span> <span style=color:#f92672>in</span> dictionary:
            distance <span style=color:#f92672>=</span> sorted([(w, compute_distance(prediction, w)) <span style=color:#66d9ef>for</span> w <span style=color:#f92672>in</span> dictionary], key<span style=color:#f92672>=</span>itemgetter(<span style=color:#ae81ff>1</span>))
            best_word <span style=color:#f92672>=</span> distance[<span style=color:#ae81ff>0</span>]
            prediction <span style=color:#f92672>=</span> best_word[<span style=color:#ae81ff>0</span>]
        <span style=color:#66d9ef>return</span> word <span style=color:#f92672>==</span> prediction, word, prediction


    num_correct <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
    num_incorrect <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
    <span style=color:#66d9ef>for</span> word <span style=color:#f92672>in</span> valid_words:
        correct, word, prediction <span style=color:#f92672>=</span> improved_prediction(word, net, valid_words,shear<span style=color:#f92672>=</span><span style=color:#ae81ff>0.2</span>)
        <span style=color:#66d9ef>if</span> correct:
            num_correct <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
        <span style=color:#66d9ef>else</span>:
            num_incorrect <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
    print(<span style=color:#e6db74>&#34;Number correct is </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(num_correct))
    print(<span style=color:#e6db74>&#34;Number incorrect is </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(num_incorrect))
</code></pre></div><p>Output:</p>
<pre><code>The num of steps needed is: 1
Number correct is 3785
Number incorrect is 1728
</code></pre>
<p>正确率稍有提升</p>
<h2 id=第九章>第九章</h2>
<p>昨天跑去搞 wordpress 搭建网站了 (๑•́ ₃•̀๑) （摸鱼真舒服</p>
<p>本章主要介绍如下内容</p>
<ul>
<li>特征工程和如何根据应用选择特征</li>
<li>带着新问题，重新回顾词袋模型</li>
<li>特征类型和字符 N 元语法模型</li>
<li>支持向量机</li>
<li>数据集清洗</li>
</ul>
<h3 id=为作品找到作者>为作品找到作者</h3>
<p>作者归属可以看作是一种分类问题，已知一部分作者，数据集为多个作者的作品（训练集），目标是确定一组作者不详的作品（测试集）是谁写的。如果作者恰好是已知的作者里面的，这种问题叫作封闭问题</p>
<p>如果作者可能不在里面，这种问题就叫作开放问题</p>
<p>获取数据，书中的链接有很多已经失效，我参考网上的取得了下载方式。</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># -*- coding: utf-8 -*-</span>
<span style=color:#75715e># get_data.py</span>
<span style=color:#f92672>import</span> requests
<span style=color:#f92672>import</span> os
<span style=color:#f92672>import</span> time
<span style=color:#f92672>from</span> collections <span style=color:#f92672>import</span> defaultdict

titles <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#39;burton&#39;</span>: [<span style=color:#ae81ff>4657</span>, <span style=color:#ae81ff>2400</span>, <span style=color:#ae81ff>5760</span>, <span style=color:#ae81ff>6036</span>, <span style=color:#ae81ff>7111</span>, <span style=color:#ae81ff>8821</span>, <span style=color:#ae81ff>18506</span>, <span style=color:#ae81ff>4658</span>, <span style=color:#ae81ff>5761</span>, <span style=color:#ae81ff>6886</span>, <span style=color:#ae81ff>7113</span>],
          <span style=color:#e6db74>&#39;dickens&#39;</span>: [<span style=color:#ae81ff>24022</span>, <span style=color:#ae81ff>1392</span>, <span style=color:#ae81ff>1414</span>, <span style=color:#ae81ff>1467</span>, <span style=color:#ae81ff>2324</span>, <span style=color:#ae81ff>580</span>, <span style=color:#ae81ff>786</span>, <span style=color:#ae81ff>888</span>, <span style=color:#ae81ff>963</span>, <span style=color:#ae81ff>27924</span>, <span style=color:#ae81ff>1394</span>, <span style=color:#ae81ff>1415</span>, <span style=color:#ae81ff>15618</span>, <span style=color:#ae81ff>25985</span>, <span style=color:#ae81ff>588</span>, <span style=color:#ae81ff>807</span>,
                      <span style=color:#ae81ff>914</span>, <span style=color:#ae81ff>967</span>, <span style=color:#ae81ff>30127</span>, <span style=color:#ae81ff>1400</span>, <span style=color:#ae81ff>1421</span>, <span style=color:#ae81ff>16023</span>, <span style=color:#ae81ff>28198</span>, <span style=color:#ae81ff>644</span>, <span style=color:#ae81ff>809</span>, <span style=color:#ae81ff>917</span>, <span style=color:#ae81ff>968</span>, <span style=color:#ae81ff>1023</span>, <span style=color:#ae81ff>1406</span>, <span style=color:#ae81ff>1422</span>, <span style=color:#ae81ff>17879</span>, <span style=color:#ae81ff>30368</span>,
                      <span style=color:#ae81ff>675</span>, <span style=color:#ae81ff>810</span>, <span style=color:#ae81ff>924</span>, <span style=color:#ae81ff>98</span>, <span style=color:#ae81ff>1289</span>, <span style=color:#ae81ff>1413</span>, <span style=color:#ae81ff>1423</span>, <span style=color:#ae81ff>17880</span>, <span style=color:#ae81ff>32241</span>, <span style=color:#ae81ff>699</span>, <span style=color:#ae81ff>821</span>, <span style=color:#ae81ff>927</span>],
          <span style=color:#e6db74>&#39;doyle&#39;</span>: [<span style=color:#ae81ff>2349</span>, <span style=color:#ae81ff>11656</span>, <span style=color:#ae81ff>1644</span>, <span style=color:#ae81ff>22357</span>, <span style=color:#ae81ff>2347</span>, <span style=color:#ae81ff>290</span>, <span style=color:#ae81ff>34627</span>, <span style=color:#ae81ff>5148</span>, <span style=color:#ae81ff>8394</span>, <span style=color:#ae81ff>26153</span>, <span style=color:#ae81ff>12555</span>, <span style=color:#ae81ff>1661</span>, <span style=color:#ae81ff>23059</span>, <span style=color:#ae81ff>2348</span>, <span style=color:#ae81ff>294</span>,
                    <span style=color:#ae81ff>355</span>, <span style=color:#ae81ff>5260</span>, <span style=color:#ae81ff>8727</span>, <span style=color:#ae81ff>10446</span>, <span style=color:#ae81ff>126</span>, <span style=color:#ae81ff>17398</span>, <span style=color:#ae81ff>2343</span>, <span style=color:#ae81ff>2350</span>, <span style=color:#ae81ff>3070</span>, <span style=color:#ae81ff>356</span>, <span style=color:#ae81ff>5317</span>, <span style=color:#ae81ff>903</span>, <span style=color:#ae81ff>10581</span>, <span style=color:#ae81ff>13152</span>, <span style=color:#ae81ff>2038</span>, <span style=color:#ae81ff>2344</span>,
                    <span style=color:#ae81ff>244</span>, <span style=color:#ae81ff>32536</span>, <span style=color:#ae81ff>423</span>, <span style=color:#ae81ff>537</span>, <span style=color:#ae81ff>108</span>, <span style=color:#ae81ff>139</span>, <span style=color:#ae81ff>2097</span>, <span style=color:#ae81ff>2345</span>, <span style=color:#ae81ff>24951</span>, <span style=color:#ae81ff>32777</span>, <span style=color:#ae81ff>4295</span>, <span style=color:#ae81ff>7964</span>, <span style=color:#ae81ff>11413</span>, <span style=color:#ae81ff>1638</span>, <span style=color:#ae81ff>21768</span>, <span style=color:#ae81ff>2346</span>,
                    <span style=color:#ae81ff>2845</span>, <span style=color:#ae81ff>3289</span>, <span style=color:#ae81ff>439</span>, <span style=color:#ae81ff>834</span>],
          <span style=color:#e6db74>&#39;gaboriau&#39;</span>: [<span style=color:#ae81ff>1748</span>, <span style=color:#ae81ff>1651</span>, <span style=color:#ae81ff>2736</span>, <span style=color:#ae81ff>3336</span>, <span style=color:#ae81ff>4604</span>, <span style=color:#ae81ff>4002</span>, <span style=color:#ae81ff>2451</span>, <span style=color:#ae81ff>305</span>, <span style=color:#ae81ff>3802</span>, <span style=color:#ae81ff>547</span>],
          <span style=color:#e6db74>&#39;nesbit&#39;</span>: [<span style=color:#ae81ff>34219</span>, <span style=color:#ae81ff>23661</span>, <span style=color:#ae81ff>28804</span>, <span style=color:#ae81ff>4378</span>, <span style=color:#ae81ff>778</span>, <span style=color:#ae81ff>20404</span>, <span style=color:#ae81ff>28725</span>, <span style=color:#ae81ff>33028</span>, <span style=color:#ae81ff>4513</span>, <span style=color:#ae81ff>794</span>],
          <span style=color:#e6db74>&#39;tarkington&#39;</span>: [<span style=color:#ae81ff>1098</span>, <span style=color:#ae81ff>15855</span>, <span style=color:#ae81ff>1983</span>, <span style=color:#ae81ff>297</span>, <span style=color:#ae81ff>402</span>, <span style=color:#ae81ff>5798</span>, <span style=color:#ae81ff>8740</span>, <span style=color:#ae81ff>980</span>, <span style=color:#ae81ff>1158</span>, <span style=color:#ae81ff>1611</span>, <span style=color:#ae81ff>2326</span>, <span style=color:#ae81ff>30092</span>, <span style=color:#ae81ff>483</span>, <span style=color:#ae81ff>5949</span>, <span style=color:#ae81ff>8867</span>,
                         <span style=color:#ae81ff>13275</span>, <span style=color:#ae81ff>18259</span>, <span style=color:#ae81ff>2595</span>, <span style=color:#ae81ff>3428</span>, <span style=color:#ae81ff>5756</span>, <span style=color:#ae81ff>6401</span>, <span style=color:#ae81ff>9659</span>],
          <span style=color:#e6db74>&#39;twain&#39;</span>: [<span style=color:#ae81ff>1044</span>, <span style=color:#ae81ff>1213</span>, <span style=color:#ae81ff>245</span>, <span style=color:#ae81ff>30092</span>, <span style=color:#ae81ff>3176</span>, <span style=color:#ae81ff>3179</span>, <span style=color:#ae81ff>3183</span>, <span style=color:#ae81ff>3189</span>, <span style=color:#ae81ff>74</span>, <span style=color:#ae81ff>86</span>, <span style=color:#ae81ff>1086</span>, <span style=color:#ae81ff>142</span>, <span style=color:#ae81ff>2572</span>, <span style=color:#ae81ff>3173</span>, <span style=color:#ae81ff>3177</span>, <span style=color:#ae81ff>3180</span>, <span style=color:#ae81ff>3186</span>,
                    <span style=color:#ae81ff>3192</span>, <span style=color:#ae81ff>76</span>, <span style=color:#ae81ff>91</span>, <span style=color:#ae81ff>119</span>, <span style=color:#ae81ff>1837</span>, <span style=color:#ae81ff>2895</span>, <span style=color:#ae81ff>3174</span>, <span style=color:#ae81ff>3178</span>, <span style=color:#ae81ff>3181</span>, <span style=color:#ae81ff>3187</span>, <span style=color:#ae81ff>3432</span>, <span style=color:#ae81ff>8525</span>]}

<span style=color:#66d9ef>assert</span> len(titles) <span style=color:#f92672>==</span> <span style=color:#ae81ff>7</span>

<span style=color:#66d9ef>assert</span> len(titles[<span style=color:#e6db74>&#39;tarkington&#39;</span>]) <span style=color:#f92672>==</span> <span style=color:#ae81ff>22</span>
<span style=color:#66d9ef>assert</span> len(titles[<span style=color:#e6db74>&#39;dickens&#39;</span>]) <span style=color:#f92672>==</span> <span style=color:#ae81ff>44</span>
<span style=color:#66d9ef>assert</span> len(titles[<span style=color:#e6db74>&#39;nesbit&#39;</span>]) <span style=color:#f92672>==</span> <span style=color:#ae81ff>10</span>
<span style=color:#66d9ef>assert</span> len(titles[<span style=color:#e6db74>&#39;doyle&#39;</span>]) <span style=color:#f92672>==</span> <span style=color:#ae81ff>51</span>
<span style=color:#66d9ef>assert</span> len(titles[<span style=color:#e6db74>&#39;twain&#39;</span>]) <span style=color:#f92672>==</span> <span style=color:#ae81ff>29</span>
<span style=color:#66d9ef>assert</span> len(titles[<span style=color:#e6db74>&#39;burton&#39;</span>]) <span style=color:#f92672>==</span> <span style=color:#ae81ff>11</span>
<span style=color:#66d9ef>assert</span> len(titles[<span style=color:#e6db74>&#39;gaboriau&#39;</span>]) <span style=color:#f92672>==</span> <span style=color:#ae81ff>10</span>

url_base <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;http://www.gutenberg.org/files/&#39;</span>
url_format <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;</span><span style=color:#e6db74>{url_base}{id}</span><span style=color:#e6db74>/</span><span style=color:#e6db74>{id}</span><span style=color:#e6db74>-0.txt&#39;</span>

<span style=color:#75715e># 修复URL</span>
url_fix_format <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;http://www.gutenberg.org/cache/epub/</span><span style=color:#e6db74>{id}</span><span style=color:#e6db74>/pg</span><span style=color:#e6db74>{id}</span><span style=color:#e6db74>.txt&#39;</span>

fiexes <span style=color:#f92672>=</span> defaultdict(list)
<span style=color:#75715e># fixes = {}</span>
<span style=color:#75715e># fixes[4657] = &#39;http://www.gutenberg.org/cache/epub/4657/pg4657.txt&#39;</span>

<span style=color:#75715e># make parent folder if not exists</span>
<span style=color:#75715e># data_folder = os.path.join(os.path.expanduser(&#39;~&#39;),&#39;Data&#39;,&#39;books&#39;) #</span>
<span style=color:#75715e># 这是在用户user目录中存储</span>
data_folder <span style=color:#f92672>=</span> os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>dirname(os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>abspath(__file__))


<span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;__main__&#39;</span>:
    <span style=color:#66d9ef>if</span> <span style=color:#f92672>not</span> os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>exists(data_folder):
        os<span style=color:#f92672>.</span>makedirs(data_folder)
    print(data_folder)

    <span style=color:#66d9ef>for</span> author <span style=color:#f92672>in</span> titles:
        print(<span style=color:#e6db74>&#39;Downloading titles from&#39;</span>, author)
        <span style=color:#75715e># make author&#39;s folder if not exists</span>
        author_folder <span style=color:#f92672>=</span> os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(data_folder, author)
        <span style=color:#66d9ef>if</span> <span style=color:#f92672>not</span> os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>exists(author_folder):
            os<span style=color:#f92672>.</span>makedirs(author_folder)
        <span style=color:#75715e># download each title to this folder</span>
        <span style=color:#66d9ef>for</span> bookid <span style=color:#f92672>in</span> titles[author]:
            <span style=color:#75715e># if bookid in fixes:</span>
            <span style=color:#75715e>#     print(&#39; - Applying fix to book with id&#39;, bookid)</span>
            <span style=color:#75715e>#     url = fixes[bookid]</span>
            <span style=color:#75715e># else:</span>
            <span style=color:#75715e>#     print(&#39; - Getting book with id&#39;, bookid)</span>
            <span style=color:#75715e>#     url = url_format.format(url_base=url_base, id=bookid)</span>

            url <span style=color:#f92672>=</span> url_format<span style=color:#f92672>.</span>format(url_base<span style=color:#f92672>=</span>url_base, id<span style=color:#f92672>=</span>bookid)
            print(<span style=color:#e6db74>&#39; - &#39;</span>, url)
            filename <span style=color:#f92672>=</span> os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(author_folder, <span style=color:#e6db74>&#39;</span><span style=color:#e6db74>%s</span><span style=color:#e6db74>.txt&#39;</span> <span style=color:#f92672>%</span> bookid)
            <span style=color:#66d9ef>if</span> os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>exists(filename):
                print(<span style=color:#e6db74>&#39; - File already exists, skipping&#39;</span>)
            <span style=color:#66d9ef>else</span>:
                r <span style=color:#f92672>=</span> requests<span style=color:#f92672>.</span>get(url)
                <span style=color:#66d9ef>if</span> r<span style=color:#f92672>.</span>status_code <span style=color:#f92672>==</span> <span style=color:#ae81ff>404</span>:
                    print(<span style=color:#e6db74>&#39;url 404:&#39;</span>, author, bookid, <span style=color:#e6db74>&#39;add to fixes list&#39;</span>)
                    fiexes[author]<span style=color:#f92672>.</span>append(bookid)
                <span style=color:#66d9ef>else</span>:
                    txt <span style=color:#f92672>=</span> r<span style=color:#f92672>.</span>text
                    <span style=color:#66d9ef>with</span> open(filename, <span style=color:#e6db74>&#39;w&#39;</span>, encoding<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;utf-8&#39;</span>) <span style=color:#66d9ef>as</span> f:
                        f<span style=color:#f92672>.</span>write(txt)
                time<span style=color:#f92672>.</span>sleep(<span style=color:#ae81ff>1</span>)
    print(<span style=color:#e6db74>&#39;Download complete&#39;</span>)

    print(<span style=color:#e6db74>&#39;开始下载修复列表&#39;</span>)
    <span style=color:#66d9ef>for</span> author <span style=color:#f92672>in</span> fiexes:
        print(<span style=color:#e6db74>&#39;开始下载&lt;</span><span style=color:#e6db74>%s</span><span style=color:#e6db74>&gt;的作品&#39;</span> <span style=color:#f92672>%</span> author)
        author_folder <span style=color:#f92672>=</span> os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(data_folder, author)
        <span style=color:#66d9ef>if</span> <span style=color:#f92672>not</span> os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>exists(author_folder):
            os<span style=color:#f92672>.</span>makedirs(author_folder)

        <span style=color:#66d9ef>for</span> bookid <span style=color:#f92672>in</span> fiexes[author]:
            filename <span style=color:#f92672>=</span> os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(author_folder, <span style=color:#e6db74>&#39;</span><span style=color:#e6db74>%s</span><span style=color:#e6db74>.txt&#39;</span> <span style=color:#f92672>%</span> bookid)
            <span style=color:#66d9ef>if</span> os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>exists(filename):
                print(<span style=color:#e6db74>&#39;文件已经下载，跳过&#39;</span>)
            <span style=color:#66d9ef>else</span>:
                url_fix <span style=color:#f92672>=</span> url_fix_format<span style=color:#f92672>.</span>format(id<span style=color:#f92672>=</span>bookid)
                print(<span style=color:#e6db74>&#39; - &#39;</span>, url_fix)
                r <span style=color:#f92672>=</span> requests<span style=color:#f92672>.</span>get(url_fix)
                <span style=color:#66d9ef>if</span> r<span style=color:#f92672>.</span>status_code <span style=color:#f92672>==</span> <span style=color:#ae81ff>404</span>:
                    print(<span style=color:#e6db74>&#39;又出错了！&#39;</span>, author, bookid)
                <span style=color:#66d9ef>else</span>:
                    <span style=color:#66d9ef>with</span> open(filename, <span style=color:#e6db74>&#39;w&#39;</span>, encoding<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;utf-8&#39;</span>) <span style=color:#66d9ef>as</span> f:
                        f<span style=color:#f92672>.</span>write(r<span style=color:#f92672>.</span>text)
                time<span style=color:#f92672>.</span>sleep(<span style=color:#ae81ff>1</span>)
    print(<span style=color:#e6db74>&#39;修复列表下载完毕&#39;</span>)
</code></pre></div><p>最后下载完成有 177 本书</p>
<hr>
<p>支持向量机是一种二类分类器，扩展后可用来对多个类别进行分类 9（对于多种类别的分类问题，我们创建多个 SVM 分类器——每个还是二类分类器）</p>
<p>C 参数对于训练 SVM 来说很重要，C 参数与分类器正确分类比例相关，但可能带来过拟合的风险。C 值越高，间隔越小，表示要尽可能把所有数据正确分类。C 值越小，间隔越大——有些数据将无法正确分类。C 值低，过拟合训练数据的可能性就低，但是分类效果可能会相对较差</p>
<p>SVM（基础形式）局限性之一就是只能用来对线性可分的数据进行分类。如果数据线性不可分，就要用到内核函数，将其置入更高维的空间中，加入更多伪特征直到数据线性可分。常用的内核函数有几种。线性内核最简单，它无外乎两个个体的特征向量的点积、带权重的特征和偏置项。多项式核提高点积的阶数（比如 2）。此外，还有高斯内核（rbf）、Sigmoind 内核</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># -*- coding: utf-8 -*-</span>
<span style=color:#75715e># author_test.py</span>
<span style=color:#f92672>import</span> os

<span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
<span style=color:#f92672>from</span> sklearn.feature_extraction.text <span style=color:#f92672>import</span> CountVectorizer
<span style=color:#f92672>from</span> sklearn.svm <span style=color:#f92672>import</span> SVC  <span style=color:#75715e># 支持向量机</span>
<span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> cross_val_score
<span style=color:#f92672>from</span> sklearn.pipeline <span style=color:#f92672>import</span> Pipeline
<span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> GridSearchCV
<span style=color:#f92672>from</span> ch9 <span style=color:#f92672>import</span> getdata


<span style=color:#75715e># 去掉古藤堡的说明</span>
<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>clean_book</span>(document):
    lines <span style=color:#f92672>=</span> document<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>)
    start <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
    end <span style=color:#f92672>=</span> len(lines)
    <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(len(lines)):
        line <span style=color:#f92672>=</span> lines[i]
        <span style=color:#66d9ef>if</span> line<span style=color:#f92672>.</span>startswith(<span style=color:#e6db74>&#34;*** START OF THIS PROJECT GUTENBERG&#34;</span>):
            start <span style=color:#f92672>=</span> i <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>
        <span style=color:#66d9ef>elif</span> line<span style=color:#f92672>.</span>startswith(<span style=color:#e6db74>&#34;*** END OF THIS PROJECT GUTENBERG&#34;</span>):
            end <span style=color:#f92672>=</span> i <span style=color:#f92672>-</span> <span style=color:#ae81ff>1</span>
    <span style=color:#66d9ef>return</span> <span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>join(lines[start:end])


<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>load_books_data</span>(folder<span style=color:#f92672>=</span>getdata<span style=color:#f92672>.</span>data_folder):
    <span style=color:#75715e># 存储文档和作者</span>
    documents <span style=color:#f92672>=</span> []
    authors <span style=color:#f92672>=</span> []
    <span style=color:#75715e># 遍历子文件夹</span>
    subfolders <span style=color:#f92672>=</span> [subfolder <span style=color:#66d9ef>for</span> subfolder <span style=color:#f92672>in</span> os<span style=color:#f92672>.</span>listdir(folder)
                  <span style=color:#66d9ef>if</span> os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>isdir(os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(folder, subfolder))]
    <span style=color:#66d9ef>for</span> author_number, subfolder <span style=color:#f92672>in</span> enumerate(subfolders):
        full_subfolder_path <span style=color:#f92672>=</span> os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(folder, subfolder)
        <span style=color:#66d9ef>for</span> document_name <span style=color:#f92672>in</span> os<span style=color:#f92672>.</span>listdir(full_subfolder_path):
            <span style=color:#75715e># 跳过目录下的getdata.py文件</span>
            <span style=color:#66d9ef>if</span> document_name <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;getdata.cpython-38.pyc&#39;</span>:
                <span style=color:#66d9ef>continue</span>
            <span style=color:#66d9ef>with</span> open(os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(full_subfolder_path, document_name), <span style=color:#e6db74>&#39;r&#39;</span>) <span style=color:#66d9ef>as</span> inf:
                documents<span style=color:#f92672>.</span>append(clean_book(inf<span style=color:#f92672>.</span>read()))
                authors<span style=color:#f92672>.</span>append(author_number)
    <span style=color:#66d9ef>return</span> documents, np<span style=color:#f92672>.</span>array(authors, <span style=color:#e6db74>&#39;int&#39;</span>)

<span style=color:#75715e># 功能词</span>
function_words <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#34;a&#34;</span>, <span style=color:#e6db74>&#34;able&#34;</span>, <span style=color:#e6db74>&#34;aboard&#34;</span>, <span style=color:#e6db74>&#34;about&#34;</span>, <span style=color:#e6db74>&#34;above&#34;</span>, <span style=color:#e6db74>&#34;absent&#34;</span>,
                  <span style=color:#e6db74>&#34;according&#34;</span>, <span style=color:#e6db74>&#34;accordingly&#34;</span>, <span style=color:#e6db74>&#34;across&#34;</span>, <span style=color:#e6db74>&#34;after&#34;</span>, <span style=color:#e6db74>&#34;against&#34;</span>,
                  <span style=color:#e6db74>&#34;ahead&#34;</span>, <span style=color:#e6db74>&#34;albeit&#34;</span>, <span style=color:#e6db74>&#34;all&#34;</span>, <span style=color:#e6db74>&#34;along&#34;</span>, <span style=color:#e6db74>&#34;alongside&#34;</span>, <span style=color:#e6db74>&#34;although&#34;</span>,
                  <span style=color:#e6db74>&#34;am&#34;</span>, <span style=color:#e6db74>&#34;amid&#34;</span>, <span style=color:#e6db74>&#34;amidst&#34;</span>, <span style=color:#e6db74>&#34;among&#34;</span>, <span style=color:#e6db74>&#34;amongst&#34;</span>, <span style=color:#e6db74>&#34;amount&#34;</span>, <span style=color:#e6db74>&#34;an&#34;</span>,
                  <span style=color:#e6db74>&#34;and&#34;</span>, <span style=color:#e6db74>&#34;another&#34;</span>, <span style=color:#e6db74>&#34;anti&#34;</span>, <span style=color:#e6db74>&#34;any&#34;</span>, <span style=color:#e6db74>&#34;anybody&#34;</span>, <span style=color:#e6db74>&#34;anyone&#34;</span>,
                  <span style=color:#e6db74>&#34;anything&#34;</span>, <span style=color:#e6db74>&#34;are&#34;</span>, <span style=color:#e6db74>&#34;around&#34;</span>, <span style=color:#e6db74>&#34;as&#34;</span>, <span style=color:#e6db74>&#34;aside&#34;</span>, <span style=color:#e6db74>&#34;astraddle&#34;</span>,
                  <span style=color:#e6db74>&#34;astride&#34;</span>, <span style=color:#e6db74>&#34;at&#34;</span>, <span style=color:#e6db74>&#34;away&#34;</span>, <span style=color:#e6db74>&#34;bar&#34;</span>, <span style=color:#e6db74>&#34;barring&#34;</span>, <span style=color:#e6db74>&#34;be&#34;</span>, <span style=color:#e6db74>&#34;because&#34;</span>,
                  <span style=color:#e6db74>&#34;been&#34;</span>, <span style=color:#e6db74>&#34;before&#34;</span>, <span style=color:#e6db74>&#34;behind&#34;</span>, <span style=color:#e6db74>&#34;being&#34;</span>, <span style=color:#e6db74>&#34;below&#34;</span>, <span style=color:#e6db74>&#34;beneath&#34;</span>,
                  <span style=color:#e6db74>&#34;beside&#34;</span>, <span style=color:#e6db74>&#34;besides&#34;</span>, <span style=color:#e6db74>&#34;better&#34;</span>, <span style=color:#e6db74>&#34;between&#34;</span>, <span style=color:#e6db74>&#34;beyond&#34;</span>, <span style=color:#e6db74>&#34;bit&#34;</span>,
                  <span style=color:#e6db74>&#34;both&#34;</span>, <span style=color:#e6db74>&#34;but&#34;</span>, <span style=color:#e6db74>&#34;by&#34;</span>, <span style=color:#e6db74>&#34;can&#34;</span>, <span style=color:#e6db74>&#34;certain&#34;</span>, <span style=color:#e6db74>&#34;circa&#34;</span>, <span style=color:#e6db74>&#34;close&#34;</span>,
                  <span style=color:#e6db74>&#34;concerning&#34;</span>, <span style=color:#e6db74>&#34;consequently&#34;</span>, <span style=color:#e6db74>&#34;considering&#34;</span>, <span style=color:#e6db74>&#34;could&#34;</span>,
                  <span style=color:#e6db74>&#34;couple&#34;</span>, <span style=color:#e6db74>&#34;dare&#34;</span>, <span style=color:#e6db74>&#34;deal&#34;</span>, <span style=color:#e6db74>&#34;despite&#34;</span>, <span style=color:#e6db74>&#34;down&#34;</span>, <span style=color:#e6db74>&#34;due&#34;</span>, <span style=color:#e6db74>&#34;during&#34;</span>,
                  <span style=color:#e6db74>&#34;each&#34;</span>, <span style=color:#e6db74>&#34;eight&#34;</span>, <span style=color:#e6db74>&#34;eighth&#34;</span>, <span style=color:#e6db74>&#34;either&#34;</span>, <span style=color:#e6db74>&#34;enough&#34;</span>, <span style=color:#e6db74>&#34;every&#34;</span>,
                  <span style=color:#e6db74>&#34;everybody&#34;</span>, <span style=color:#e6db74>&#34;everyone&#34;</span>, <span style=color:#e6db74>&#34;everything&#34;</span>, <span style=color:#e6db74>&#34;except&#34;</span>, <span style=color:#e6db74>&#34;excepting&#34;</span>,
                  <span style=color:#e6db74>&#34;excluding&#34;</span>, <span style=color:#e6db74>&#34;failing&#34;</span>, <span style=color:#e6db74>&#34;few&#34;</span>, <span style=color:#e6db74>&#34;fewer&#34;</span>, <span style=color:#e6db74>&#34;fifth&#34;</span>, <span style=color:#e6db74>&#34;first&#34;</span>,
                  <span style=color:#e6db74>&#34;five&#34;</span>, <span style=color:#e6db74>&#34;following&#34;</span>, <span style=color:#e6db74>&#34;for&#34;</span>, <span style=color:#e6db74>&#34;four&#34;</span>, <span style=color:#e6db74>&#34;fourth&#34;</span>, <span style=color:#e6db74>&#34;from&#34;</span>, <span style=color:#e6db74>&#34;front&#34;</span>,
                  <span style=color:#e6db74>&#34;given&#34;</span>, <span style=color:#e6db74>&#34;good&#34;</span>, <span style=color:#e6db74>&#34;great&#34;</span>, <span style=color:#e6db74>&#34;had&#34;</span>, <span style=color:#e6db74>&#34;half&#34;</span>, <span style=color:#e6db74>&#34;have&#34;</span>, <span style=color:#e6db74>&#34;he&#34;</span>,
                  <span style=color:#e6db74>&#34;heaps&#34;</span>, <span style=color:#e6db74>&#34;hence&#34;</span>, <span style=color:#e6db74>&#34;her&#34;</span>, <span style=color:#e6db74>&#34;hers&#34;</span>, <span style=color:#e6db74>&#34;herself&#34;</span>, <span style=color:#e6db74>&#34;him&#34;</span>, <span style=color:#e6db74>&#34;himself&#34;</span>,
                  <span style=color:#e6db74>&#34;his&#34;</span>, <span style=color:#e6db74>&#34;however&#34;</span>, <span style=color:#e6db74>&#34;i&#34;</span>, <span style=color:#e6db74>&#34;if&#34;</span>, <span style=color:#e6db74>&#34;in&#34;</span>, <span style=color:#e6db74>&#34;including&#34;</span>, <span style=color:#e6db74>&#34;inside&#34;</span>,
                  <span style=color:#e6db74>&#34;instead&#34;</span>, <span style=color:#e6db74>&#34;into&#34;</span>, <span style=color:#e6db74>&#34;is&#34;</span>, <span style=color:#e6db74>&#34;it&#34;</span>, <span style=color:#e6db74>&#34;its&#34;</span>, <span style=color:#e6db74>&#34;itself&#34;</span>, <span style=color:#e6db74>&#34;keeping&#34;</span>,
                  <span style=color:#e6db74>&#34;lack&#34;</span>, <span style=color:#e6db74>&#34;less&#34;</span>, <span style=color:#e6db74>&#34;like&#34;</span>, <span style=color:#e6db74>&#34;little&#34;</span>, <span style=color:#e6db74>&#34;loads&#34;</span>, <span style=color:#e6db74>&#34;lots&#34;</span>, <span style=color:#e6db74>&#34;majority&#34;</span>,
                  <span style=color:#e6db74>&#34;many&#34;</span>, <span style=color:#e6db74>&#34;masses&#34;</span>, <span style=color:#e6db74>&#34;may&#34;</span>, <span style=color:#e6db74>&#34;me&#34;</span>, <span style=color:#e6db74>&#34;might&#34;</span>, <span style=color:#e6db74>&#34;mine&#34;</span>, <span style=color:#e6db74>&#34;minority&#34;</span>,
                  <span style=color:#e6db74>&#34;minus&#34;</span>, <span style=color:#e6db74>&#34;more&#34;</span>, <span style=color:#e6db74>&#34;most&#34;</span>, <span style=color:#e6db74>&#34;much&#34;</span>, <span style=color:#e6db74>&#34;must&#34;</span>, <span style=color:#e6db74>&#34;my&#34;</span>, <span style=color:#e6db74>&#34;myself&#34;</span>,
                  <span style=color:#e6db74>&#34;near&#34;</span>, <span style=color:#e6db74>&#34;need&#34;</span>, <span style=color:#e6db74>&#34;neither&#34;</span>, <span style=color:#e6db74>&#34;nevertheless&#34;</span>, <span style=color:#e6db74>&#34;next&#34;</span>, <span style=color:#e6db74>&#34;nine&#34;</span>,
                  <span style=color:#e6db74>&#34;ninth&#34;</span>, <span style=color:#e6db74>&#34;no&#34;</span>, <span style=color:#e6db74>&#34;nobody&#34;</span>, <span style=color:#e6db74>&#34;none&#34;</span>, <span style=color:#e6db74>&#34;nor&#34;</span>, <span style=color:#e6db74>&#34;nothing&#34;</span>,
                  <span style=color:#e6db74>&#34;notwithstanding&#34;</span>, <span style=color:#e6db74>&#34;number&#34;</span>, <span style=color:#e6db74>&#34;numbers&#34;</span>, <span style=color:#e6db74>&#34;of&#34;</span>, <span style=color:#e6db74>&#34;off&#34;</span>, <span style=color:#e6db74>&#34;on&#34;</span>,
                  <span style=color:#e6db74>&#34;once&#34;</span>, <span style=color:#e6db74>&#34;one&#34;</span>, <span style=color:#e6db74>&#34;onto&#34;</span>, <span style=color:#e6db74>&#34;opposite&#34;</span>, <span style=color:#e6db74>&#34;or&#34;</span>, <span style=color:#e6db74>&#34;other&#34;</span>, <span style=color:#e6db74>&#34;ought&#34;</span>,
                  <span style=color:#e6db74>&#34;our&#34;</span>, <span style=color:#e6db74>&#34;ours&#34;</span>, <span style=color:#e6db74>&#34;ourselves&#34;</span>, <span style=color:#e6db74>&#34;out&#34;</span>, <span style=color:#e6db74>&#34;outside&#34;</span>, <span style=color:#e6db74>&#34;over&#34;</span>, <span style=color:#e6db74>&#34;part&#34;</span>,
                  <span style=color:#e6db74>&#34;past&#34;</span>, <span style=color:#e6db74>&#34;pending&#34;</span>, <span style=color:#e6db74>&#34;per&#34;</span>, <span style=color:#e6db74>&#34;pertaining&#34;</span>, <span style=color:#e6db74>&#34;place&#34;</span>, <span style=color:#e6db74>&#34;plenty&#34;</span>,
                  <span style=color:#e6db74>&#34;plethora&#34;</span>, <span style=color:#e6db74>&#34;plus&#34;</span>, <span style=color:#e6db74>&#34;quantities&#34;</span>, <span style=color:#e6db74>&#34;quantity&#34;</span>, <span style=color:#e6db74>&#34;quarter&#34;</span>,
                  <span style=color:#e6db74>&#34;regarding&#34;</span>, <span style=color:#e6db74>&#34;remainder&#34;</span>, <span style=color:#e6db74>&#34;respecting&#34;</span>, <span style=color:#e6db74>&#34;rest&#34;</span>, <span style=color:#e6db74>&#34;round&#34;</span>,
                  <span style=color:#e6db74>&#34;save&#34;</span>, <span style=color:#e6db74>&#34;saving&#34;</span>, <span style=color:#e6db74>&#34;second&#34;</span>, <span style=color:#e6db74>&#34;seven&#34;</span>, <span style=color:#e6db74>&#34;seventh&#34;</span>, <span style=color:#e6db74>&#34;several&#34;</span>,
                  <span style=color:#e6db74>&#34;shall&#34;</span>, <span style=color:#e6db74>&#34;she&#34;</span>, <span style=color:#e6db74>&#34;should&#34;</span>, <span style=color:#e6db74>&#34;similar&#34;</span>, <span style=color:#e6db74>&#34;since&#34;</span>, <span style=color:#e6db74>&#34;six&#34;</span>, <span style=color:#e6db74>&#34;sixth&#34;</span>,
                  <span style=color:#e6db74>&#34;so&#34;</span>, <span style=color:#e6db74>&#34;some&#34;</span>, <span style=color:#e6db74>&#34;somebody&#34;</span>, <span style=color:#e6db74>&#34;someone&#34;</span>, <span style=color:#e6db74>&#34;something&#34;</span>, <span style=color:#e6db74>&#34;spite&#34;</span>,
                  <span style=color:#e6db74>&#34;such&#34;</span>, <span style=color:#e6db74>&#34;ten&#34;</span>, <span style=color:#e6db74>&#34;tenth&#34;</span>, <span style=color:#e6db74>&#34;than&#34;</span>, <span style=color:#e6db74>&#34;thanks&#34;</span>, <span style=color:#e6db74>&#34;that&#34;</span>, <span style=color:#e6db74>&#34;the&#34;</span>,
                  <span style=color:#e6db74>&#34;their&#34;</span>, <span style=color:#e6db74>&#34;theirs&#34;</span>, <span style=color:#e6db74>&#34;them&#34;</span>, <span style=color:#e6db74>&#34;themselves&#34;</span>, <span style=color:#e6db74>&#34;then&#34;</span>, <span style=color:#e6db74>&#34;thence&#34;</span>,
                  <span style=color:#e6db74>&#34;therefore&#34;</span>, <span style=color:#e6db74>&#34;these&#34;</span>, <span style=color:#e6db74>&#34;they&#34;</span>, <span style=color:#e6db74>&#34;third&#34;</span>, <span style=color:#e6db74>&#34;this&#34;</span>, <span style=color:#e6db74>&#34;those&#34;</span>,
                  <span style=color:#e6db74>&#34;though&#34;</span>, <span style=color:#e6db74>&#34;three&#34;</span>, <span style=color:#e6db74>&#34;through&#34;</span>, <span style=color:#e6db74>&#34;throughout&#34;</span>, <span style=color:#e6db74>&#34;thru&#34;</span>, <span style=color:#e6db74>&#34;thus&#34;</span>,
                  <span style=color:#e6db74>&#34;till&#34;</span>, <span style=color:#e6db74>&#34;time&#34;</span>, <span style=color:#e6db74>&#34;to&#34;</span>, <span style=color:#e6db74>&#34;tons&#34;</span>, <span style=color:#e6db74>&#34;top&#34;</span>, <span style=color:#e6db74>&#34;toward&#34;</span>, <span style=color:#e6db74>&#34;towards&#34;</span>,
                  <span style=color:#e6db74>&#34;two&#34;</span>, <span style=color:#e6db74>&#34;under&#34;</span>, <span style=color:#e6db74>&#34;underneath&#34;</span>, <span style=color:#e6db74>&#34;unless&#34;</span>, <span style=color:#e6db74>&#34;unlike&#34;</span>, <span style=color:#e6db74>&#34;until&#34;</span>,
                  <span style=color:#e6db74>&#34;unto&#34;</span>, <span style=color:#e6db74>&#34;up&#34;</span>, <span style=color:#e6db74>&#34;upon&#34;</span>, <span style=color:#e6db74>&#34;us&#34;</span>, <span style=color:#e6db74>&#34;used&#34;</span>, <span style=color:#e6db74>&#34;various&#34;</span>, <span style=color:#e6db74>&#34;versus&#34;</span>,
                  <span style=color:#e6db74>&#34;via&#34;</span>, <span style=color:#e6db74>&#34;view&#34;</span>, <span style=color:#e6db74>&#34;wanting&#34;</span>, <span style=color:#e6db74>&#34;was&#34;</span>, <span style=color:#e6db74>&#34;we&#34;</span>, <span style=color:#e6db74>&#34;were&#34;</span>, <span style=color:#e6db74>&#34;what&#34;</span>,
                  <span style=color:#e6db74>&#34;whatever&#34;</span>, <span style=color:#e6db74>&#34;when&#34;</span>, <span style=color:#e6db74>&#34;whenever&#34;</span>, <span style=color:#e6db74>&#34;where&#34;</span>, <span style=color:#e6db74>&#34;whereas&#34;</span>,
                  <span style=color:#e6db74>&#34;wherever&#34;</span>, <span style=color:#e6db74>&#34;whether&#34;</span>, <span style=color:#e6db74>&#34;which&#34;</span>, <span style=color:#e6db74>&#34;whichever&#34;</span>, <span style=color:#e6db74>&#34;while&#34;</span>,
                  <span style=color:#e6db74>&#34;whilst&#34;</span>, <span style=color:#e6db74>&#34;who&#34;</span>, <span style=color:#e6db74>&#34;whoever&#34;</span>, <span style=color:#e6db74>&#34;whole&#34;</span>, <span style=color:#e6db74>&#34;whom&#34;</span>, <span style=color:#e6db74>&#34;whomever&#34;</span>,
                  <span style=color:#e6db74>&#34;whose&#34;</span>, <span style=color:#e6db74>&#34;will&#34;</span>, <span style=color:#e6db74>&#34;with&#34;</span>, <span style=color:#e6db74>&#34;within&#34;</span>, <span style=color:#e6db74>&#34;without&#34;</span>, <span style=color:#e6db74>&#34;would&#34;</span>, <span style=color:#e6db74>&#34;yet&#34;</span>,
                  <span style=color:#e6db74>&#34;you&#34;</span>, <span style=color:#e6db74>&#34;your&#34;</span>, <span style=color:#e6db74>&#34;yours&#34;</span>, <span style=color:#e6db74>&#34;yourself&#34;</span>, <span style=color:#e6db74>&#34;yourselves&#34;</span>]


<span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;__main__&#39;</span>:
    <span style=color:#75715e># 获取数据</span>
    documents, classes <span style=color:#f92672>=</span> load_books_data(getdata<span style=color:#f92672>.</span>data_folder)
    <span style=color:#75715e># 提取特征词</span>
    extractor <span style=color:#f92672>=</span> CountVectorizer(vocabulary<span style=color:#f92672>=</span>function_words)
    <span style=color:#75715e># 参数字典</span>
    parameters <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#39;kernel&#39;</span>: (<span style=color:#e6db74>&#39;linear&#39;</span>, <span style=color:#e6db74>&#39;rbf&#39;</span>), <span style=color:#e6db74>&#39;C&#39;</span>: [<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>10</span>]}
    svr <span style=color:#f92672>=</span> SVC()
    <span style=color:#75715e># 使用网格搜索最优参数值</span>
    grid <span style=color:#f92672>=</span> GridSearchCV(svr, parameters)
    <span style=color:#75715e># 使用功能词分类</span>
    pipeline1 <span style=color:#f92672>=</span> Pipeline([(<span style=color:#e6db74>&#39;feature_extraction&#39;</span>, extractor),
                          (<span style=color:#e6db74>&#39;clf&#39;</span>, grid)])
    scores <span style=color:#f92672>=</span> cross_val_score(pipeline1, documents, classes, scoring<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;f1_macro&#39;</span>)
    print(np<span style=color:#f92672>.</span>mean(scores))
</code></pre></div><p>Output:</p>
<pre><code>0.7738985477640941
Score: 0.813
</code></pre>
<h3 id=n-元语法>N 元语法</h3>
<p>N 元语法由一系列的 N 个为一组的对象组成，N 为每组对象的个数</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># 用N元语法分类</span>
    pipeline <span style=color:#f92672>=</span> Pipeline([(<span style=color:#e6db74>&#39;feature_extraction&#39;</span>, CountVectorizer(analyzer<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;char&#39;</span>, ngram_range<span style=color:#f92672>=</span>(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>))),  <span style=color:#75715e># 长度为3的N元语法</span>
                         (<span style=color:#e6db74>&#39;classifier&#39;</span>, grid)
                         ])
    scores <span style=color:#f92672>=</span> cross_val_score(pipeline, documents, classes, scoring<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;f1_macro&#39;</span>)
    print(<span style=color:#e6db74>&#34;Score: </span><span style=color:#e6db74>{:.3f}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(np<span style=color:#f92672>.</span>mean(scores)))
</code></pre></div><p>Output:</p>
<pre><code>Score: 0.813
</code></pre>
<h3 id=安然邮件数据集>安然邮件数据集</h3>
<ul>
<li>读取数据集</li>
<li>清洗数据</li>
<li>组装流水线</li>
<li>使用 F 值评估</li>
</ul>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># -*- coding: utf-8 -*-</span>
<span style=color:#f92672>import</span> os
<span style=color:#f92672>from</span> email.parser <span style=color:#f92672>import</span> Parser  <span style=color:#75715e># 邮件解析器</span>
<span style=color:#f92672>from</span> sklearn.feature_extraction.text <span style=color:#f92672>import</span> CountVectorizer
<span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> GridSearchCV, cross_val_score, train_test_split
<span style=color:#f92672>from</span> sklearn.pipeline <span style=color:#f92672>import</span> Pipeline
<span style=color:#f92672>from</span> sklearn.svm <span style=color:#f92672>import</span> SVC
<span style=color:#f92672>from</span> sklearn.utils <span style=color:#f92672>import</span> check_random_state  <span style=color:#75715e># 随机状态实例</span>
<span style=color:#f92672>from</span> sklearn.metrics <span style=color:#f92672>import</span> confusion_matrix
<span style=color:#f92672>from</span> matplotlib <span style=color:#f92672>import</span> pyplot <span style=color:#66d9ef>as</span> plt
<span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
<span style=color:#f92672>import</span> quotequail

enron_data_folder <span style=color:#f92672>=</span> os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>dirname(os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>abspath(__file__)), <span style=color:#e6db74>&#34;maildir&#34;</span>)
<span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;__main__&#39;</span>:
    p <span style=color:#f92672>=</span> Parser()


    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>get_enron_corpus</span>(num_authors<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>, data_folder<span style=color:#f92672>=</span>enron_data_folder,
                         min_docs_author<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>, max_docs_author<span style=color:#f92672>=</span><span style=color:#ae81ff>100</span>,
                         random_state<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>):
        random_state <span style=color:#f92672>=</span> check_random_state(random_state)
        <span style=color:#75715e># 随机对得到的邮箱列表进行排序</span>
        <span style=color:#75715e># os.listdir函数每次返回结果不一定相同，在使用该函数前先排序，从而保持返回结果的一致性</span>
        email_addresses <span style=color:#f92672>=</span> sorted(os<span style=color:#f92672>.</span>listdir(data_folder))
        random_state<span style=color:#f92672>.</span>shuffle(email_addresses)

        documents <span style=color:#f92672>=</span> []
        classes <span style=color:#f92672>=</span> []
        author_num <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
        authors <span style=color:#f92672>=</span> {}

        <span style=color:#75715e># 遍历邮箱文件夹，查找它下面名字中含有“sent”的表示发件箱的子文件夹</span>
        <span style=color:#66d9ef>for</span> user <span style=color:#f92672>in</span> email_addresses:
            users_email_folder <span style=color:#f92672>=</span> os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(data_folder, user)
            mail_folders <span style=color:#f92672>=</span> [os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(users_email_folder, subfolder) <span style=color:#66d9ef>for</span> subfolder <span style=color:#f92672>in</span> os<span style=color:#f92672>.</span>listdir(users_email_folder)
                            <span style=color:#66d9ef>if</span> <span style=color:#e6db74>&#34;sent&#34;</span> <span style=color:#f92672>in</span> subfolder]
            <span style=color:#66d9ef>try</span>:
                <span style=color:#75715e># 获取子文件夹中的每一封邮件，跳过其中的子文件夹</span>
                authored_emails <span style=color:#f92672>=</span> [open(os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(mail_folder, email_filename), encoding<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;cp1252&#39;</span>)<span style=color:#f92672>.</span>read()
                                   <span style=color:#66d9ef>for</span> mail_folder <span style=color:#f92672>in</span> mail_folders
                                   <span style=color:#66d9ef>for</span> email_filename <span style=color:#f92672>in</span> os<span style=color:#f92672>.</span>listdir(mail_folder)]
            <span style=color:#66d9ef>except</span> <span style=color:#a6e22e>IsADirectoryError</span>:
                <span style=color:#66d9ef>continue</span>
            <span style=color:#75715e># 获得至少十封邮件</span>
            <span style=color:#66d9ef>if</span> len(authored_emails) <span style=color:#f92672>&lt;</span> min_docs_author:
                <span style=color:#66d9ef>continue</span>
            <span style=color:#75715e># 最多获取前100封邮件</span>
            <span style=color:#66d9ef>if</span> len(authored_emails) <span style=color:#f92672>&gt;</span> max_docs_author:
                authored_emails <span style=color:#f92672>=</span> authored_emails[:max_docs_author]
            <span style=color:#75715e># 解析邮件，获取邮件内容</span>
            contents <span style=color:#f92672>=</span> [p<span style=color:#f92672>.</span>parsestr(email)<span style=color:#f92672>.</span>_payload <span style=color:#66d9ef>for</span> email <span style=color:#f92672>in</span> authored_emails]
            documents<span style=color:#f92672>.</span>extend(contents)
            <span style=color:#75715e># 将发件人添加到类列表中，每封邮件添加一次</span>
            classes<span style=color:#f92672>.</span>extend([author_num] <span style=color:#f92672>*</span> len(authored_emails))
            <span style=color:#75715e># 记录收件人编号，再把编号+1</span>
            authors[user] <span style=color:#f92672>=</span> author_num
            author_num <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
            <span style=color:#75715e># 收件人数量达到设置的值跳出循环</span>
            <span style=color:#66d9ef>if</span> author_num <span style=color:#f92672>&gt;=</span> num_authors <span style=color:#f92672>or</span> author_num <span style=color:#f92672>&gt;=</span> len(email_addresses):
                <span style=color:#66d9ef>break</span>
        <span style=color:#75715e># 返回邮件数据集以及收件人字典</span>
        <span style=color:#66d9ef>return</span> documents, np<span style=color:#f92672>.</span>array(classes), authors

    documents, classes, authors <span style=color:#f92672>=</span> get_enron_corpus(data_folder<span style=color:#f92672>=</span>enron_data_folder, random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>14</span>)

    <span style=color:#75715e># 移除邮件的回复信息</span>
    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>remove_replies</span>(email_contents):
        r <span style=color:#f92672>=</span> quotequail<span style=color:#f92672>.</span>unwrap(email_contents)
        <span style=color:#66d9ef>if</span> r <span style=color:#f92672>is</span> <span style=color:#66d9ef>None</span>:
            <span style=color:#66d9ef>return</span> email_contents
        <span style=color:#66d9ef>if</span> <span style=color:#e6db74>&#39;text_top&#39;</span> <span style=color:#f92672>in</span> r:
            <span style=color:#66d9ef>return</span> r[<span style=color:#e6db74>&#39;text_top&#39;</span>]  <span style=color:#75715e># 字典r中存在text_top，返回它的值</span>
        <span style=color:#66d9ef>elif</span> <span style=color:#e6db74>&#39;text&#39;</span> <span style=color:#f92672>in</span> r:
            <span style=color:#66d9ef>return</span> r[<span style=color:#e6db74>&#39;text&#39;</span>]
        <span style=color:#66d9ef>return</span> email_contents

    documents <span style=color:#f92672>=</span> [remove_replies(document) <span style=color:#66d9ef>for</span> document <span style=color:#f92672>in</span> documents]

    parameters <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#39;kernel&#39;</span>: (<span style=color:#e6db74>&#39;linear&#39;</span>, <span style=color:#e6db74>&#39;rbf&#39;</span>), <span style=color:#e6db74>&#39;C&#39;</span>: [<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>10</span>]}
    svr <span style=color:#f92672>=</span> SVC()
    grid <span style=color:#f92672>=</span> GridSearchCV(svr, parameters)
    pipeline <span style=color:#f92672>=</span> Pipeline([(<span style=color:#e6db74>&#39;feature_extraction&#39;</span>, CountVectorizer(analyzer<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;char&#39;</span>, ngram_range<span style=color:#f92672>=</span>(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>))),
                         (<span style=color:#e6db74>&#39;classifier&#39;</span>, grid)
                         ])
    scores <span style=color:#f92672>=</span> cross_val_score(pipeline, documents, classes, scoring<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;f1_macro&#39;</span>)
    print(<span style=color:#e6db74>&#34;Score: </span><span style=color:#e6db74>{:.3f}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(np<span style=color:#f92672>.</span>mean(scores)))
</code></pre></div><p>Output:</p>
<pre><code>Score: 0.664
</code></pre>
<hr>
<p>从流水线中获得最好的参数组合</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    training_documents, test_documents, y_train, y_test <span style=color:#f92672>=</span> train_test_split(documents, classes, random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>14</span>)
    pipeline<span style=color:#f92672>.</span>fit(training_documents, y_train)
    y_pred <span style=color:#f92672>=</span> pipeline<span style=color:#f92672>.</span>predict(test_documents)
    print(pipeline<span style=color:#f92672>.</span>named_steps[<span style=color:#e6db74>&#39;classifier&#39;</span>]<span style=color:#f92672>.</span>best_params_)
</code></pre></div><p>Output:</p>
<pre><code>{'C': 10, 'kernel': 'rbf'}
</code></pre>
<hr>
<p>绘制混淆矩阵查看分类情况</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    cm <span style=color:#f92672>=</span> confusion_matrix(y_test, y_pred)
    cm <span style=color:#f92672>=</span> cm <span style=color:#f92672>/</span> cm<span style=color:#f92672>.</span>astype(np<span style=color:#f92672>.</span>float)<span style=color:#f92672>.</span>sum(axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)

    sorted_authors <span style=color:#f92672>=</span> sorted(authors<span style=color:#f92672>.</span>keys(), key<span style=color:#f92672>=</span><span style=color:#66d9ef>lambda</span> x: authors[x])
    plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>20</span>, <span style=color:#ae81ff>20</span>))
    plt<span style=color:#f92672>.</span>imshow(cm, cmap<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;Blues&#39;</span>)
    tick_marks <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>arange(len(sorted_authors))
    plt<span style=color:#f92672>.</span>xticks(tick_marks, sorted_authors)
    plt<span style=color:#f92672>.</span>yticks(tick_marks, sorted_authors)
    plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#39;Actual&#39;</span>)
    plt<span style=color:#f92672>.</span>xlabel(<span style=color:#e6db74>&#39;Predicted&#39;</span>)
    plt<span style=color:#f92672>.</span>show()
</code></pre></div><p>Output:</p>
<p><figure>
<a href=/img/in-post/data-mining/ch9/myplot9.1.png>
<img src=/img/in-post/data-mining/ch9/myplot9.1.png loading=lazy alt=9.1>
</a>
<figcaption>9.1</figcaption>
</figure></p>
<h2 id=第十章>第十章</h2>
<p>这两天在鼓捣 jupyterlab，一开始在服务器上建了一个 lab 环境，可每次连接都要登上几分钟，不知道是服务器 CPU 不行还是网络不行。然后又在本地鼓捣，在 debian 装 nodejs 和 npm 的时候把系统依赖搞崩了，于是狠下心来重装了电脑。。。发生的事情太多，心累。。</p>
<p>昨天重装了 Ubuntu，搞了下美化，安装了必须的软件（别说 Ubuntu 还挺好用，真香）</p>
<p>我保证这是最后一句吐槽了，一定</p>
<p>本章介绍如何对新闻语料进行聚类，以发现其中的趋势和主题。</p>
<h3 id=获取新闻文章>获取新闻文章</h3>
<p>这一章的数据集是从 reddit 获得的网页链接，reddit 的 app 审核机制不是很严格(?)因此我终于拿到了墙外的 api，使用 requests 下载又费了一番功夫，使用书上源码的 url 下载总是 403 错误，研究了好半天 reddit 的 api，发现 reddit 的 url 改成了(new, top, &mldr;)，修改之后总算完成了链接的索引</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># get_links.py</span>
<span style=color:#75715e># -*- coding: utf-8 -*-</span>
<span style=color:#f92672>import</span> json
<span style=color:#f92672>import</span> os
<span style=color:#f92672>import</span> requests
<span style=color:#f92672>import</span> getpass
<span style=color:#f92672>import</span> time

<span style=color:#75715e># 需要的一些凭证</span>
CLIENT_ID <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;xxxxxxxxxxx&#34;</span>
CLIENT_SECRET <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;xxxxxxxxxxx&#34;</span>
USER_AGENT <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;python:xxxxxxxxx (by /u/xxxxxxxxx)&#34;</span>
USERNAME <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;xxxxxxxx&#34;</span>
PASSWORD <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;xxxxxxxxxxxxxx&#34;</span>

<span style=color:#75715e># requests使用代理</span>
proxies <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#34;http&#34;</span>: <span style=color:#e6db74>&#34;socks5://xxxxxx&#34;</span>, <span style=color:#e6db74>&#34;https&#34;</span>: <span style=color:#e6db74>&#34;socks5://xxxxxx&#34;</span>}


<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>login</span>(username, password):
    <span style=color:#66d9ef>if</span> password <span style=color:#f92672>is</span> <span style=color:#66d9ef>None</span>:
        password <span style=color:#f92672>=</span> getpass<span style=color:#f92672>.</span>getpass(
            <span style=color:#e6db74>&#34;Enter reddit password for user </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>: &#34;</span><span style=color:#f92672>.</span>format(username)
        )
    headers <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#34;User-Agent&#34;</span>: USER_AGENT}
    <span style=color:#75715e># 使用凭据设置身份验证对象</span>
    client_auth <span style=color:#f92672>=</span> requests<span style=color:#f92672>.</span>auth<span style=color:#f92672>.</span>HTTPBasicAuth(CLIENT_ID, CLIENT_SECRET)
    post_data <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#34;grant_type&#34;</span>: <span style=color:#e6db74>&#34;password&#34;</span>, <span style=color:#e6db74>&#34;username&#34;</span>: username, <span style=color:#e6db74>&#34;password&#34;</span>: password}
    response <span style=color:#f92672>=</span> requests<span style=color:#f92672>.</span>post(
        <span style=color:#e6db74>&#34;https://www.reddit.com/api/v1/access_token&#34;</span>,
        proxies<span style=color:#f92672>=</span>proxies,
        auth<span style=color:#f92672>=</span>client_auth,
        data<span style=color:#f92672>=</span>post_data,
        headers<span style=color:#f92672>=</span>headers,
    )
    <span style=color:#66d9ef>return</span> response<span style=color:#f92672>.</span>json()


<span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;__main__&#34;</span>:
    <span style=color:#75715e># 调用login获取token</span>
    <span style=color:#75715e># token = login(USERNAME, PASSWORD)</span>
    <span style=color:#75715e># print(token)</span>

    token <span style=color:#f92672>=</span> {
        <span style=color:#e6db74>&#34;access_token&#34;</span>: <span style=color:#e6db74>&#34;xxxxxxxxxxxxxxxxxxxxxxxx&#34;</span>,
        <span style=color:#e6db74>&#34;token_type&#34;</span>: <span style=color:#e6db74>&#34;xxxxx&#34;</span>,
        <span style=color:#e6db74>&#34;expires_in&#34;</span>: <span style=color:#ae81ff>3600</span>,
        <span style=color:#e6db74>&#34;scope&#34;</span>: <span style=color:#e6db74>&#34;*&#34;</span>,
    }

    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>get_links</span>(subreddit, token, n_pages<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>):
        <span style=color:#75715e># 存放链接信息</span>
        stories <span style=color:#f92672>=</span> []
        after <span style=color:#f92672>=</span> <span style=color:#66d9ef>None</span>
        <span style=color:#66d9ef>for</span> page_number <span style=color:#f92672>in</span> range(n_pages):
            <span style=color:#75715e># 进行调用之前等待，以避免超过API限制</span>
            print(<span style=color:#e6db74>&#34;等待2s...&#34;</span>)
            time<span style=color:#f92672>.</span>sleep(<span style=color:#ae81ff>2</span>)
            <span style=color:#75715e># 设置标头进行调用</span>
            headers <span style=color:#f92672>=</span> {
                <span style=color:#e6db74>&#34;Authorization&#34;</span>: <span style=color:#e6db74>&#34;bearer </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(token[<span style=color:#e6db74>&#34;access_token&#34;</span>]),
                <span style=color:#e6db74>&#34;User-Agent&#34;</span>: USER_AGENT,
            }
            <span style=color:#75715e># top为最热链接，这里也可以换成new</span>
            url <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;https://oauth.reddit.com/r/</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>/top?limit=100&#34;</span><span style=color:#f92672>.</span>format(subreddit)
            <span style=color:#66d9ef>if</span> after:
                url <span style=color:#f92672>+=</span> <span style=color:#e6db74>&#34;&amp;after=</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(after)
            <span style=color:#66d9ef>while</span> <span style=color:#66d9ef>True</span>:
                <span style=color:#66d9ef>try</span>:
                    response <span style=color:#f92672>=</span> requests<span style=color:#f92672>.</span>get(
                        url, proxies<span style=color:#f92672>=</span>proxies, headers<span style=color:#f92672>=</span>headers, timeout<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>
                    )
                    result <span style=color:#f92672>=</span> response<span style=color:#f92672>.</span>json()
                    <span style=color:#75715e># 获取下一个循环的cursor</span>
                    after <span style=color:#f92672>=</span> result[<span style=color:#e6db74>&#34;data&#34;</span>][<span style=color:#e6db74>&#34;after&#34;</span>]
                <span style=color:#66d9ef>except</span>:
                    print(<span style=color:#e6db74>&#34;requests出错等待...&#34;</span>)
                    time<span style=color:#f92672>.</span>sleep(<span style=color:#ae81ff>2</span>)
                <span style=color:#66d9ef>else</span>:
                    <span style=color:#66d9ef>break</span>
            <span style=color:#75715e># 将所有新闻项添加到story列表中</span>
            <span style=color:#66d9ef>for</span> story <span style=color:#f92672>in</span> result[<span style=color:#e6db74>&#34;data&#34;</span>][<span style=color:#e6db74>&#34;children&#34;</span>]:
                stories<span style=color:#f92672>.</span>append(
                    (
                        story[<span style=color:#e6db74>&#34;data&#34;</span>][<span style=color:#e6db74>&#34;title&#34;</span>],
                        story[<span style=color:#e6db74>&#34;data&#34;</span>][<span style=color:#e6db74>&#34;url&#34;</span>],
                        story[<span style=color:#e6db74>&#34;data&#34;</span>][<span style=color:#e6db74>&#34;score&#34;</span>],
                    )
                )
        <span style=color:#66d9ef>return</span> stories

    stories <span style=color:#f92672>=</span> get_links(<span style=color:#e6db74>&#34;worldnews&#34;</span>, token)
    base_folder <span style=color:#f92672>=</span> os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>dirname(os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>abspath(__file__))
    data_folder <span style=color:#f92672>=</span> os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(base_folder, <span style=color:#e6db74>&#34;raw&#34;</span>)
    <span style=color:#75715e># 这里我将所有的链接都存在了文件里，因为获取这些网站的内容要很久</span>
    <span style=color:#66d9ef>with</span> open(os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(base_folder, <span style=color:#e6db74>&#34;stories2.txt&#34;</span>), <span style=color:#e6db74>&#34;w&#34;</span>) <span style=color:#66d9ef>as</span> f:
        <span style=color:#66d9ef>for</span> link <span style=color:#f92672>in</span> stories:
            f<span style=color:#f92672>.</span>write(json<span style=color:#f92672>.</span>dumps(list(link)))
            f<span style=color:#f92672>.</span>write(<span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>)
</code></pre></div><h3 id=从网站抽取文本>从网站抽取文本</h3>
<p>api/top 总共有 500 个网站，我又获取了 api/new 的 490 个，总共下载了半个小时，失败了 300。。。</p>
<p>最后成功下载的网站数为 365</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># get_data.py</span>
<span style=color:#75715e># -*- coding: utf-8 -*-</span>
<span style=color:#f92672>import</span> hashlib
<span style=color:#f92672>import</span> os
<span style=color:#f92672>import</span> requests
<span style=color:#f92672>import</span> json


proxies <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#34;http&#34;</span>: <span style=color:#e6db74>&#34;socks5://xxxxxxxxxxxx&#34;</span>, <span style=color:#e6db74>&#34;https&#34;</span>: <span style=color:#e6db74>&#34;socks5://xxxxxxxxxxxxx&#34;</span>}


<span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;__main__&#34;</span>:
    base_folder <span style=color:#f92672>=</span> os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>dirname(os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>abspath(__file__))
    data_folder <span style=color:#f92672>=</span> os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(base_folder, <span style=color:#e6db74>&#34;raw&#34;</span>)
    <span style=color:#75715e># 读取链接数据</span>
    <span style=color:#66d9ef>with</span> open(os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(base_folder, <span style=color:#e6db74>&#34;stories1.txt&#34;</span>), <span style=color:#e6db74>&#34;r&#34;</span>) <span style=color:#66d9ef>as</span> f:
        temp <span style=color:#f92672>=</span> f<span style=color:#f92672>.</span>readlines()
    stories <span style=color:#f92672>=</span> []
    <span style=color:#66d9ef>for</span> l <span style=color:#f92672>in</span> temp:
        stories<span style=color:#f92672>.</span>append(json<span style=color:#f92672>.</span>loads(l))

    <span style=color:#75715e># 获取网页内容</span>
    number_errors <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
    <span style=color:#66d9ef>for</span> title, url, score <span style=color:#f92672>in</span> stories:
        print(url)
        output_filename <span style=color:#f92672>=</span> hashlib<span style=color:#f92672>.</span>md5(url<span style=color:#f92672>.</span>encode())<span style=color:#f92672>.</span>hexdigest()
        fullpath <span style=color:#f92672>=</span> os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(data_folder, output_filename <span style=color:#f92672>+</span> <span style=color:#e6db74>&#34;.txt&#34;</span>)
        <span style=color:#66d9ef>try</span>:
            response <span style=color:#f92672>=</span> requests<span style=color:#f92672>.</span>get(url, proxies<span style=color:#f92672>=</span>proxies, timeout<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>)
            data <span style=color:#f92672>=</span> response<span style=color:#f92672>.</span>text
            <span style=color:#66d9ef>with</span> open(fullpath, <span style=color:#e6db74>&#34;w&#34;</span>) <span style=color:#66d9ef>as</span> outf:
                outf<span style=color:#f92672>.</span>write(data)
        <span style=color:#66d9ef>except</span> <span style=color:#a6e22e>Exception</span> <span style=color:#66d9ef>as</span> e:
            number_errors <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
            <span style=color:#75715e># 输出出错数量</span>
            print(<span style=color:#e6db74>&#34;出错：</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(number_errors))
</code></pre></div><hr>
<p>下载下来的网页全是 html 文件，要从中提取出有用的信息，这里使用较为通用的 lxml 库，其它处理 html 的库还有 BeautifulSoup 等。</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># get_content.py</span>
<span style=color:#75715e># -*- coding: utf-8 -*-</span>
<span style=color:#f92672>import</span> os
<span style=color:#f92672>from</span> lxml <span style=color:#f92672>import</span> html, etree

<span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;__main__&#34;</span>:
    base_folder <span style=color:#f92672>=</span> os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>dirname(os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>abspath(__file__))
    data_folder <span style=color:#f92672>=</span> os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(base_folder, <span style=color:#e6db74>&#34;raw&#34;</span>)
    <span style=color:#75715e># 输出变成纯文本文件的路径</span>
    text_output_folder <span style=color:#f92672>=</span> os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(base_folder, <span style=color:#e6db74>&#34;textonly&#34;</span>)
    filenames <span style=color:#f92672>=</span> [
        os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(data_folder, filename) <span style=color:#66d9ef>for</span> filename <span style=color:#f92672>in</span> os<span style=color:#f92672>.</span>listdir(data_folder)
    ]
    <span style=color:#75715e># 存放不可能包含新闻内容的节点</span>
    skip_node_types <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#34;script&#34;</span>, <span style=color:#e6db74>&#34;head&#34;</span>, <span style=color:#e6db74>&#34;style&#34;</span>, etree<span style=color:#f92672>.</span>Comment]
    <span style=color:#75715e># 把html文件解析成lxml对象</span>
    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>get_text_from_file</span>(filename):
        <span style=color:#66d9ef>with</span> open(filename, <span style=color:#e6db74>&#34;r&#34;</span>) <span style=color:#66d9ef>as</span> inf:
            html_tree <span style=color:#f92672>=</span> html<span style=color:#f92672>.</span>parse(inf)
        <span style=color:#66d9ef>return</span> get_text_from_node(html_tree<span style=color:#f92672>.</span>getroot())

    <span style=color:#75715e># 抽取子节点中的文本内容，最后返回拼接在一起的所有子节点的文本</span>
    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>get_text_from_node</span>(node):
        <span style=color:#66d9ef>if</span> len(node) <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>:
            <span style=color:#75715e># 没有子节点，直接返回内容</span>
            <span style=color:#66d9ef>if</span> node<span style=color:#f92672>.</span>text:
                <span style=color:#66d9ef>return</span> node<span style=color:#f92672>.</span>text
            <span style=color:#66d9ef>else</span>:
                <span style=color:#66d9ef>return</span> <span style=color:#e6db74>&#34;&#34;</span>
        <span style=color:#66d9ef>else</span>:
            <span style=color:#75715e># 有子节点，递归调用得到内容</span>
            results <span style=color:#f92672>=</span> (
                get_text_from_node(child)
                <span style=color:#66d9ef>for</span> child <span style=color:#f92672>in</span> node
                <span style=color:#66d9ef>if</span> child<span style=color:#f92672>.</span>tag <span style=color:#f92672>not</span> <span style=color:#f92672>in</span> skip_node_types
            )
        result <span style=color:#f92672>=</span> str<span style=color:#f92672>.</span>join(<span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, (r <span style=color:#66d9ef>for</span> r <span style=color:#f92672>in</span> results <span style=color:#66d9ef>if</span> len(r) <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>1</span>))
        <span style=color:#75715e># 检查文本长度</span>
        <span style=color:#66d9ef>if</span> len(result) <span style=color:#f92672>&gt;=</span> <span style=color:#ae81ff>100</span>:
            <span style=color:#66d9ef>return</span> result
        <span style=color:#66d9ef>else</span>:
            <span style=color:#66d9ef>return</span> <span style=color:#e6db74>&#34;&#34;</span>

    <span style=color:#66d9ef>for</span> filename <span style=color:#f92672>in</span> os<span style=color:#f92672>.</span>listdir(data_folder):
        text <span style=color:#f92672>=</span> get_text_from_file(os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(data_folder, filename))
        <span style=color:#66d9ef>with</span> open(os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(text_output_folder, filename), <span style=color:#e6db74>&#34;w&#34;</span>) <span style=color:#66d9ef>as</span> outf:
            outf<span style=color:#f92672>.</span>write(text)
</code></pre></div><h3 id=新闻语料聚类>新闻语料聚类</h3>
<p>k-means 算法</p>
<p>k-means 聚类算法迭代寻找最能够代表数据的聚类质心点。算法开始时使用从训练数据中随机选取的几个数据点作为质心点。k-means 中的 k 表示寻找多少个质心点，同时也是算法将会找到的簇的数量。步骤：</p>
<ul>
<li>为每一个数据点分配簇标签<br>
为每个个体设置一个标签，将它和最近的质心点联系起来，标签相同的个体属于同一个簇</li>
<li>更新各簇的质心点</li>
</ul>
<p>每次更新质心点时，所有质心点将会小范围移动，这会轻微改变每个数据点在簇内的位置，从而引发下一次迭代时质心点的变动</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># -*- coding: utf-8 -*-</span>
<span style=color:#f92672>import</span> os
<span style=color:#f92672>from</span> sklearn.cluster <span style=color:#f92672>import</span> KMeans
<span style=color:#75715e># TfidfVectorizer向量化工具，根据词语出现在多少篇文章中，对词语计数进行加权</span>
<span style=color:#75715e># 出现在较多文档中的词语权重较低（用文档集数量除以词语出现在的文档的数量，然后取对数）</span>
<span style=color:#f92672>from</span> sklearn.feature_extraction.text <span style=color:#f92672>import</span> TfidfVectorizer
<span style=color:#f92672>from</span> sklearn.pipeline <span style=color:#f92672>import</span> Pipeline
<span style=color:#f92672>from</span> collections <span style=color:#f92672>import</span> Counter
<span style=color:#f92672>from</span> scipy.sparse <span style=color:#f92672>import</span> csr_matrix  <span style=color:#75715e># 稀疏矩阵</span>
<span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
<span style=color:#f92672>from</span> scipy.sparse.csgraph <span style=color:#f92672>import</span> minimum_spanning_tree  <span style=color:#75715e># 计算最小生成树MST</span>
<span style=color:#f92672>from</span> scipy.sparse.csgraph <span style=color:#f92672>import</span> connected_components  <span style=color:#75715e># 连通分支</span>
<span style=color:#f92672>from</span> sklearn.base <span style=color:#f92672>import</span> BaseEstimator, ClusterMixin
<span style=color:#f92672>from</span> sklearn.cluster <span style=color:#f92672>import</span> MiniBatchKMeans
<span style=color:#f92672>from</span> sklearn.feature_extraction.text <span style=color:#f92672>import</span> HashingVectorizer


base_folder <span style=color:#f92672>=</span> os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>dirname(os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>abspath(__file__))
data_folder <span style=color:#f92672>=</span> os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(base_folder, <span style=color:#e6db74>&#34;raw&#34;</span>)
text_output_folder <span style=color:#f92672>=</span> os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(base_folder, <span style=color:#e6db74>&#34;textonly&#34;</span>)

<span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;__main__&#34;</span>:
    <span style=color:#75715e># 分簇的数量</span>
    n_clusters <span style=color:#f92672>=</span> <span style=color:#ae81ff>10</span>
    pipeline <span style=color:#f92672>=</span> Pipeline(
        [
            (<span style=color:#e6db74>&#34;feature_extraction&#34;</span>, TfidfVectorizer(max_df<span style=color:#f92672>=</span><span style=color:#ae81ff>0.4</span>)),  <span style=color:#75715e># 特征抽取，忽略出现在40%文档中的词语（删除功能词）</span>
            (<span style=color:#e6db74>&#34;clusterer&#34;</span>, KMeans(n_clusters<span style=color:#f92672>=</span>n_clusters)),  <span style=color:#75715e># 调用k-means算法</span>
        ]
    )
    documents <span style=color:#f92672>=</span> [
        open(os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(text_output_folder, filename))<span style=color:#f92672>.</span>read()
        <span style=color:#66d9ef>for</span> filename <span style=color:#f92672>in</span> os<span style=color:#f92672>.</span>listdir(text_output_folder)
    ]
    <span style=color:#75715e># 不为fit函数指定目标类别，进行训练</span>
    pipeline<span style=color:#f92672>.</span>fit(documents)
    <span style=color:#75715e># 使用训练过的算法预测</span>
    <span style=color:#75715e># labels包含每个数据点的簇标签，标签相同的数据点属于同一个簇，标签本身没有含义</span>
    labels <span style=color:#f92672>=</span> pipeline<span style=color:#f92672>.</span>predict(documents)

    <span style=color:#75715e># 使用Counter类查看每个簇的数据点数量</span>
    c <span style=color:#f92672>=</span> Counter(labels)
    <span style=color:#66d9ef>for</span> cluster_number <span style=color:#f92672>in</span> range(n_clusters):
        print(
            <span style=color:#e6db74>&#34;Cluster </span><span style=color:#e6db74>{}</span><span style=color:#e6db74> contains </span><span style=color:#e6db74>{}</span><span style=color:#e6db74> samples&#34;</span><span style=color:#f92672>.</span>format(cluster_number, c[cluster_number])
        )
</code></pre></div><p>Output:</p>
<pre><code>Cluster 0 contains 2 samples
Cluster 1 contains 4 samples
Cluster 2 contains 1 samples
Cluster 3 contains 2 samples
Cluster 4 contains 329 samples
Cluster 5 contains 7 samples
Cluster 6 contains 2 samples
Cluster 7 contains 13 samples
Cluster 8 contains 3 samples
Cluster 9 contains 2 samples
</code></pre>
<hr>
<p>聚类分析主要是探索性分析，因此很难有效地评估结果的好坏，如果有测试集，可以对其分析来评价效果</p>
<p>对于 k-means 算法，寻找新质心点的标准是，最小化每个数据点到最近质心点的距离。这叫作算法的惯性权重（inertia），任何经过训练的 KMeans 实例都有该属性</p>
<p>下面将 n_clusters 依次取 2 到 20 之间的值，每取一个值，k-means 算法运行 10 次。每次运行算法都记录惯性权重。</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># 惯性权重，这个值没有意义，但是可以用来确定n_clusters</span>
    print(pipeline<span style=color:#f92672>.</span>named_steps[<span style=color:#e6db74>&#34;clusterer&#34;</span>]<span style=color:#f92672>.</span>inertia_)
    print()
    inertia_scores <span style=color:#f92672>=</span> []
    n_clusters_values <span style=color:#f92672>=</span> list(range(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>20</span>))
    <span style=color:#66d9ef>for</span> n_clusters <span style=color:#f92672>in</span> n_clusters_values:
        <span style=color:#75715e># 当前的惯性权重组</span>
        cur_inertia_scores <span style=color:#f92672>=</span> []
        X <span style=color:#f92672>=</span> TfidfVectorizer(max_df<span style=color:#f92672>=</span><span style=color:#ae81ff>0.4</span>)<span style=color:#f92672>.</span>fit_transform(documents)
        <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>10</span>):
            km <span style=color:#f92672>=</span> KMeans(n_clusters<span style=color:#f92672>=</span>n_clusters)<span style=color:#f92672>.</span>fit(X)
            cur_inertia_scores<span style=color:#f92672>.</span>append(km<span style=color:#f92672>.</span>inertia_)
        inertia_scores<span style=color:#f92672>.</span>append(cur_inertia_scores)
        print(<span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{}</span><span style=color:#e6db74> : </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(n_clusters, np<span style=color:#f92672>.</span>mean(cur_inertia_scores)))
</code></pre></div><p>Output:</p>
<pre><code>291.45747555507467

2 : 310.72961350285766
3 : 305.7904332223444
4 : 302.18859768191396
5 : 300.28785590112705
6 : 297.48005120447067
7 : 294.226862724111
8 : 292.340968109182
9 : 291.18707107605024
10 : 289.46981977256536
11 : 287.9333326469133
12 : 285.0561596766078
13 : 284.33745019948356
14 : 282.71178879028537
15 : 280.94991762471807
16 : 279.9555799316599
17 : 278.3825941905214
18 : 274.94616060558434
19 : 275.0297854253871
</code></pre>
<hr>
<p>将上表作图</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#f92672>import</span> plotly
    data <span style=color:#f92672>=</span> plotly<span style=color:#f92672>.</span>graph_objs<span style=color:#f92672>.</span>Scatter(
        x<span style=color:#f92672>=</span>list(range(<span style=color:#ae81ff>18</span>)),
        y<span style=color:#f92672>=</span>[
            <span style=color:#ae81ff>310.73</span>,
            <span style=color:#ae81ff>305.79</span>,
            <span style=color:#ae81ff>302.18</span>,
            <span style=color:#ae81ff>300.28</span>,
            <span style=color:#ae81ff>297.48</span>,
            <span style=color:#ae81ff>294.22</span>,
            <span style=color:#ae81ff>292.34</span>,
            <span style=color:#ae81ff>291.18</span>,
            <span style=color:#ae81ff>289.46</span>,
            <span style=color:#ae81ff>287.93</span>,
            <span style=color:#ae81ff>285.05</span>,
            <span style=color:#ae81ff>284.33</span>,
            <span style=color:#ae81ff>282.71</span>,
            <span style=color:#ae81ff>280.94</span>,
            <span style=color:#ae81ff>279.95</span>,
            <span style=color:#ae81ff>278.38</span>,
            <span style=color:#ae81ff>274.94</span>,
            <span style=color:#ae81ff>275.02</span>,
        ],
    )
    fig <span style=color:#f92672>=</span> plotly<span style=color:#f92672>.</span>graph_objs<span style=color:#f92672>.</span>Figure(data)
    fig<span style=color:#f92672>.</span>show()
</code></pre></div><p>Output:</p>
<p><figure>
<a href=/img/in-post/data-mining/ch10/10.1.png>
<img src=/img/in-post/data-mining/ch10/10.1.png loading=lazy alt=10.1>
</a>
<figcaption>10.1</figcaption>
</figure></p>
<hr>
<p>根据上图可以发现在 n_clusters=9 和 15 时拐点比较明显，这里为了方便计算，我们按照书上选择 6</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># 设置n_clusters值为6， 重新运行算法</span>
    n_clusters <span style=color:#f92672>=</span> <span style=color:#ae81ff>6</span>
    pipeline <span style=color:#f92672>=</span> Pipeline(
        [
            (<span style=color:#e6db74>&#34;feature_extraction&#34;</span>, TfidfVectorizer(max_df<span style=color:#f92672>=</span><span style=color:#ae81ff>0.4</span>)),
            (<span style=color:#e6db74>&#34;clusterer&#34;</span>, KMeans(n_clusters<span style=color:#f92672>=</span>n_clusters)),
        ]
    )
    pipeline<span style=color:#f92672>.</span>fit(documents)
    labels <span style=color:#f92672>=</span> pipeline<span style=color:#f92672>.</span>predict(documents)
    <span style=color:#75715e># 获取特征的所对应的词</span>
    terms <span style=color:#f92672>=</span> pipeline<span style=color:#f92672>.</span>named_steps[<span style=color:#e6db74>&#34;feature_extraction&#34;</span>]<span style=color:#f92672>.</span>get_feature_names()
    <span style=color:#75715e># 统计6个簇中每个簇的元素个数</span>
    c <span style=color:#f92672>=</span> Counter(labels)
    <span style=color:#66d9ef>for</span> cluster_number <span style=color:#f92672>in</span> range(n_clusters):
        print(
            <span style=color:#e6db74>&#34;Cluster </span><span style=color:#e6db74>{}</span><span style=color:#e6db74> contains </span><span style=color:#e6db74>{}</span><span style=color:#e6db74> samples&#34;</span><span style=color:#f92672>.</span>format(cluster_number, c[cluster_number])
        )
        print(<span style=color:#e6db74>&#34; Most important terms&#34;</span>)
        centroid <span style=color:#f92672>=</span> pipeline<span style=color:#f92672>.</span>named_steps[<span style=color:#e6db74>&#34;clusterer&#34;</span>]<span style=color:#f92672>.</span>cluster_centers_[cluster_number]
        most_important <span style=color:#f92672>=</span> centroid<span style=color:#f92672>.</span>argsort()
        <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>5</span>):
            <span style=color:#75715e># 排列是非降序排列</span>
            term_index <span style=color:#f92672>=</span> most_important[<span style=color:#f92672>-</span>(i <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>)]
            <span style=color:#75715e># 输出序号，词语，得分</span>
            print(
                <span style=color:#e6db74>&#34; </span><span style=color:#e6db74>{0}</span><span style=color:#e6db74> </span><span style=color:#e6db74>{1}</span><span style=color:#e6db74> (score: </span><span style=color:#e6db74>{2:.4f}</span><span style=color:#e6db74>)&#34;</span><span style=color:#f92672>.</span>format(
                    i <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>, terms[term_index], centroid[term_index]
                )
            )
</code></pre></div><p>Output:</p>
<pre><code>Cluster 0 contains 15 samples
Most important terms
1 games (score: 0.2351)
2 olympic (score: 0.1921)
3 athletes (score: 0.1555)
4 ioc (score: 0.1383)
5 tokyo (score: 0.1365)
Cluster 1 contains 48 samples
Most important terms
1 she (score: 0.0442)
2 her (score: 0.0409)
3 masks (score: 0.0381)
4 monday (score: 0.0298)
5 23 (score: 0.0294)
Cluster 2 contains 150 samples
Most important terms
1 you (score: 0.0342)
2 measures (score: 0.0246)
3 would (score: 0.0246)
4 country (score: 0.0233)
5 our (score: 0.0231)
Cluster 3 contains 14 samples
Most important terms
1 your (score: 0.1922)
2 you (score: 0.1833)
3 robot (score: 0.1644)
4 unusual (score: 0.1505)
5 box (score: 0.1478)
Cluster 4 contains 128 samples
Most important terms
1 india (score: 0.0222)
2 et (score: 0.0189)
3 tablet (score: 0.0156)
4 app (score: 0.0140)
5 2020 (score: 0.0129)
Cluster 5 contains 10 samples
Most important terms
1 cache (score: 0.2858)
2 found (score: 0.2672)
3 server (score: 0.2484)
4 error (score: 0.2358)
5 mod_security (score: 0.1450)
</code></pre>
<hr>
<p>上面代码在流水线最后一步的 k-means 实例上调用转换方法。得到的矩阵有六个特征，数据量跟文档的长度相同，shape=(365,6)</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># 用K-means算法转化特征</span>
    X <span style=color:#f92672>=</span> pipeline<span style=color:#f92672>.</span>transform(documents)
</code></pre></div><h3 id=聚类融合>聚类融合</h3>
<p>聚类算法也可以进行融合，这样做的主要原因是，融合后得到的算法能够平滑算法多次运行所得到的不同结果。多次运行 k-means 算法得到的结果因最初选择的质心点不同而不同。多次运行算法，综合考虑所得到的多个结果，可以减少波动。聚类融合方法还可以降低参数选择对最终结果的影响。大多数聚类算法对参数选择很敏感,参数稍有不同将带来不同的聚类结果</p>
<p>最基本的融合方法是对数据进行多次聚类，每次都记录各个数据点的簇标签。然后计算每两个数据点被分到同一个簇的次数。这就是<em>证据累积</em>算法（Evidence Accumulation Clustering，EAC）的精髓</p>
<ul>
<li>第一步，使用 k-means 等低水平的聚类算法对数据集进行多次聚类，记录每一次迭代两个数据点出现在同一簇的频率，将结果保存到共协矩阵（coassociation）中</li>
<li>第二步，使用另外一种聚类算法——分级聚类对第一步得到的共协矩阵进行聚类分析。分级聚类一个比较有趣的特性是，它等价于寻找一棵把所有节点连接到一起的树，并把权重低的边去掉。</li>
</ul>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># 遍历所有标签，记录具有相同标签的两个数据点的位置，创建共协矩阵</span>
    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>create_coassociation_matrix</span>(labels):
        rows <span style=color:#f92672>=</span> []
        cols <span style=color:#f92672>=</span> []
        <span style=color:#75715e># labels种类</span>
        unique_labels <span style=color:#f92672>=</span> set(labels)
        <span style=color:#66d9ef>for</span> label <span style=color:#f92672>in</span> unique_labels:
            <span style=color:#75715e># 找出label值相同的数据点</span>
            indices <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>where(labels <span style=color:#f92672>==</span> label)[<span style=color:#ae81ff>0</span>]
            <span style=color:#75715e># 记录他们的位置：如1、3点的数据均为1，即1和1相同，1和3相同，3和1相同，3和3相同</span>
            <span style=color:#75715e># 行和列均增加了4个indices*indices个数字</span>
            <span style=color:#66d9ef>for</span> index1 <span style=color:#f92672>in</span> indices:
                <span style=color:#66d9ef>for</span> index2 <span style=color:#f92672>in</span> indices:
                    rows<span style=color:#f92672>.</span>append(index1)
                    cols<span style=color:#f92672>.</span>append(index2)
        <span style=color:#75715e># 返回给定shape和type的值全为1的矩阵</span>
        data <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>ones((len(rows),))
        <span style=color:#75715e># 创建稀疏矩阵满足：a[rows[k], cols[k]] = data[k]</span>
        <span style=color:#66d9ef>return</span> csr_matrix((data, (rows, cols)), dtype<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;float&#34;</span>)

    <span style=color:#75715e># 使用标签生成共协矩阵</span>
    C <span style=color:#f92672>=</span> create_coassociation_matrix(labels)
    <span style=color:#75715e># 这里书上说多输入几次C看看结果，我没有用notebook，但是使用print输出是一样的，因此没有搞懂书上的含义</span>
    print(C)
    print((<span style=color:#ae81ff>365</span> <span style=color:#f92672>**</span> <span style=color:#ae81ff>2</span> <span style=color:#f92672>-</span> create_coassociation_matrix(labels)<span style=color:#f92672>.</span>nnz) <span style=color:#f92672>/</span> <span style=color:#ae81ff>365</span> <span style=color:#f92672>**</span> <span style=color:#ae81ff>2</span>)

    mst <span style=color:#f92672>=</span> minimum_spanning_tree(C)
    mst <span style=color:#f92672>=</span> minimum_spanning_tree(<span style=color:#f92672>-</span>C)

    pipeline<span style=color:#f92672>.</span>fit(documents)
    labels2 <span style=color:#f92672>=</span> pipeline<span style=color:#f92672>.</span>predict(documents)
    C2 <span style=color:#f92672>=</span> create_coassociation_matrix(labels2)
    C_sum <span style=color:#f92672>=</span> (C <span style=color:#f92672>+</span> C2) <span style=color:#f92672>/</span> <span style=color:#ae81ff>2</span>
    mst <span style=color:#f92672>=</span> minimum_spanning_tree(<span style=color:#f92672>-</span>C_sum)
    <span style=color:#75715e># 删除低于阈值的边</span>
    mst<span style=color:#f92672>.</span>data[mst<span style=color:#f92672>.</span>data <span style=color:#f92672>&gt;</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>] <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
    number_of_clusters, labels <span style=color:#f92672>=</span> connected_components(mst)
</code></pre></div><p>Output:</p>
<pre><code>(0, 0)	1.0
(0, 1)	1.0
(0, 2)	1.0
(0, 3)	1.0
(0, 4)	1.0
(0, 5)	1.0
(0, 6)	1.0
(0, 7)	1.0
(0, 8)	1.0
(0, 9)	1.0
(0, 10)	1.0
(0, 11)	1.0
(0, 12)	1.0
(0, 13)	1.0
:	:
(364, 350)	1.0
(364, 351)	1.0
(364, 352)	1.0
(364, 353)	1.0
(364, 354)	1.0
(364, 355)	1.0
(364, 356)	1.0
(364, 357)	1.0
(364, 358)	1.0
(364, 359)	1.0
(364, 360)	1.0
(364, 361)	1.0
(364, 362)	1.0
(364, 363)	1.0
(364, 364)	1.0
0.11092512666541565
</code></pre>
<hr>
<p>从图的理论角度看，生成树为所有节点都连接到一起的图。<em>最小生成树</em>（Minimum Spanning Tree，MST）即总权重最低的生成树。结合我们的应用来讲，图中的节点对应数据集中的个体，边的权重对应两个顶点被分到同一簇的次数——也就是共协矩阵所记录的值。</p>
<p>矩阵 C 中，值越高表示一组数据点被分到同一簇的次数越多——这个值表示相似度。相反，minimum_spanning_tree 函数的输入为距离，高的值反而表示相似度越小。这里又用到了一次取反</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    mst <span style=color:#f92672>=</span> minimum_spanning_tree(C)
    <span style=color:#75715e># 对C取反再计算最小生成树</span>
    mst <span style=color:#f92672>=</span> minimum_spanning_tree(<span style=color:#f92672>-</span>C)
    <span style=color:#75715e># 创建额外的标签</span>
    pipeline<span style=color:#f92672>.</span>fit(documents)
    labels2 <span style=color:#f92672>=</span> pipeline<span style=color:#f92672>.</span>predict(documents)
    C2 <span style=color:#f92672>=</span> create_coassociation_matrix(labels2)
    C_sum <span style=color:#f92672>=</span> (C <span style=color:#f92672>+</span> C2) <span style=color:#f92672>/</span> <span style=color:#ae81ff>2</span>
    <span style=color:#75715e># 生成阈值不全为1和0的最小生成树</span>
    mst <span style=color:#f92672>=</span> minimum_spanning_tree(<span style=color:#f92672>-</span>C_sum)
    <span style=color:#75715e># 删除低于阈值的边</span>
    mst<span style=color:#f92672>.</span>data[mst<span style=color:#f92672>.</span>data <span style=color:#f92672>&gt;</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>] <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
    number_of_clusters, labels <span style=color:#f92672>=</span> connected_components(mst)
    print(number_of_clusters)
    print(labels)
</code></pre></div><p>Output:</p>
<pre><code>2
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0, 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0, 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
</code></pre>
<hr>
<p>k-means 算法不考虑特征的权重，它寻找的是圆形簇（circular clusters）</p>
<p>证据累积算法的工作原理为重新把特征映射到新空间，每次运行 k-means 算法都相当于使用转换器对特征进行一次转换。</p>
<p>证据累积算法只关心数据点之间的距离而不是它们在原来特征空间的位置。对于没有规范化过的特征，仍然存在问题。因此，特征规范很重要，无论如何都要做（我们用 tf-idf 规范特征值，从而使特征具有相同的值域）</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># 创建证据累积算法类</span>
    <span style=color:#66d9ef>class</span> <span style=color:#a6e22e>EAC</span>(BaseEstimator, ClusterMixin):
        <span style=color:#66d9ef>def</span> __init__(
            self, n_clusterings<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>, cut_threshold<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>, n_clusters_range<span style=color:#f92672>=</span>(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>10</span>)
        ):
            self<span style=color:#f92672>.</span>n_clusterings <span style=color:#f92672>=</span> n_clusterings  <span style=color:#75715e># k-means算法运行次数</span>
            self<span style=color:#f92672>.</span>cut_threshold <span style=color:#f92672>=</span> cut_threshold  <span style=color:#75715e># 用来删除边的阈值</span>
            self<span style=color:#f92672>.</span>n_clusters_range <span style=color:#f92672>=</span> n_clusters_range  <span style=color:#75715e># 每次运行k-means算法要找到的簇的数量</span>

        <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>fit</span>(self, X, y<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>):
            <span style=color:#75715e># 进行指定次数的共协矩阵累加</span>
            C <span style=color:#f92672>=</span> sum(
                (
                    create_coassociation_matrix(self<span style=color:#f92672>.</span>_single_clustering(X))
                    <span style=color:#66d9ef>for</span> _ <span style=color:#f92672>in</span> range(self<span style=color:#f92672>.</span>n_clusterings)
                )
            )
            mst <span style=color:#f92672>=</span> minimum_spanning_tree(<span style=color:#f92672>-</span>C)
            mst<span style=color:#f92672>.</span>data[mst<span style=color:#f92672>.</span>data <span style=color:#f92672>&gt;</span> <span style=color:#f92672>-</span>self<span style=color:#f92672>.</span>cut_threshold] <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
            self<span style=color:#f92672>.</span>n_components, self<span style=color:#f92672>.</span>labels_ <span style=color:#f92672>=</span> connected_components(mst)
            <span style=color:#66d9ef>return</span> self

        <span style=color:#75715e># 进行一次集群</span>
        <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_single_clustering</span>(self, X):
            <span style=color:#75715e># 在给定范围中随机选择一个集群数</span>
            n_clusters <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>randint(<span style=color:#f92672>*</span>self<span style=color:#f92672>.</span>n_clusters_range)
            km <span style=color:#f92672>=</span> KMeans(n_clusters<span style=color:#f92672>=</span>n_clusters)
            <span style=color:#75715e># 返回由k-means计算得到的簇标签</span>
            <span style=color:#66d9ef>return</span> km<span style=color:#f92672>.</span>fit_predict(X)

    pipeline <span style=color:#f92672>=</span> Pipeline(
        [(<span style=color:#e6db74>&#34;feature_extraction&#34;</span>, TfidfVectorizer(max_df<span style=color:#f92672>=</span><span style=color:#ae81ff>0.4</span>)), (<span style=color:#e6db74>&#34;clusterer&#34;</span>, EAC())]
    )
    pipeline<span style=color:#f92672>.</span>fit(documents)
    number_of_clusters, labels <span style=color:#f92672>=</span> (
        pipeline[<span style=color:#e6db74>&#34;clusterer&#34;</span>]<span style=color:#f92672>.</span>n_components,
        pipeline[<span style=color:#e6db74>&#34;clusterer&#34;</span>]<span style=color:#f92672>.</span>labels_,
    )
    print(number_of_clusters)
    print(labels)

</code></pre></div><p>Output:</p>
<pre><code>1
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
</code></pre>
<p>总感觉有什么问题。。。 <code>(￣ε(#￣)☆╰╮o(￣皿￣///))</code></p>
<h3 id=线上学习>线上学习</h3>
<p>线上学习是指用新数据增量地改进模型。支持线上学习的算法可以先用一条或少量数据进行训练，随着更多新数据的添加，更新模型。</p>
<p>线上学习与流式学习（streaming-based learning）有关，但有几个重要的不同点。线上学习能够重新评估先前创建模型时所用到的数据，而对于后者，所有数据都只使用一次。</p>
<p>scikit-learn 提供了 MiniBatchKMeans 算法，可以用它来实现线上学习功能。这个类实现了 <code>partial_fit</code> 函数，接收一组数据，更新模型。调用<code>fit()</code>将会删除之前的训练结果，重新根据新数据进行训练。</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># 使用TfIDFVectorizer从数据集中抽取特征，创建矩阵X</span>
    n_clusters <span style=color:#f92672>=</span> <span style=color:#ae81ff>6</span>
    vec <span style=color:#f92672>=</span> TfidfVectorizer(max_df<span style=color:#f92672>=</span><span style=color:#ae81ff>0.4</span>)
    X <span style=color:#f92672>=</span> vec<span style=color:#f92672>.</span>fit_transform(documents)
    mbkm <span style=color:#f92672>=</span> MiniBatchKMeans(random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>14</span>, n_clusters<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>)
    batch_size <span style=color:#f92672>=</span> <span style=color:#ae81ff>10</span>
    <span style=color:#75715e># 随机从X矩阵中选择数据，模拟来自外部的新数据</span>
    <span style=color:#66d9ef>for</span> iteration <span style=color:#f92672>in</span> range(int(X<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>] <span style=color:#f92672>/</span> batch_size)):
        start <span style=color:#f92672>=</span> batch_size <span style=color:#f92672>*</span> iteration
        end <span style=color:#f92672>=</span> batch_size <span style=color:#f92672>*</span> (iteration <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>)
        mbkm<span style=color:#f92672>.</span>partial_fit(X[start:end])
    <span style=color:#75715e># 获取数据集聚类结果</span>
    labels <span style=color:#f92672>=</span> mbkm<span style=color:#f92672>.</span>predict(X)
    c <span style=color:#f92672>=</span> Counter(labels)
    <span style=color:#66d9ef>for</span> cluster_number <span style=color:#f92672>in</span> range(n_clusters):
        print(
            <span style=color:#e6db74>&#34;Cluster </span><span style=color:#e6db74>{}</span><span style=color:#e6db74> contains </span><span style=color:#e6db74>{}</span><span style=color:#e6db74> samples&#34;</span><span style=color:#f92672>.</span>format(cluster_number, c[cluster_number])
        )
</code></pre></div><p>Output:</p>
<pre><code>Cluster 0 contains 2 samples
Cluster 1 contains 362 samples
Cluster 2 contains 1 samples
Cluster 3 contains 0 samples
Cluster 4 contains 0 samples
Cluster 5 contains 0 samples
</code></pre>
<hr>
<p>由于 TfIDFVectorizer 不是在线算法，因此无法在流水线中使用</p>
<p>为了解决这个问题，我们使用 HashingVectorizer 类，它巧妙地使用散列算法极大地降低了计算词袋模型所需的内存开销，将数据的内容转换成散列值</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#66d9ef>class</span> <span style=color:#a6e22e>PartialFitPipeline</span>(Pipeline):
        <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>partial_fit</span>(self, X, y<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>):
            Xt <span style=color:#f92672>=</span> X
            <span style=color:#75715e># 经过最后一步之前的所有步转换</span>
            <span style=color:#66d9ef>for</span> name, transform <span style=color:#f92672>in</span> self<span style=color:#f92672>.</span>steps[:<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>]:
                Xt <span style=color:#f92672>=</span> transform<span style=color:#f92672>.</span>transform(Xt)
            <span style=color:#75715e>#　调用MiniBatchKMeans的partial_fit函数</span>
            <span style=color:#66d9ef>return</span> self<span style=color:#f92672>.</span>steps[<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>][<span style=color:#ae81ff>1</span>]<span style=color:#f92672>.</span>partial_fit(Xt, y<span style=color:#f92672>=</span>y)

    pipeline <span style=color:#f92672>=</span> PartialFitPipeline(
        [
            (<span style=color:#e6db74>&#34;feature_extraction&#34;</span>, HashingVectorizer()),
            (<span style=color:#e6db74>&#34;clusterer&#34;</span>, MiniBatchKMeans(random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>14</span>, n_clusters<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>)),
        ]
    )
    batch_size <span style=color:#f92672>=</span> <span style=color:#ae81ff>10</span>
    <span style=color:#66d9ef>for</span> iteration <span style=color:#f92672>in</span> range(int(len(documents) <span style=color:#f92672>/</span> batch_size)):
        start <span style=color:#f92672>=</span> batch_size <span style=color:#f92672>*</span> iteration
        end <span style=color:#f92672>=</span> batch_size <span style=color:#f92672>*</span> (iteration <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>)
        pipeline<span style=color:#f92672>.</span>partial_fit(documents[start:end])
    labels <span style=color:#f92672>=</span> pipeline<span style=color:#f92672>.</span>predict(documents)
    c <span style=color:#f92672>=</span> Counter(labels)
    <span style=color:#66d9ef>for</span> cluster_number <span style=color:#f92672>in</span> range(n_clusters):
        print(
            <span style=color:#e6db74>&#34;Cluster </span><span style=color:#e6db74>{}</span><span style=color:#e6db74> contains </span><span style=color:#e6db74>{}</span><span style=color:#e6db74> samples&#34;</span><span style=color:#f92672>.</span>format(cluster_number, c[cluster_number])
        )
</code></pre></div><p>Output:</p>
<pre><code>Cluster 0 contains 4 samples
Cluster 1 contains 76 samples
Cluster 2 contains 285 samples
Cluster 3 contains 0 samples
Cluster 4 contains 0 samples
Cluster 5 contains 0 samples
</code></pre>
<p>这一章的内容比较多，也学了挺久，虽然中间结果跟书上的差的有点多。。可能是因为最近新冠肺炎吧(￣_,￣ )</p>
<h2 id=第十一章>第十一章</h2>
<p>本章介绍如何使用深度神经网络识别图像中的物体</p>
<h3 id=深度神经网络>深度神经网络</h3>
<p>深度神经网络和第 8 章中的基本神经网络的差别在于规模大小。至少包含两层隐含层的神经网络被称为深度神经网络。神经网络的核心其实就是一系列矩阵运算，两个网络之间连接的权重可以用矩阵来表示。其中行表示前一层神经元，列表示后一层神经元，一个神经网络就可以用一组这样的矩阵来表示。除了神经元外，每层增加一个偏置项，它是一个特殊的神经元，永远处于激活状态，并且跟下一层的每一个神经元都有连接。</p>
<p>神经网络使用卷积层（一般来说，仅卷积神经网络包含该层）和池化层（pooling layer），池化层接收某个区域最大输出值，可以降低图像中的微小变动带来的噪音，减少（down-sample，降采样）信息量，这样后续各层所需工作量也会相应减少。</p>
<p>使用 Iris 数据集进行对比实验</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
<span style=color:#f92672>from</span> sklearn.datasets <span style=color:#f92672>import</span> load_iris
<span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> OneHotEncoder
<span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> train_test_split
<span style=color:#f92672>from</span> sklearn.metrics <span style=color:#f92672>import</span> classification_report
<span style=color:#f92672>from</span> keras.layers <span style=color:#f92672>import</span> Dense
<span style=color:#f92672>from</span> keras.models <span style=color:#f92672>import</span> Sequential
<span style=color:#f92672>from</span> matplotlib <span style=color:#f92672>import</span> pyplot <span style=color:#66d9ef>as</span> plt


iris <span style=color:#f92672>=</span> load_iris()
X <span style=color:#f92672>=</span> iris<span style=color:#f92672>.</span>data<span style=color:#f92672>.</span>astype(np<span style=color:#f92672>.</span>float32)
y_true <span style=color:#f92672>=</span> iris<span style=color:#f92672>.</span>target<span style=color:#f92672>.</span>astype(np<span style=color:#f92672>.</span>int32)

<span style=color:#75715e># 预处理数据集</span>
y_onehot <span style=color:#f92672>=</span> OneHotEncoder()<span style=color:#f92672>.</span>fit_transform(y_true<span style=color:#f92672>.</span>reshape(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>))
y_onehot <span style=color:#f92672>=</span> y_onehot<span style=color:#f92672>.</span>astype(np<span style=color:#f92672>.</span>int64)<span style=color:#f92672>.</span>todense()

X_train, X_test, y_train, y_test <span style=color:#f92672>=</span> train_test_split(X, y_onehot, random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>14</span>)
input_layer_size, hidden_layer_size, output_layer_size <span style=color:#f92672>=</span> <span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>6</span>, <span style=color:#ae81ff>3</span>
<span style=color:#75715e># 隐含层</span>
hidden_layer <span style=color:#f92672>=</span> Dense(output_dim<span style=color:#f92672>=</span>hidden_layer_size, input_dim<span style=color:#f92672>=</span>input_layer_size, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>)
<span style=color:#75715e># 输出层</span>
output_layer <span style=color:#f92672>=</span> Dense(output_layer_size, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;sigmoid&#39;</span>)
<span style=color:#75715e># 创建顺序模型</span>
model <span style=color:#f92672>=</span> Sequential(layers<span style=color:#f92672>=</span>[hidden_layer, output_layer])
<span style=color:#75715e># 为训练神经网络配置模型</span>
<span style=color:#75715e># 损失函数设置为均方误差，优化器设置为adam(亚当)即遵循原始文件中的默认参数，指定精度衡量标准</span>
model<span style=color:#f92672>.</span>compile(loss<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;mean_squared_error&#39;</span>, optimizer<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;adam&#39;</span>, metrics<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;accuracy&#39;</span>])
<span style=color:#75715e># 当一个完整的数据集通过了神经网络一次并且返回了一次，这个过程称为一次epoch</span>
<span style=color:#75715e># 为模型训练固定的epoch（数据集上的迭代）</span>
<span style=color:#75715e># 输出模式。0不输出，1每个epoch一个进度条，2一行每个epoch。</span>
history <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>fit(X_train, y_train, nb_epoch<span style=color:#f92672>=</span><span style=color:#ae81ff>100</span>, verbose<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>)
<span style=color:#75715e># 记录了连续几个epoch的训练损失值和度量值，以及验证损失值和验证度量值(如果适用的话)</span>
history<span style=color:#f92672>.</span>history
<span style=color:#75715e># 作图，绘制出epoch和loss关系图</span>
plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>10</span>))
plt<span style=color:#f92672>.</span>plot(history<span style=color:#f92672>.</span>epoch, history<span style=color:#f92672>.</span>history[<span style=color:#e6db74>&#39;loss&#39;</span>])
plt<span style=color:#f92672>.</span>xlabel(<span style=color:#e6db74>&#34;Epoch&#34;</span>)
plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#34;Loss&#34;</span>)
plt<span style=color:#f92672>.</span>show()

<span style=color:#75715e># 为输入样本生成输出预测，计算是分批进行的</span>
<span style=color:#75715e># 返回的是数值[0.9356668, 0.20588416, 0.00021186471],代表样本属于每个类别的概率</span>
y_pred <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>predict(X_test)
<span style=color:#75715e># 返回一串预测结果，样本属于哪一个类别</span>
y_pred <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>predict_classes(X_test)
y_pred <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>predict_classes(X_test)
print(classification_report(y_true<span style=color:#f92672>=</span>y_test<span style=color:#f92672>.</span>argmax(axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), y_pred<span style=color:#f92672>=</span>y_pred))
</code></pre></div><p>Output:</p>
<p><figure>
<a href=/img/in-post/data-mining/ch11/iris_100_epoch.png>
<img src=/img/in-post/data-mining/ch11/iris_100_epoch.png loading=lazy alt=iris_1>
</a>
<figcaption>iris_1</figcaption>
</figure></p>
<pre><code>              precision    recall  f1-score   support

           0       1.00      1.00      1.00        17
           1       1.00      0.08      0.14        13
           2       0.40      1.00      0.57         8

    accuracy                           0.68        38
   macro avg       0.80      0.69      0.57        38
weighted avg       0.87      0.68      0.62        38
</code></pre>
<hr>
<p>重复上面的操作，这次运行 1000 步，对比实验结果</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>hidden_layer <span style=color:#f92672>=</span> Dense(output_dim<span style=color:#f92672>=</span>hidden_layer_size, input_dim<span style=color:#f92672>=</span>input_layer_size, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>)
output_layer <span style=color:#f92672>=</span> Dense(output_layer_size, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;sigmoid&#39;</span>)
model <span style=color:#f92672>=</span> Sequential(layers<span style=color:#f92672>=</span>[hidden_layer, output_layer])
model<span style=color:#f92672>.</span>compile(loss<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;mean_squared_error&#39;</span>, optimizer<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;adam&#39;</span>, metrics<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;accuracy&#39;</span>])
history <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>fit(X_train, y_train, nb_epoch<span style=color:#f92672>=</span><span style=color:#ae81ff>1000</span>, verbose<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>12</span>, <span style=color:#ae81ff>8</span>))
plt<span style=color:#f92672>.</span>plot(history<span style=color:#f92672>.</span>epoch, history<span style=color:#f92672>.</span>history[<span style=color:#e6db74>&#39;loss&#39;</span>])
plt<span style=color:#f92672>.</span>xlabel(<span style=color:#e6db74>&#34;Epoch&#34;</span>)
plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#34;Loss&#34;</span>)
plt<span style=color:#f92672>.</span>show(<span style=color:#e6db74>&#34;keras_on_iris_2.png&#34;</span>)
y_pred <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>predict_classes(X_test)
print(classification_report(y_true<span style=color:#f92672>=</span>y_test<span style=color:#f92672>.</span>argmax(axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), y_pred<span style=color:#f92672>=</span>y_pred))
</code></pre></div><p>Output:</p>
<p><figure>
<a href=/img/in-post/data-mining/ch11/iris_1000_epoch.png>
<img src=/img/in-post/data-mining/ch11/iris_1000_epoch.png loading=lazy alt=iris_2>
</a>
<figcaption>iris_2</figcaption>
</figure></p>
<pre><code>              precision    recall  f1-score   support

           0       1.00      1.00      1.00        17
           1       1.00      1.00      1.00        13
           2       1.00      1.00      1.00         8

    accuracy                           1.00        38
   macro avg       1.00      1.00      1.00        38
weighted avg       1.00      1.00      1.00        38
</code></pre>
<p>从结果可以看出，经过 100 步训练的神经网络正确率达到了 68%，经过 1000 步训练后正确率达到了 100%</p>
<hr>
<p>验证码识别实验</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
<span style=color:#f92672>from</span> PIL <span style=color:#f92672>import</span> Image, ImageDraw, ImageFont
<span style=color:#f92672>from</span> skimage <span style=color:#f92672>import</span> transform <span style=color:#66d9ef>as</span> tf
<span style=color:#f92672>from</span> matplotlib <span style=color:#f92672>import</span> pyplot <span style=color:#66d9ef>as</span> plt
<span style=color:#f92672>from</span> sklearn.utils <span style=color:#f92672>import</span> check_random_state
<span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> OneHotEncoder
<span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> train_test_split
<span style=color:#f92672>from</span> keras.layers <span style=color:#f92672>import</span> Dense
<span style=color:#f92672>from</span> keras.models <span style=color:#f92672>import</span> Sequential
<span style=color:#f92672>from</span> skimage.measure <span style=color:#f92672>import</span> label, regionprops


<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>create_captcha</span>(text, shear<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>, size<span style=color:#f92672>=</span>(<span style=color:#ae81ff>100</span>, <span style=color:#ae81ff>30</span>), scale<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>):
    im <span style=color:#f92672>=</span> Image<span style=color:#f92672>.</span>new(<span style=color:#e6db74>&#34;L&#34;</span>, size, <span style=color:#e6db74>&#34;black&#34;</span>)
    draw <span style=color:#f92672>=</span> ImageDraw<span style=color:#f92672>.</span>Draw(im)
    font <span style=color:#f92672>=</span> ImageFont<span style=color:#f92672>.</span>truetype(
        <span style=color:#e6db74>&#34;/home/saltfish/Programming/Python/data_mining/ch11/FiraCode-Medium.otf&#34;</span>, <span style=color:#ae81ff>22</span>
    )
    draw<span style=color:#f92672>.</span>text((<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>), text, fill<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, font<span style=color:#f92672>=</span>font)
    image <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array(im)
    affine_tf <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>AffineTransform(shear<span style=color:#f92672>=</span>shear)
    image <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>warp(image, affine_tf)
    image <span style=color:#f92672>=</span> image <span style=color:#f92672>/</span> image<span style=color:#f92672>.</span>max()
    shape <span style=color:#f92672>=</span> image<span style=color:#f92672>.</span>shape
    <span style=color:#75715e># Apply scale</span>
    shapex, shapey <span style=color:#f92672>=</span> (shape[<span style=color:#ae81ff>0</span>] <span style=color:#f92672>*</span> scale, shape[<span style=color:#ae81ff>1</span>] <span style=color:#f92672>*</span> scale)
    image <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>resize(image, (shapex, shapey))
    <span style=color:#66d9ef>return</span> image

image <span style=color:#f92672>=</span> create_captcha(<span style=color:#e6db74>&#34;FISH&#34;</span>, shear<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>, scale<span style=color:#f92672>=</span><span style=color:#ae81ff>0.6</span>)
plt<span style=color:#f92672>.</span>imshow(image, cmap<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Greys&#34;</span>)
</code></pre></div><p>Output:</p>
<p><figure>
<a href=/img/in-post/data-mining/ch11/captcha_1.png>
<img src=/img/in-post/data-mining/ch11/captcha_1.png loading=lazy alt=captcha_1>
</a>
<figcaption>captcha_1</figcaption>
</figure></p>
<hr>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>segment_image</span>(image):
    <span style=color:#75715e># 标记找到连通的非黑色像素的子图像</span>
    labeled_image <span style=color:#f92672>=</span> label(image <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>0.2</span>, connectivity<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, background<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
    subimages <span style=color:#f92672>=</span> []
    <span style=color:#75715e># 拆分子图</span>
    <span style=color:#66d9ef>for</span> region <span style=color:#f92672>in</span> regionprops(labeled_image):
        <span style=color:#75715e># 提取子图</span>
        start_x, start_y, end_x, end_y <span style=color:#f92672>=</span> region<span style=color:#f92672>.</span>bbox
        subimages<span style=color:#f92672>.</span>append(image[start_x:end_x, start_y:end_y])
    <span style=color:#66d9ef>if</span> len(subimages) <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>:
        <span style=color:#75715e># 未找到子图，返回这个图片本身</span>
        <span style=color:#66d9ef>return</span> [
            image,
        ]
    <span style=color:#66d9ef>return</span> subimages

subimages <span style=color:#f92672>=</span> segment_image(image)
<span style=color:#75715e># 选出四张小图片</span>
f, axes <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>subplots(<span style=color:#ae81ff>1</span>, len(subimages), figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>3</span>))
<span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(len(subimages)):
    axes[i]<span style=color:#f92672>.</span>imshow(subimages[i], cmap<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;gray&#34;</span>)
plt<span style=color:#f92672>.</span>show()
</code></pre></div><p>Output:</p>
<p><figure>
<a href=/img/in-post/data-mining/ch11/captcha_2.png>
<img src=/img/in-post/data-mining/ch11/captcha_2.png loading=lazy alt=captcha_2>
</a>
<figcaption>captcha_2</figcaption>
</figure></p>
<hr>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>random_state <span style=color:#f92672>=</span> check_random_state(<span style=color:#ae81ff>14</span>)
letters <span style=color:#f92672>=</span> list(<span style=color:#e6db74>&#34;ABCDEFGHIJKLMNOPQRSTUVWXYZ&#34;</span>)
<span style=color:#66d9ef>assert</span> len(letters) <span style=color:#f92672>==</span> <span style=color:#ae81ff>26</span>
shear_values <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>arange(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0.8</span>, <span style=color:#ae81ff>0.05</span>)
scale_values <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>arange(<span style=color:#ae81ff>0.9</span>, <span style=color:#ae81ff>1.1</span>, <span style=color:#ae81ff>0.1</span>)

<span style=color:#75715e># 随机生成一个字母的图片</span>
<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>generate_sample</span>(random_state<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>):
    random_state <span style=color:#f92672>=</span> check_random_state(random_state)
    letter <span style=color:#f92672>=</span> random_state<span style=color:#f92672>.</span>choice(letters)
    shear <span style=color:#f92672>=</span> random_state<span style=color:#f92672>.</span>choice(shear_values)
    scale <span style=color:#f92672>=</span> random_state<span style=color:#f92672>.</span>choice(scale_values)
    <span style=color:#66d9ef>return</span> (
        create_captcha(letter, shear<span style=color:#f92672>=</span>shear, size<span style=color:#f92672>=</span>(<span style=color:#ae81ff>30</span>, <span style=color:#ae81ff>30</span>), scale<span style=color:#f92672>=</span>scale),
        letters<span style=color:#f92672>.</span>index(letter),
    )

image, target <span style=color:#f92672>=</span> generate_sample(random_state)
plt<span style=color:#f92672>.</span>imshow(image, cmap<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Greys&#34;</span>)
print(<span style=color:#e6db74>&#34;The target for this image is: </span><span style=color:#e6db74>{0}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(letters[target]))
</code></pre></div><p>Output:</p>
<pre><code>The target for this image is: L
</code></pre>
<p><figure>
<a href=/img/in-post/data-mining/ch11/captcha_3.png>
<img src=/img/in-post/data-mining/ch11/captcha_3.png loading=lazy alt=captcha_3>
</a>
<figcaption>captcha_3</figcaption>
</figure></p>
<hr>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># 生成数据集</span>
dataset, targets <span style=color:#f92672>=</span> zip(<span style=color:#f92672>*</span>(generate_sample(random_state) <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>1000</span>)))
dataset <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array(
    [tf<span style=color:#f92672>.</span>resize(segment_image(sample)[<span style=color:#ae81ff>0</span>], (<span style=color:#ae81ff>20</span>, <span style=color:#ae81ff>20</span>)) <span style=color:#66d9ef>for</span> sample <span style=color:#f92672>in</span> dataset]
)
dataset <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array(dataset, dtype<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;float&#34;</span>)
targets <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array(targets)

onehot <span style=color:#f92672>=</span> OneHotEncoder()
y <span style=color:#f92672>=</span> onehot<span style=color:#f92672>.</span>fit_transform(targets<span style=color:#f92672>.</span>reshape(targets<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>], <span style=color:#ae81ff>1</span>))
y <span style=color:#f92672>=</span> y<span style=color:#f92672>.</span>todense()
X <span style=color:#f92672>=</span> dataset<span style=color:#f92672>.</span>reshape((dataset<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>], dataset<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>1</span>] <span style=color:#f92672>*</span> dataset<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>2</span>]))
X_train, X_test, y_train, y_test <span style=color:#f92672>=</span> train_test_split(X, y, train_size<span style=color:#f92672>=</span><span style=color:#ae81ff>0.9</span>)

hidden_layer <span style=color:#f92672>=</span> Dense(<span style=color:#ae81ff>100</span>, input_dim<span style=color:#f92672>=</span>X_train<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>1</span>])
output_layer <span style=color:#f92672>=</span> Dense(y_train<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>1</span>])

model <span style=color:#f92672>=</span> Sequential(layers<span style=color:#f92672>=</span>[hidden_layer, output_layer])
model<span style=color:#f92672>.</span>compile(loss<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;mean_squared_error&#34;</span>, optimizer<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;adam&#34;</span>, metrics<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;accuracy&#34;</span>])
model<span style=color:#f92672>.</span>fit(X_train, y_train, epochs<span style=color:#f92672>=</span><span style=color:#ae81ff>1000</span>, verbose<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
y_pred <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>predict(X_test)
print(f1_score(y_pred<span style=color:#f92672>=</span>y_pred<span style=color:#f92672>.</span>argmax(axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), y_true<span style=color:#f92672>=</span>y_test<span style=color:#f92672>.</span>argmax(axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), average<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;macro&#34;</span>))
print(classification_report(y_pred<span style=color:#f92672>=</span>y_pred<span style=color:#f92672>.</span>argmax(axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), y_true<span style=color:#f92672>=</span>y_test<span style=color:#f92672>.</span>argmax(axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)))
</code></pre></div><p>Output:</p>
<pre><code>1.0

              precision    recall  f1-score   support

           0       1.00      1.00      1.00         4
           1       1.00      1.00      1.00         4
           2       1.00      1.00      1.00         3
           3       1.00      1.00      1.00        10
           4       1.00      1.00      1.00         3
           5       1.00      1.00      1.00         3
           6       1.00      1.00      1.00         1
           7       1.00      1.00      1.00         3
           8       1.00      1.00      1.00         5
           9       1.00      1.00      1.00         3
          10       1.00      1.00      1.00         3
          11       1.00      1.00      1.00         6
          12       1.00      1.00      1.00         3
          13       1.00      1.00      1.00         5
          14       1.00      1.00      1.00         4
          15       1.00      1.00      1.00         6
          16       1.00      1.00      1.00         1
          17       1.00      1.00      1.00         3
          18       1.00      1.00      1.00         2
          19       1.00      1.00      1.00         3
          20       1.00      1.00      1.00         5
          21       1.00      1.00      1.00         7
          22       1.00      1.00      1.00         4
          23       1.00      1.00      1.00         2
          24       1.00      1.00      1.00         2
          25       1.00      1.00      1.00         5

    accuracy                           1.00       100
   macro avg       1.00      1.00      1.00       100
weighted avg       1.00      1.00      1.00       100
</code></pre>
<h3 id=使用-gpu-优化>使用 GPU 优化</h3>
<p>为了让我的 GPU 能跑程序，可费了我好大功夫，结果我这 960M 的 2G 内存还跑不了太大的程序/(ㄒ o ㄒ)/~~</p>
<p>第 101 次想念我的台式机，可恶的病毒</p>
<p>配置的过程跟 <a class=link href=https://tensorflow.google.cn/install/gpu target=_blank rel=noopener>TensorFlow</a> 官网给的方法没啥区别，在这就不多说了（官网给出的 NVIDIA 显卡驱动版本是 430，我这里是 440，CUDA 版本是 10.2，依然能运行程序，可能只需要 <code>development and runtime libraries</code> 正确安装就行？）</p>
<p>使用 tensorflow 在执行 <code>modle.compile()</code> 的时候需要较长的时间，运行时的速度还是很快的</p>
<p>初次接触神经网络，不了解的东西太多了，还是先多做几个训练再说吧。。</p>
<h3 id=应用-1>应用</h3>
<p>书上使用 CIFAR 图像数据集的代码太老了（原谅我太菜了解决不了依赖问题），因此我跟着 Tensorflow 官网的代码做完了这个实验</p>
<p>服装识别</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># -*- coding: utf-8 -*-</span>
<span style=color:#f92672>from</span> __future__ <span style=color:#f92672>import</span> absolute_import, division, print_function, unicode_literals

<span style=color:#f92672>import</span> tensorflow <span style=color:#66d9ef>as</span> tf
<span style=color:#f92672>from</span> tensorflow <span style=color:#f92672>import</span> keras
<span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
<span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt


<span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;__main__&#34;</span>:
    <span style=color:#75715e># --------加载、了解、预处理数据集--------</span>
    fashion_mnist <span style=color:#f92672>=</span> keras<span style=color:#f92672>.</span>datasets<span style=color:#f92672>.</span>fashion_mnist
    (train_images, train_labels), (test_images, test_labels) <span style=color:#f92672>=</span> fashion_mnist<span style=color:#f92672>.</span>load_data()
    class_names <span style=color:#f92672>=</span> [
        <span style=color:#e6db74>&#34;T-shirt/top&#34;</span>,
        <span style=color:#e6db74>&#34;Trouser&#34;</span>,
        <span style=color:#e6db74>&#34;Pullover&#34;</span>,
        <span style=color:#e6db74>&#34;Dress&#34;</span>,
        <span style=color:#e6db74>&#34;Coat&#34;</span>,
        <span style=color:#e6db74>&#34;Sandal&#34;</span>,
        <span style=color:#e6db74>&#34;Shirt&#34;</span>,
        <span style=color:#e6db74>&#34;Sneaker&#34;</span>,
        <span style=color:#e6db74>&#34;Bag&#34;</span>,
        <span style=color:#e6db74>&#34;Ankle boot&#34;</span>,
    ]
    <span style=color:#75715e># 查看数据集</span>
    print(
        train_images<span style=color:#f92672>.</span>shape,  <span style=color:#75715e># (60000，28，28)</span>
        len(train_labels),  <span style=color:#75715e># 60000</span>
        train_labels,  <span style=color:#75715e># [9 0 0 ... 3 0 5]</span>
        test_images<span style=color:#f92672>.</span>shape,  <span style=color:#75715e># (10000, 28, 28)</span>
        len(test_labels),  <span style=color:#75715e># 10000</span>
    )
</code></pre></div><p>Output:</p>
<pre><code>(60000, 28, 28) 60000 [9 0 0 ... 3 0 5] (10000, 28, 28) 10000
</code></pre>
<hr>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># 查看图像</span>
    plt<span style=color:#f92672>.</span>figure()
    plt<span style=color:#f92672>.</span>imshow(train_images[<span style=color:#ae81ff>0</span>])
    plt<span style=color:#f92672>.</span>colorbar()
    plt<span style=color:#f92672>.</span>grid(<span style=color:#66d9ef>False</span>)
    plt<span style=color:#f92672>.</span>show()
    <span style=color:#75715e># 预处理标准化</span>
    train_images <span style=color:#f92672>=</span> train_images <span style=color:#f92672>/</span> <span style=color:#ae81ff>255.0</span>
    test_images <span style=color:#f92672>=</span> test_images <span style=color:#f92672>/</span> <span style=color:#ae81ff>255.0</span>

    <span style=color:#75715e># 查看数据集</span>
    plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>10</span>))
    <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>25</span>):
        plt<span style=color:#f92672>.</span>subplot(<span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>5</span>, i <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>)
        plt<span style=color:#f92672>.</span>xticks([])
        plt<span style=color:#f92672>.</span>yticks([])
        plt<span style=color:#f92672>.</span>grid(<span style=color:#66d9ef>False</span>)
        plt<span style=color:#f92672>.</span>imshow(train_images[i], cmap<span style=color:#f92672>=</span>plt<span style=color:#f92672>.</span>cm<span style=color:#f92672>.</span>binary)
        plt<span style=color:#f92672>.</span>xlabel(class_names[train_labels[i]])
    plt<span style=color:#f92672>.</span>show()
</code></pre></div><p>Output:</p>
<hr>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># --------建立模型--------</span>
    <span style=color:#75715e># 建立神经网络所需要模型的各层</span>
    <span style=color:#75715e># tf.keras.layers.Flatten将图像的格式从二维数组(28 * 28)转换为一维数组(28 * 28 = 784)</span>
    <span style=color:#75715e># 可以将这个图层看作是图像中取消堆叠的像素行，并将它们排列起来</span>
    <span style=color:#75715e># 这个层没有参数需要学习; 它只是重新格式化数据。</span>
    <span style=color:#75715e>#</span>
    <span style=color:#75715e># 然后是两个稠密层（完全连接的层），中间一层有128个节点，</span>
    <span style=color:#75715e># 最后一层返回长度为10的对数数组。每个神经元包含一个得分，指示当前图像对这一类的评分</span>
    model <span style=color:#f92672>=</span> keras<span style=color:#f92672>.</span>Sequential(
        [
            keras<span style=color:#f92672>.</span>layers<span style=color:#f92672>.</span>Flatten(input_shape<span style=color:#f92672>=</span>(<span style=color:#ae81ff>28</span>, <span style=color:#ae81ff>28</span>)),
            keras<span style=color:#f92672>.</span>layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>128</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;relu&#34;</span>),
            keras<span style=color:#f92672>.</span>layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>10</span>),
        ]
    )
    <span style=color:#75715e># --------编译模型--------</span>
    <span style=color:#75715e># 损失函数：这可以衡量训练期间模型的准确程度，希望最小化这个函数，以便将模型“引导”到正确的方向</span>
    <span style=color:#75715e># 优化器：如何基于它看到的数据和它的损失函数更新模型</span>
    <span style=color:#75715e># 指标：用于检测训练和测试步骤。下面的例子使用精确度，即正确分类的图像的分数</span>
    model<span style=color:#f92672>.</span>compile(
        optimizer<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;adam&#34;</span>,
        loss<span style=color:#f92672>=</span>tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>losses<span style=color:#f92672>.</span>SparseCategoricalCrossentropy(from_logits<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>),
        metrics<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;accuracy&#34;</span>],
    )
    <span style=color:#75715e># --------训练模型--------</span>
    model<span style=color:#f92672>.</span>fit(train_images, train_labels, epochs<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>)
    <span style=color:#75715e># --------评估表现--------</span>
    test_loss, test_acc <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>evaluate(test_images, test_labels, verbose<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>)
    print(<span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>Test accuracy:&#34;</span>, test_acc)

    probability_model <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>Sequential([model, tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>layers<span style=color:#f92672>.</span>Softmax()])
    <span style=color:#75715e># prediction是由10个数字组成的数组。它们表示模型对图像对应于10种不同衣服各自的置信度</span>
    predictions <span style=color:#f92672>=</span> probability_model<span style=color:#f92672>.</span>predict(test_images)
    print(predictions[<span style=color:#ae81ff>0</span>])
</code></pre></div><p>Output:</p>
<pre><code>pciBusID: 0000:02:00.0 name: GeForce GTX 960M computeCapability: 5.0
coreClock: 1.176GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s
Epoch 1/10
1875/1875 [==============================] - 3s 2ms/step - loss: 0.4919 - accuracy: 0.8271
Epoch 2/10
1875/1875 [==============================] - 3s 1ms/step - loss: 0.3758 - accuracy: 0.8648
Epoch 3/10
1875/1875 [==============================] - 2s 1ms/step - loss: 0.3346 - accuracy: 0.8770
Epoch 4/10
1875/1875 [==============================] - 2s 1ms/step - loss: 0.3099 - accuracy: 0.8860
Epoch 5/10
1875/1875 [==============================] - 2s 1ms/step - loss: 0.2927 - accuracy: 0.8927
Epoch 6/10
1875/1875 [==============================] - 2s 1ms/step - loss: 0.2807 - accuracy: 0.8962
Epoch 7/10
1875/1875 [==============================] - 2s 1ms/step - loss: 0.2655 - accuracy: 0.9010
Epoch 8/10
1875/1875 [==============================] - 2s 1ms/step - loss: 0.2548 - accuracy: 0.9044
Epoch 9/10
1875/1875 [==============================] - 3s 1ms/step - loss: 0.2440 - accuracy: 0.9095
Epoch 10/10
1875/1875 [==============================] - 2s 1ms/step - loss: 0.2373 - accuracy: 0.9113
313/313 - 0s - loss: 0.3479 - accuracy: 0.8798

Test accuracy: 0.879800021648407

[1.3496768e-07 1.5826453e-10 1.7375668e-09 2.1999605e-10 5.5648923e-07
1.9829762e-03 1.9957926e-07 1.8424643e-04 9.3086570e-09 9.9783188e-01]
</code></pre>
<p>从输出可以看出 loss 函数正在逐渐减小，训练的准确率在不断的增加，这正是我们所要的</p>
<p>在训练集中的准确率为 91.1%， 而在测试集中只有 88%，这是出现了过拟合(overfitting)，关于过拟合的证明和避免过拟合的方法，等过几天单独写一个 post 学习一下</p>
<hr>
<p>定义两个函数用来绘图，更直观地看出预测结果</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># --------验证模型--------</span>
    <span style=color:#75715e># 制作图表来观察十个类别预测的完整集合</span>
    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>plot_image</span>(i, predictions_array, true_label, img):
        predictions_array, true_label, img <span style=color:#f92672>=</span> predictions_array, true_label[i], img[i]
        plt<span style=color:#f92672>.</span>grid(<span style=color:#66d9ef>False</span>)
        plt<span style=color:#f92672>.</span>xticks([])
        plt<span style=color:#f92672>.</span>yticks([])
        plt<span style=color:#f92672>.</span>imshow(img, cmap<span style=color:#f92672>=</span>plt<span style=color:#f92672>.</span>cm<span style=color:#f92672>.</span>binary)
        predicted_label <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>argmax(predictions_array)
        <span style=color:#66d9ef>if</span> predicted_label <span style=color:#f92672>==</span> true_label:
            color <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;blue&#34;</span>
        <span style=color:#66d9ef>else</span>:
            color <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;red&#34;</span>
        <span style=color:#75715e># 置信度百分比</span>
        plt<span style=color:#f92672>.</span>xlabel(
            <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{}</span><span style=color:#e6db74> </span><span style=color:#e6db74>{:2.0f}</span><span style=color:#e6db74>% (</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>)&#34;</span><span style=color:#f92672>.</span>format(
                class_names[predicted_label],
                <span style=color:#ae81ff>100</span> <span style=color:#f92672>*</span> np<span style=color:#f92672>.</span>max(predictions_array),
                class_names[true_label],
            ),
            color<span style=color:#f92672>=</span>color,
        )

    <span style=color:#75715e># 绘制置信度柱状图</span>
    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>plot_value_array</span>(i, predictions_array, true_label):
        predictions_array, true_label <span style=color:#f92672>=</span> predictions_array, true_label[i]
        plt<span style=color:#f92672>.</span>grid(<span style=color:#66d9ef>False</span>)
        plt<span style=color:#f92672>.</span>xticks(range(<span style=color:#ae81ff>10</span>))
        plt<span style=color:#f92672>.</span>yticks([])
        thisplot <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>bar(range(<span style=color:#ae81ff>10</span>), predictions_array, color<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;#777777&#34;</span>)
        plt<span style=color:#f92672>.</span>ylim([<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>])
        predicted_label <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>argmax(predictions_array)
        <span style=color:#75715e># 错误的预测标签为红色</span>
        thisplot[predicted_label]<span style=color:#f92672>.</span>set_color(<span style=color:#e6db74>&#34;red&#34;</span>)
        <span style=color:#75715e># 正确的标签为蓝色</span>
        thisplot[true_label]<span style=color:#f92672>.</span>set_color(<span style=color:#e6db74>&#34;blue&#34;</span>)

    i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
    plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>6</span>, <span style=color:#ae81ff>3</span>))
    plt<span style=color:#f92672>.</span>subplot(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>1</span>)
    plot_image(i, predictions[i], test_labels, test_images)
    plt<span style=color:#f92672>.</span>subplot(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>)
    plot_value_array(i, predictions[i], test_labels)
    plt<span style=color:#f92672>.</span>show()

    i <span style=color:#f92672>=</span> <span style=color:#ae81ff>12</span>
    plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>6</span>, <span style=color:#ae81ff>3</span>))
    plt<span style=color:#f92672>.</span>subplot(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>1</span>)
    plot_image(i, predictions[i], test_labels, test_images)
    plt<span style=color:#f92672>.</span>subplot(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>)
    plot_value_array(i, predictions[i], test_labels)
    plt<span style=color:#f92672>.</span>show()

    num_rows <span style=color:#f92672>=</span> <span style=color:#ae81ff>5</span>
    num_cols <span style=color:#f92672>=</span> <span style=color:#ae81ff>3</span>
    num_images <span style=color:#f92672>=</span> num_rows <span style=color:#f92672>*</span> num_cols
    plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>2</span> <span style=color:#f92672>*</span> num_cols, <span style=color:#ae81ff>2</span> <span style=color:#f92672>*</span> num_rows))
    <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(num_images):
        plt<span style=color:#f92672>.</span>subplot(num_rows, <span style=color:#ae81ff>2</span> <span style=color:#f92672>*</span> num_cols, <span style=color:#ae81ff>2</span> <span style=color:#f92672>*</span> i <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>)
        plot_image(i, predictions[i], test_labels, test_images)
        plt<span style=color:#f92672>.</span>subplot(num_rows, <span style=color:#ae81ff>2</span> <span style=color:#f92672>*</span> num_cols, <span style=color:#ae81ff>2</span> <span style=color:#f92672>*</span> i <span style=color:#f92672>+</span> <span style=color:#ae81ff>2</span>)
        plot_value_array(i, predictions[i], test_labels)
    plt<span style=color:#f92672>.</span>tight_layout()
    plt<span style=color:#f92672>.</span>show()
</code></pre></div><p>Output:</p>
<hr>
<p>示范如何使用模型来得到预测结果</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># --------使用模型--------</span>
    img <span style=color:#f92672>=</span> test_images[<span style=color:#ae81ff>1</span>]
    print(img<span style=color:#f92672>.</span>shape)
    <span style=color:#75715e># 转换成keras支持的格式</span>
    img <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>expand_dims(img, <span style=color:#ae81ff>0</span>)
    print(img<span style=color:#f92672>.</span>shape)
    <span style=color:#75715e># 为该图像预测</span>
    predictions_single <span style=color:#f92672>=</span> probability_model<span style=color:#f92672>.</span>predict(img)
    print(predictions_single)
    plot_value_array(<span style=color:#ae81ff>1</span>, predictions_single[<span style=color:#ae81ff>0</span>], test_labels)
    _ <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>xticks(range(<span style=color:#ae81ff>10</span>), class_names, rotation<span style=color:#f92672>=</span><span style=color:#ae81ff>45</span>)
    plt<span style=color:#f92672>.</span>show()
    <span style=color:#75715e># 返回预测的种类</span>
    print(<span style=color:#e6db74>&#34;result: &#34;</span>, np<span style=color:#f92672>.</span>argmax(predictions_single[<span style=color:#ae81ff>0</span>]))
</code></pre></div><p>Output:</p>
<pre><code>(28, 28)
(1, 28, 28)
[[3.3822223e-05 3.9569712e-13 9.9579656e-01 1.2699689e-10 3.9967773e-03
1.0960948e-12 1.7281482e-04 5.0896191e-17 7.9589724e-11 1.4832706e-12]]
result: 2

# 这张图片忘了保存了
</code></pre>
<hr>
<p>试着增加步数观察是否能得到更好的结果</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#75715e># 仅修改这一行代码，其它不变，重新运行</span>
    model<span style=color:#f92672>.</span>fit(train_images, train_labels, epochs<span style=color:#f92672>=</span><span style=color:#ae81ff>100</span>, verbose<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
</code></pre></div><p>Output:</p>
<pre><code>313/313 - 0s - loss: 0.8228 - accuracy: 0.8824
Test accuracy: 0.8823999762535095

[3.4202448e-25 0.0000000e+00 1.0021874e-24 0.0000000e+00 5.4433387e-31
1.8526166e-17 5.1352536e-34 4.5777732e-13 1.4344803e-28 1.0000000e+00]

(28, 28)
(1, 28, 28)
[[2.1121348e-16 0.0000000e+00 1.0000000e+00 1.0520916e-32 5.9910987e-09
1.4628578e-34 1.1571613e-14 0.0000000e+00 6.4996830e-38 0.0000000e+00]]
result: 2
</code></pre>
<p>在增加到 100 步后，最后一步的输出为</p>
<pre><code>Epoch 100/100
1875/1875 [==============================] - 3s 2ms/step - loss: 0.0570 - accuracy: 0.9790
</code></pre>
<p>在训练集上的精确度达到了 97.9%，而在测试集中也只达到了 88.2%，有微小的进步</p>
<p>这个实验条理清晰地展示了深度学习的基本步骤：</p>
<ul>
<li>加载、了解、预处理数据集</li>
<li>建立模型</li>
<li>建立模型</li>
<li>训练模型</li>
<li>评估表现</li>
<li>验证模型</li>
<li>使用模型做预测</li>
</ul>
<hr>
<p>这本书就快看完了，正愁不知道下本书看啥的我又发现了一个学习宝库<code>TensorFlow</code>。就决定是你了！</p>
<p>笔记本好难用，还是 pycharm 适合我。。。但还是得学用笔记本啊～～</p>
<h2 id=第十二章>第十二章</h2>
<p>本章主要介绍了 python 使用 MapReduce 来进行大数据处理</p>
<h3 id=mapreduce-例子>MapReduce 例子</h3>
<p>MapReduce 主要分为两步：映射（Map）和规约（Reduce）</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># -*- coding: utf-8 -*-</span>
<span style=color:#f92672>from</span> collections <span style=color:#f92672>import</span> defaultdict
<span style=color:#f92672>from</span> sklearn.datasets <span style=color:#f92672>import</span> fetch_20newsgroups

<span style=color:#f92672>from</span> joblib <span style=color:#f92672>import</span> Parallel, delayed

<span style=color:#f92672>import</span> timeit


<span style=color:#75715e># 计算documents中的单词出现词素</span>
<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>map_word_count</span>(document_id, document):
    counts <span style=color:#f92672>=</span> defaultdict(int)
    <span style=color:#66d9ef>for</span> word <span style=color:#f92672>in</span> document<span style=color:#f92672>.</span>split():
        counts[word] <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
    <span style=color:#66d9ef>for</span> word <span style=color:#f92672>in</span> counts:
        <span style=color:#66d9ef>yield</span> word, counts[word]


<span style=color:#75715e># 将map得到的结果，即每篇文章中单词出现的次数整合起来</span>
<span style=color:#75715e># 如文章1中单词&#34;apple&#34;出现了2次，文章2中单词&#34;apple&#34;出现了5次，则返回结果为[&#34;apple&#34;:[2,5],...]</span>
<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>shuffle_words</span>(results_generators):
    records <span style=color:#f92672>=</span> defaultdict(list)
    <span style=color:#75715e># 遍历每一篇文章</span>
    <span style=color:#66d9ef>for</span> results <span style=color:#f92672>in</span> results_generators:
        <span style=color:#75715e># 遍历每个单词</span>
        <span style=color:#66d9ef>for</span> word, count <span style=color:#f92672>in</span> results:
            records[word]<span style=color:#f92672>.</span>append(count)
    <span style=color:#75715e># 每次生成一个单词</span>
    <span style=color:#66d9ef>for</span> word <span style=color:#f92672>in</span> records:
        <span style=color:#66d9ef>yield</span> word, records[word]


<span style=color:#75715e># 将单词所对应的列表叠加起来得到单词出现次数</span>
<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>reduce_counts</span>(word, list_of_counts):
    <span style=color:#66d9ef>return</span> word, sum(list_of_counts)


<span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;__main__&#34;</span>:
    dataset <span style=color:#f92672>=</span> fetch_20newsgroups(subset<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;train&#34;</span>)
    documents <span style=color:#f92672>=</span> dataset<span style=color:#f92672>.</span>data
    start <span style=color:#f92672>=</span> timeit<span style=color:#f92672>.</span>default_timer()
    <span style=color:#75715e># 生成器，输出(单词，出现次数的键值对)</span>
    map_results <span style=color:#f92672>=</span> map(map_word_count, range(len(documents)), documents)
    shuffle_results <span style=color:#f92672>=</span> shuffle_words(map_results)
    reduce_results <span style=color:#f92672>=</span> [
        reduce_counts(word, list_of_counts) <span style=color:#66d9ef>for</span> word, list_of_counts <span style=color:#f92672>in</span> shuffle_results
    ]
    end <span style=color:#f92672>=</span> timeit<span style=color:#f92672>.</span>default_timer()
    print(reduce_results[:<span style=color:#ae81ff>5</span>])
    print(len(reduce_results))
    print(<span style=color:#e6db74>&#34;----------&#34;</span>, str(end <span style=color:#f92672>-</span> start))
</code></pre></div><p>Output:</p>
<pre><code>pydev debugger: process 7540 is connecting
[('From:', 11536), ('lerxst@wam.umd.edu', 2), (&quot;(where's&quot;, 3), ('my', 7679), ('thing)', 9)]
280308
---------- 4.087287616999674
</code></pre>
<hr>
<p>接下来导入 joblib 库，将 map 工作分配出去，使用 4 个进程进行计算</p>
<p>Input:</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>map_word_count</span>(document_id, document):
        counts <span style=color:#f92672>=</span> defaultdict(int)
        <span style=color:#66d9ef>for</span> word <span style=color:#f92672>in</span> document<span style=color:#f92672>.</span>split():
            counts[word] <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
        <span style=color:#66d9ef>return</span> list(counts<span style=color:#f92672>.</span>items())

    start <span style=color:#f92672>=</span> timeit<span style=color:#f92672>.</span>default_timer()

    map_results <span style=color:#f92672>=</span> Parallel(n_jobs<span style=color:#f92672>=</span><span style=color:#ae81ff>4</span>)(
        delayed(map_word_count)(i, document) <span style=color:#66d9ef>for</span> i, document <span style=color:#f92672>in</span> enumerate(documents)
    )

    shuffle_results <span style=color:#f92672>=</span> shuffle_words(map_results)
    reduce_results <span style=color:#f92672>=</span> [
        reduce_counts(word, list_of_counts) <span style=color:#66d9ef>for</span> word, list_of_counts <span style=color:#f92672>in</span> shuffle_results
    ]

    end <span style=color:#f92672>=</span> timeit<span style=color:#f92672>.</span>default_timer()

    print(reduce_results[:<span style=color:#ae81ff>5</span>])
    print(len(reduce_results))
    print(<span style=color:#e6db74>&#34;----------&#34;</span>, str(end <span style=color:#f92672>-</span> start))
</code></pre></div><p>Output:</p>
<pre><code>pydev debugger: process 7566 is connecting
pydev debugger: process 7556 is connecting
pydev debugger: process 7552 is connecting
pydev debugger: process 7561 is connecting
[('From:', 11536), ('lerxst@wam.umd.edu', 2), (&quot;(where's&quot;, 3), ('my', 7679), ('thing)', 9)]
280308
---------- 3.5958340090001
</code></pre>
<p>可以看到运行时间确实减少了（数据集太少了效果不怎么样）</p>
<h3 id=mapreduce-应用>MapReduce 应用</h3>
<p>书中使用 blogs 的数据集，有 19320 个人的 blog 信息</p>
<p>手头上的电脑配置有点不行了，跑的属实费劲，就放在这了（其实是迫不及待想去做做 tensorflow 的练习了嘿嘿）</p>
<h2 id=接下来的方向>接下来的方向</h2>
<p>书中根据每一章的内容，都有更进一步的实践，我会选几个单独做一下练习</p>
<p>Done</p>
<h2 id=参考链接>参考链接</h2>
<ol>
<li><a class=link href=https://docs.python.org/zh-cn/3.8/index.html target=_blank rel=noopener>python-3.8.2-doc</a></li>
<li><a class=link href=https://pandas.pydata.org/docs/user_guide/index.html target=_blank rel=noopener>pandas-doc</a></li>
<li><a class=link href=https://numpy.org/devdocs/ target=_blank rel=noopener>numpy-doc</a></li>
<li><a class=link href=https://scikit-learn.org/stable/index.html target=_blank rel=noopener>scikit-learn</a></li>
<li><a class=link href=https://tensorflow.google.cn/ target=_blank rel=noopener>tensorflow</a></li>
</ol>
</section>
<footer class=article-footer>
<section class=article-tags>
<a href=/tags/data-science/>data science</a>
</section>
<section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span>
</section>
<section class=article-lastmod><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>
Last updated on Mar 23, 2020 00:00 +0800
</span>
</section></footer>
</article>
<aside class=related-contents--wrapper>
<h2 class=section-title>Related contents</h2>
<div class=related-contents>
<div class="flex article-list--tile">
<article>
<a href=/p/pandas-%E5%85%A5%E9%97%A8/>
<div class=article-details>
<h2 class=article-title>Pandas 入门</h2>
</div>
</a>
</article>
<article>
<a href=/p/python-%E7%8E%AF%E5%A2%83%E7%AE%A1%E7%90%86/>
<div class=article-details>
<h2 class=article-title>Python 环境管理</h2>
</div>
</a>
</article>
<article>
<a href=/p/effective-python/>
<div class=article-details>
<h2 class=article-title>Effective Python</h2>
</div>
</a>
</article>
<article>
<a href=/p/python-encode/>
<div class=article-details>
<h2 class=article-title>Python Encode</h2>
</div>
</a>
</article>
</div>
</div>
</aside>
<div id=gitalk-container></div>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css>
<script src=https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/blueimp-md5@2.18.0/js/md5.min.js></script>
<script>const gitalk=new Gitalk({clientID:"60fcbf378ba98da93c38",clientSecret:"97006a937aa9fd569bd7f7c6f1dfa69e39c45a2a",repo:"saltfishpr.github.io",owner:"saltfishpr",admin:["saltfishpr"],distractionFreeMode:!1,id:md5(location.pathname)});(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("gitalk-container").innerHTML="Gitalk comments not available by default when the website is previewed locally.";return}gitalk.render("gitalk-container")})()</script>
<footer class=site-footer>
<section class=copyright>
&copy;
2020 -
2021 咸鱼硕的博客
</section>
<section class=powerby>
Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> <br>
Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.5.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a>
</section>
</footer>
<div class=pswp tabindex=-1 role=dialog aria-hidden=true>
<div class=pswp__bg></div>
<div class=pswp__scroll-wrap>
<div class=pswp__container>
<div class=pswp__item></div>
<div class=pswp__item></div>
<div class=pswp__item></div>
</div>
<div class="pswp__ui pswp__ui--hidden">
<div class=pswp__top-bar>
<div class=pswp__counter></div>
<button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
<div class=pswp__preloader>
<div class=pswp__preloader__icn>
<div class=pswp__preloader__cut>
<div class=pswp__preloader__donut></div>
</div>
</div>
</div>
</div>
<div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
<div class=pswp__share-tooltip></div>
</div>
<button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
</button>
<div class=pswp__caption>
<div class=pswp__caption__center></div>
</div>
</div>
</div>
</div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css integrity="sha256-c0uckgykQ9v5k+IqViZOZKc47Jn7KQil4/MP3ySA3F8=" crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.css integrity="sha256-SBLU4vv6CA6lHsZ1XyTdhyjJxCjPif/TRkjnsyGAGnE=" crossorigin=anonymous>
</main>
<aside class="sidebar right-sidebar sticky">
<section class="widget archives">
<div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg>
</div>
<h2 class="widget-title section-title">Table of contents</h2>
<div class=widget--toc>
<nav id=TableOfContents>
<ol>
<li><a href=#第一章>第一章</a>
<ol>
<li><a href=#亲和性分析>亲和性分析</a></li>
<li><a href=#one-rule-算法>One Rule 算法</a></li>
</ol>
</li>
<li><a href=#第二章>第二章</a>
<ol>
<li><a href=#scikit-learn-估计器>scikit-learn 估计器</a></li>
<li><a href=#流水线在预处理中的作用>流水线在预处理中的作用</a></li>
<li><a href=#流水线>流水线</a></li>
</ol>
</li>
<li><a href=#第三章>第三章</a>
<ol>
<li><a href=#加载数据集>加载数据集</a></li>
<li><a href=#决策树>决策树</a></li>
<li><a href=#随机森林>随机森林</a></li>
<li><a href=#课后练习>课后练习</a></li>
</ol>
</li>
<li><a href=#第四章>第四章</a>
<ol>
<li><a href=#亲和性分析-1>亲和性分析</a></li>
<li><a href=#电影推荐问题>电影推荐问题</a></li>
<li><a href=#apriori-算法的实现>Apriori 算法的实现</a></li>
<li><a href=#抽取关联规则>抽取关联规则</a></li>
<li><a href=#评估测试>评估测试</a></li>
</ol>
</li>
<li><a href=#第五章>第五章</a>
<ol>
<li><a href=#特征抽取>特征抽取</a></li>
<li><a href=#特征选择>特征选择</a></li>
<li><a href=#创建特征>创建特征</a></li>
<li><a href=#创建自己的转换器>创建自己的转换器</a></li>
</ol>
</li>
<li><a href=#第六章>第六章</a>
<ol>
<li><a href=#消歧>消歧</a></li>
<li><a href=#文本转换器>文本转换器</a></li>
<li><a href=#朴素贝叶斯>朴素贝叶斯</a></li>
<li><a href=#应用>应用</a></li>
</ol>
</li>
<li><a href=#第七章>第七章</a>
<ol>
<li><a href=#加载数据集-1>加载数据集</a></li>
<li><a href=#寻找子图>寻找子图</a></li>
</ol>
</li>
<li><a href=#第八章>第八章</a>
<ol>
<li><a href=#人工神经网络>人工神经网络</a></li>
<li><a href=#创建数据集>创建数据集</a></li>
<li><a href=#训练和分类>训练和分类</a></li>
<li><a href=#用词典提升准确率>用词典提升准确率</a></li>
</ol>
</li>
<li><a href=#第九章>第九章</a>
<ol>
<li><a href=#为作品找到作者>为作品找到作者</a></li>
<li><a href=#n-元语法>N 元语法</a></li>
<li><a href=#安然邮件数据集>安然邮件数据集</a></li>
</ol>
</li>
<li><a href=#第十章>第十章</a>
<ol>
<li><a href=#获取新闻文章>获取新闻文章</a></li>
<li><a href=#从网站抽取文本>从网站抽取文本</a></li>
<li><a href=#新闻语料聚类>新闻语料聚类</a></li>
<li><a href=#聚类融合>聚类融合</a></li>
<li><a href=#线上学习>线上学习</a></li>
</ol>
</li>
<li><a href=#第十一章>第十一章</a>
<ol>
<li><a href=#深度神经网络>深度神经网络</a></li>
<li><a href=#使用-gpu-优化>使用 GPU 优化</a></li>
<li><a href=#应用-1>应用</a></li>
</ol>
</li>
<li><a href=#第十二章>第十二章</a>
<ol>
<li><a href=#mapreduce-例子>MapReduce 例子</a></li>
<li><a href=#mapreduce-应用>MapReduce 应用</a></li>
</ol>
</li>
<li><a href=#接下来的方向>接下来的方向</a></li>
<li><a href=#参考链接>参考链接</a></li>
</ol>
</nav>
</div>
</section>
</aside>
</div>
<script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g=" crossorigin=anonymous defer></script><script type=text/javascript src=/ts/main.js defer></script>
<script>(function(){const a=document.createElement('link');a.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",a.type="text/css",a.rel="stylesheet",document.head.appendChild(a)})()</script>
</body>
</html>