<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><meta http-equiv=x-ua-compatible content="IE=edge, chrome=1"><title>数据挖掘入门与实践 - 咸鱼硕的博客</title><meta name=Description content="《Python 数据挖掘入门与实践》学习笔记"><meta property="og:title" content="数据挖掘入门与实践"><meta property="og:description" content="《Python 数据挖掘入门与实践》学习笔记"><meta property="og:type" content="article"><meta property="og:url" content="https://saltfishpr.github.io/posts/2020-03-09-data-mining/"><meta property="og:image" content="https://saltfishpr.github.io/posts/2020-03-09-data-mining/cover.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-03-09T00:00:00+08:00"><meta property="article:modified_time" content="2022-03-30T21:42:52+08:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://saltfishpr.github.io/posts/2020-03-09-data-mining/cover.png"><meta name=twitter:title content="数据挖掘入门与实践"><meta name=twitter:description content="《Python 数据挖掘入门与实践》学习笔记"><meta name=application-name content="咸鱼硕的博客"><meta name=apple-mobile-web-app-title content="咸鱼硕的博客"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel=icon href=go.svg><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://saltfishpr.github.io/posts/2020-03-09-data-mining/><link rel=prev href=https://saltfishpr.github.io/posts/2020-03-06-python-encode/><link rel=next href=https://saltfishpr.github.io/posts/2020-03-10-build-a-github-pages/><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/normalize.css@8.0.1/normalize.min.css><link rel=stylesheet href=/css/style.min.89b621a9bf174f6453c265bdcf5f2ffe8feb8bf3555ce4432c220058d367643a9e0aae3b0c211fc83b05a5bdc47d2ce47d74361d8a2becb6f76a7df35e3c3def.css integrity="sha512-ibYhqb8XT2RTwmW9z18v/o/ri/NVXORDLCIAWNNnZDqeCq47DCEfyDsFpb3EfSzkfXQ2HYor7Lb3an3zXjw97w=="><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/animate.css@3.7.2/animate.min.css><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"数据挖掘入门与实践","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/saltfishpr.github.io\/posts\/2020-03-09-data-mining\/"},"image":["https:\/\/saltfishpr.github.io\/images\/Apple-Devices-Preview.png"],"genre":"posts","keywords":"python, data science","wordcount":31471,"url":"https:\/\/saltfishpr.github.io\/posts\/2020-03-09-data-mining\/","datePublished":"2020-03-09T00:00:00+08:00","dateModified":"2022-03-30T21:42:52+08:00","license":"This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher":{"@type":"Organization","name":"xxxx","logo":"https:\/\/saltfishpr.github.io\/images\/avatar.png"},"author":{"@type":"Person","name":"Salt Fish"},"description":"《Python 数据挖掘入门与实践》学习笔记"}</script></head><body header-desktop=fixed header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem("theme")?localStorage.getItem("theme")==="dark":"auto"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"auto"==="dark")&&document.body.setAttribute("theme","dark")</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title=咸鱼硕的博客><span class=header-title-pre><i class="fas fa-code"></i></span>咸鱼硕的博客</a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>所有文章 </a><a class=menu-item href=/tags/>标签 </a><a class=menu-item href=/categories/>分类 </a><a class=menu-item href=/about/>关于 </a><span class="menu-item delimiter"></span><a href=javascript:void(0); class="menu-item language" title=选择语言>简体中文<i class="fas fa-chevron-right fa-fw"></i>
<select class=language-select id=language-select-desktop onchange="location=this.value"><option value=/posts/2020-03-09-data-mining/ selected>简体中文</option></select>
</a><span class="menu-item search" id=search-desktop><input type=text placeholder=搜索文章标题或内容... id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=搜索><i class="fas fa-search fa-fw"></i></a>
<a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=清空><i class="fas fa-times-circle fa-fw"></i></a>
<span class="search-button search-loading" id=search-loading-desktop><i class="fas fa-spinner fa-fw fa-spin"></i></span>
</span><a href=javascript:void(0); class="menu-item theme-switch" title=切换主题><i class="fas fa-adjust fa-fw"></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title=咸鱼硕的博客><span class=header-title-pre><i class="fas fa-code"></i></span>咸鱼硕的博客</a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=搜索文章标题或内容... id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=搜索><i class="fas fa-search fa-fw"></i></a>
<a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=清空><i class="fas fa-times-circle fa-fw"></i></a>
<span class="search-button search-loading" id=search-loading-mobile><i class="fas fa-spinner fa-fw fa-spin"></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>取消</a></div><a class=menu-item href=/posts/ title>所有文章</a><a class=menu-item href=/tags/ title>标签</a><a class=menu-item href=/categories/ title>分类</a><a class=menu-item href=/about/ title>关于</a><a href=javascript:void(0); class="menu-item theme-switch" title=切换主题>
<i class="fas fa-adjust fa-fw"></i>
</a><a href=javascript:void(0); class=menu-item title=选择语言>简体中文<i class="fas fa-chevron-right fa-fw"></i>
<select class=language-select onchange="location=this.value"><option value=/posts/2020-03-09-data-mining/ selected>简体中文</option></select></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>目录</h2><div class=toc-content id=toc-content-auto></div></div><article class="page single"><h1 class="single-title animated flipInX">数据挖掘入门与实践</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=https://github.com/SaltFishPr title=Author target=_blank rel="noopener noreffer author" class=author><i class="fas fa-user-circle fa-fw"></i>Salt Fish</a></span>&nbsp;<span class=post-category>收录于 <a href=/categories/coding/><i class="far fa-folder fa-fw"></i>coding</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime=2020-03-09>2020-03-09</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;约 31471 字&nbsp;
<i class="far fa-clock fa-fw"></i>&nbsp;预计阅读 63 分钟&nbsp;</div></div><div class="details toc" id=toc-static kept><div class="details-summary toc-title"><span>目录</span>
<span><i class="details-icon fas fa-angle-right"></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#第一章>第一章</a><ul><li><a href=#亲和性分析>亲和性分析</a></li><li><a href=#one-rule-算法>One Rule 算法</a></li></ul></li><li><a href=#第二章>第二章</a><ul><li><a href=#scikit-learn-估计器>scikit-learn 估计器</a></li><li><a href=#流水线在预处理中的作用>流水线在预处理中的作用</a></li><li><a href=#流水线>流水线</a></li></ul></li><li><a href=#第三章>第三章</a><ul><li><a href=#加载数据集>加载数据集</a></li><li><a href=#决策树>决策树</a></li><li><a href=#随机森林>随机森林</a></li><li><a href=#课后练习>课后练习</a></li></ul></li><li><a href=#第四章>第四章</a><ul><li><a href=#亲和性分析-1>亲和性分析</a></li><li><a href=#电影推荐问题>电影推荐问题</a></li><li><a href=#apriori-算法的实现>Apriori 算法的实现</a></li><li><a href=#抽取关联规则>抽取关联规则</a></li><li><a href=#评估测试>评估测试</a></li></ul></li><li><a href=#第五章>第五章</a><ul><li><a href=#特征抽取>特征抽取</a></li><li><a href=#特征选择>特征选择</a></li><li><a href=#创建特征>创建特征</a></li><li><a href=#创建自己的转换器>创建自己的转换器</a></li></ul></li><li><a href=#第六章>第六章</a><ul><li><a href=#消歧>消歧</a></li><li><a href=#文本转换器>文本转换器</a></li><li><a href=#朴素贝叶斯>朴素贝叶斯</a></li><li><a href=#应用>应用</a></li></ul></li><li><a href=#第七章>第七章</a><ul><li><a href=#加载数据集-1>加载数据集</a></li><li><a href=#寻找子图>寻找子图</a></li></ul></li><li><a href=#第八章>第八章</a><ul><li><a href=#人工神经网络>人工神经网络</a></li><li><a href=#创建数据集>创建数据集</a></li><li><a href=#训练和分类>训练和分类</a></li><li><a href=#用词典提升准确率>用词典提升准确率</a></li></ul></li><li><a href=#第九章>第九章</a><ul><li><a href=#为作品找到作者>为作品找到作者</a></li><li><a href=#n-元语法>N 元语法</a></li><li><a href=#安然邮件数据集>安然邮件数据集</a></li></ul></li><li><a href=#第十章>第十章</a><ul><li><a href=#获取新闻文章>获取新闻文章</a></li><li><a href=#从网站抽取文本>从网站抽取文本</a></li><li><a href=#新闻语料聚类>新闻语料聚类</a></li><li><a href=#聚类融合>聚类融合</a></li><li><a href=#线上学习>线上学习</a></li></ul></li><li><a href=#第十一章>第十一章</a><ul><li><a href=#深度神经网络>深度神经网络</a></li><li><a href=#使用-gpu-优化>使用 GPU 优化</a></li><li><a href=#应用-1>应用</a></li></ul></li><li><a href=#第十二章>第十二章</a><ul><li><a href=#mapreduce-例子>MapReduce 例子</a></li><li><a href=#mapreduce-应用>MapReduce 应用</a></li></ul></li><li><a href=#接下来的方向>接下来的方向</a></li><li><a href=#参考链接>参考链接</a></li></ul></nav></div></div><div class=content id=content><p>书上的源码在<a href=http://www.packtpub.com/support target=_blank rel="noopener noreffer">官网</a>上可以注册账号下载，这里只为记录自己的学习过程。</p><p>如果有侵权情况，请给我发邮件通知我删除 <a href=mailto:526191197@qq.com rel>526191197@qq.com</a></p><p>此笔记的代码均在 <code>pycharm - python3.8</code> 中运行通过</p><p>学习数据挖掘，让数据服务于人类</p><h2 id=第一章>第一章</h2><h3 id=亲和性分析>亲和性分析</h3><p>亲和性分析根据样本个体（物体）之间的相似度，确定他们的关系亲疏。应用场景有以下几个方面：</p><ul><li>向用户投放定向广告</li><li>为用户提供推荐（如歌曲推荐，电影推荐等）</li></ul><p>名词：</p><ul><li>规则：一条规则由前提条件和结论两部分组成</li><li>支持度：<u>数据集</u>中规则应验的次数</li><li>置信度：规则（结果）出现的次数 / 条件出现的次数（条件相同的规则数量），衡量规则的准确率</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># -*- coding: utf-8 -*-</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>collections</span> <span class=kn>import</span> <span class=n>defaultdict</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>operator</span> <span class=kn>import</span> <span class=n>itemgetter</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s1>&#39;__main__&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>dataset_filename</span> <span class=o>=</span> <span class=s2>&#34;affinity_dataset.txt&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>X</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>loadtxt</span><span class=p>(</span><span class=n>dataset_filename</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>n_samples</span><span class=p>,</span> <span class=n>n_features</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>shape</span>  <span class=c1># 样本数，特征数</span>
</span></span><span class=line><span class=cl>    <span class=n>features</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&#34;bread&#34;</span><span class=p>,</span> <span class=s2>&#34;milk&#34;</span><span class=p>,</span> <span class=s2>&#34;cheese&#34;</span><span class=p>,</span> <span class=s2>&#34;apples&#34;</span><span class=p>,</span> <span class=s2>&#34;bananas&#34;</span><span class=p>]</span>  <span class=c1># 商品名列表</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 如果xxx，那么xxx 就是一条规则。规则由前提条件和结论两部分组成</span>
</span></span><span class=line><span class=cl>    <span class=c1># 这里注意&#39;如果买A则他们会买B&#39;和&#39;如果买B则他们会买A&#39;不是一个规则，在下面的循环中体现出来</span>
</span></span><span class=line><span class=cl>    <span class=n>valid_rules</span> <span class=o>=</span> <span class=n>defaultdict</span><span class=p>(</span><span class=nb>int</span><span class=p>)</span>  <span class=c1># 规则应验</span>
</span></span><span class=line><span class=cl>    <span class=n>invalid_rules</span> <span class=o>=</span> <span class=n>defaultdict</span><span class=p>(</span><span class=nb>int</span><span class=p>)</span>  <span class=c1># 规则无效</span>
</span></span><span class=line><span class=cl>    <span class=n>num_occurences</span> <span class=o>=</span> <span class=n>defaultdict</span><span class=p>(</span><span class=nb>int</span><span class=p>)</span>  <span class=c1># 商品购买数量字典</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>sample</span> <span class=ow>in</span> <span class=n>X</span><span class=p>:</span>  <span class=c1># 对数据集里的每个消费者</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>premise</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_features</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>sample</span><span class=p>[</span><span class=n>premise</span><span class=p>]</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>  <span class=c1># 如果这个商品没有买，继续看下一个商品</span>
</span></span><span class=line><span class=cl>                <span class=k>continue</span>
</span></span><span class=line><span class=cl>            <span class=n>num_occurences</span><span class=p>[</span><span class=n>premise</span><span class=p>]</span> <span class=o>+=</span> <span class=mi>1</span>  <span class=c1># 记录这个商品购买数量</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>conclusion</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_features</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=n>premise</span> <span class=o>==</span> <span class=n>conclusion</span><span class=p>:</span>  <span class=c1># 跳过此商品</span>
</span></span><span class=line><span class=cl>                    <span class=k>continue</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=n>sample</span><span class=p>[</span><span class=n>conclusion</span><span class=p>]</span> <span class=o>==</span> <span class=mi>1</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=n>valid_rules</span><span class=p>[(</span><span class=n>premise</span><span class=p>,</span> <span class=n>conclusion</span><span class=p>)]</span> <span class=o>+=</span> <span class=mi>1</span>  <span class=c1># 规则应验</span>
</span></span><span class=line><span class=cl>                <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=n>invalid_rules</span><span class=p>[(</span><span class=n>premise</span><span class=p>,</span> <span class=n>conclusion</span><span class=p>)]</span> <span class=o>+=</span> <span class=mi>1</span>  <span class=c1># 规则无效</span>
</span></span><span class=line><span class=cl>    <span class=n>support</span> <span class=o>=</span> <span class=n>valid_rules</span>  <span class=c1># 支持度字典，即规则应验次数</span>
</span></span><span class=line><span class=cl>    <span class=n>confidence</span> <span class=o>=</span> <span class=n>defaultdict</span><span class=p>(</span><span class=nb>float</span><span class=p>)</span>  <span class=c1># 置信度字典</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>premise</span><span class=p>,</span> <span class=n>conclusion</span> <span class=ow>in</span> <span class=n>valid_rules</span><span class=o>.</span><span class=n>keys</span><span class=p>():</span>  <span class=c1># 条件/结论</span>
</span></span><span class=line><span class=cl>        <span class=n>rule</span> <span class=o>=</span> <span class=p>(</span><span class=n>premise</span><span class=p>,</span> <span class=n>conclusion</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># 置信度 = 规则发生的次数/条件发生的次数</span>
</span></span><span class=line><span class=cl>        <span class=n>confidence</span><span class=p>[</span><span class=n>rule</span><span class=p>]</span> <span class=o>=</span> <span class=n>valid_rules</span><span class=p>[</span><span class=n>rule</span><span class=p>]</span> <span class=o>/</span> <span class=n>num_occurences</span><span class=p>[</span><span class=n>premise</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>print_rule</span><span class=p>(</span><span class=n>premise</span><span class=p>,</span> <span class=n>conclusion</span><span class=p>,</span> <span class=n>support</span><span class=p>,</span> <span class=n>confidence</span><span class=p>,</span> <span class=n>features</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>premise_name</span> <span class=o>=</span> <span class=n>features</span><span class=p>[</span><span class=n>premise</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>conclusion_name</span> <span class=o>=</span> <span class=n>features</span><span class=p>[</span><span class=n>conclusion</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;Rule: If a person buys </span><span class=si>{0}</span><span class=s2> they will also buy </span><span class=si>{1}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>premise_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>conclusion_name</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34; - Confidence: </span><span class=si>{0:.3f}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>confidence</span><span class=p>[(</span><span class=n>premise</span><span class=p>,</span> <span class=n>conclusion</span><span class=p>)]))</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34; - Support: </span><span class=si>{0}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>support</span><span class=p>[(</span><span class=n>premise</span><span class=p>,</span> <span class=n>conclusion</span><span class=p>)]))</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 得到支持度最高的规则，items()返回字典所有元素的列表，itemgetter(1)表示用支持度的值作为键，进行降序排列</span>
</span></span><span class=line><span class=cl>    <span class=n>sorted_support</span> <span class=o>=</span> <span class=nb>sorted</span><span class=p>(</span><span class=n>support</span><span class=o>.</span><span class=n>items</span><span class=p>(),</span> <span class=n>key</span><span class=o>=</span><span class=n>itemgetter</span><span class=p>(</span><span class=mi>1</span><span class=p>),</span> <span class=n>reverse</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>5</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Rule #</span><span class=si>{0}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>premise</span><span class=p>,</span> <span class=n>conclusion</span> <span class=o>=</span> <span class=n>sorted_support</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>print_rule</span><span class=p>(</span><span class=n>premise</span><span class=p>,</span> <span class=n>conclusion</span><span class=p>,</span> <span class=n>support</span><span class=p>,</span> <span class=n>confidence</span><span class=p>,</span> <span class=n>features</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>sorted_confidence</span> <span class=o>=</span> <span class=nb>sorted</span><span class=p>(</span><span class=n>confidence</span><span class=o>.</span><span class=n>items</span><span class=p>(),</span> <span class=n>key</span><span class=o>=</span><span class=n>itemgetter</span><span class=p>(</span><span class=mi>1</span><span class=p>),</span> <span class=n>reverse</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>5</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Rule #</span><span class=si>{0}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>premise</span><span class=p>,</span> <span class=n>conclusion</span> <span class=o>=</span> <span class=n>sorted_confidence</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>print_rule</span><span class=p>(</span><span class=n>premise</span><span class=p>,</span> <span class=n>conclusion</span><span class=p>,</span> <span class=n>support</span><span class=p>,</span> <span class=n>confidence</span><span class=p>,</span> <span class=n>features</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Output：</p><pre><code>Rule #1
Rule: If a person buys cheese they will also buy bananas
- Confidence: 0.659
- Support: 27
Rule #2
Rule: If a person buys bananas they will also buy cheese
- Confidence: 0.458
- Support: 27
Rule #3
Rule: If a person buys cheese they will also buy apples
- Confidence: 0.610
- Support: 25

Rule #1
Rule: If a person buys apples they will also buy cheese
- Confidence: 0.694
- Support: 25
Rule #2
Rule: If a person buys cheese they will also buy bananas
- Confidence: 0.659
- Support: 27
Rule #3
Rule: If a person buys bread they will also buy bananas
- Confidence: 0.630
- Support: 17
</code></pre><h3 id=one-rule-算法>One Rule 算法</h3><p><code>OneR</code>(One Rule)算法根据已有的数据中，具有相同特征值的个体最可能属于哪个类别进行分类。One Rule 就是从四个特征中选择分类效果最好的哪个作为分类依据。</p><blockquote><p>假如数据集的某一个特征可以取 0 或 1 两个值。数据集共有三个类别。特征值为 0 的情况下，A 类有 20 个这样的个体，B 类有 60 个，C 类也有 20 个。那么特征值为 0 的个体最可能属于 B 类,当然还有 40 个个体确实是特征值为 0，但是它们不属于 B 类。将特征值为 0 的个体分到 B 类的错误率就是 40%，因为有 40 个这样的个体分别属于 A 类和 C 类。特征值为 1 时，计算方法类似，不再赘述；其他各特征值最可能属于的类别及错误率的计算方法也一样。</p></blockquote><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span><span class=lnt>107
</span><span class=lnt>108
</span><span class=lnt>109
</span><span class=lnt>110
</span><span class=lnt>111
</span><span class=lnt>112
</span><span class=lnt>113
</span><span class=lnt>114
</span><span class=lnt>115
</span><span class=lnt>116
</span><span class=lnt>117
</span><span class=lnt>118
</span><span class=lnt>119
</span><span class=lnt>120
</span><span class=lnt>121
</span><span class=lnt>122
</span><span class=lnt>123
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># -*- coding: utf-8 -*-</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.datasets</span> <span class=kn>import</span> <span class=n>load_iris</span>  <span class=c1># Iris植物分类数据集</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>collections</span> <span class=kn>import</span> <span class=n>defaultdict</span>  <span class=c1># 初始化数据字典</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>operator</span> <span class=kn>import</span> <span class=n>itemgetter</span>  <span class=c1># 得到一个列表的制定元素</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>train_test_split</span>  <span class=c1># 将一个数据集且分为训练集和测试集</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.metrics</span> <span class=kn>import</span> <span class=n>classification_report</span>  <span class=c1># 分析预测结果</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 这里保留函数的文档方便查阅</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>train</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y_true</span><span class=p>,</span> <span class=n>feature</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Computes the predictors and error for a given feature using the OneR algorithm
</span></span></span><span class=line><span class=cl><span class=s2>    Parameters
</span></span></span><span class=line><span class=cl><span class=s2>    ----------
</span></span></span><span class=line><span class=cl><span class=s2>    X: array [n_samples, n_features]
</span></span></span><span class=line><span class=cl><span class=s2>        The two dimensional array that holds the dataset. Each row is a sample, each column
</span></span></span><span class=line><span class=cl><span class=s2>        is a feature.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    y_true: array [n_samples,]
</span></span></span><span class=line><span class=cl><span class=s2>        The one dimensional array that holds the class values. Corresponds to X, such that
</span></span></span><span class=line><span class=cl><span class=s2>        y_true[i] is the class value for sample X[i].
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    feature: int
</span></span></span><span class=line><span class=cl><span class=s2>        An integer corresponding to the index of the variable we wish to test.
</span></span></span><span class=line><span class=cl><span class=s2>        0 &lt;= variable &lt; n_features
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns
</span></span></span><span class=line><span class=cl><span class=s2>    -------
</span></span></span><span class=line><span class=cl><span class=s2>    predictors: dictionary of tuples: (value, prediction)
</span></span></span><span class=line><span class=cl><span class=s2>        For each item in the array, if the variable has a given value, make the given prediction.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    error: float
</span></span></span><span class=line><span class=cl><span class=s2>        The ratio of training data that this rule incorrectly predicts.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># 检查是否为有效数字</span>
</span></span><span class=line><span class=cl>    <span class=n>n_samples</span><span class=p>,</span> <span class=n>n_features</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=mi>0</span> <span class=o>&lt;=</span> <span class=n>feature</span> <span class=o>&lt;</span> <span class=n>n_features</span>
</span></span><span class=line><span class=cl>    <span class=c1># X[:, feature]为numpy矩阵的索引用法，第一维：所有数组，第二维：feature，set去重得到value有几个取值</span>
</span></span><span class=line><span class=cl>    <span class=c1># 这个feature特征值在每个数据中有多少个取值</span>
</span></span><span class=line><span class=cl>    <span class=n>values</span> <span class=o>=</span> <span class=nb>set</span><span class=p>(</span><span class=n>X</span><span class=p>[:,</span> <span class=n>feature</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=c1># Stores the predictors array that is returned</span>
</span></span><span class=line><span class=cl>    <span class=n>predictors</span> <span class=o>=</span> <span class=nb>dict</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>errors</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=c1># 对每个特征值的每个取值调用train_feature_value函数获得该取值出现最多的类和错误率</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>current_value</span> <span class=ow>in</span> <span class=n>values</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>most_frequent_class</span><span class=p>,</span> <span class=n>error</span> <span class=o>=</span> <span class=n>train_feature_value</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>X</span><span class=p>,</span> <span class=n>y_true</span><span class=p>,</span> <span class=n>feature</span><span class=p>,</span> <span class=n>current_value</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>predictors</span><span class=p>[</span><span class=n>current_value</span><span class=p>]</span> <span class=o>=</span> <span class=n>most_frequent_class</span>  <span class=c1># 该取值出现最多的类</span>
</span></span><span class=line><span class=cl>        <span class=n>errors</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>error</span><span class=p>)</span>  <span class=c1># 存储错误率</span>
</span></span><span class=line><span class=cl>    <span class=n>total_error</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=n>errors</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 返回预测方案（即feature的取值分别对应哪个类别）和总错误率</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>predictors</span><span class=p>,</span> <span class=n>total_error</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>train_feature_value</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y_true</span><span class=p>,</span> <span class=n>feature</span><span class=p>,</span> <span class=n>value</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>class_counts</span> <span class=o>=</span> <span class=n>defaultdict</span><span class=p>(</span><span class=nb>int</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># Iterate through each sample and count the frequency of each class/value pair</span>
</span></span><span class=line><span class=cl>    <span class=c1># 第feature个特征的值为value的时候，在每个种类中出现的次数，这里的植物有三个种类</span>
</span></span><span class=line><span class=cl>    <span class=c1># 因此最终class_counts有三个键值对</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>sample</span><span class=p>,</span> <span class=n>y</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y_true</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>sample</span><span class=p>[</span><span class=n>feature</span><span class=p>]</span> <span class=o>==</span> <span class=n>value</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>class_counts</span><span class=p>[</span><span class=n>y</span><span class=p>]</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>    <span class=c1># 对class_count以value由大到小排列</span>
</span></span><span class=line><span class=cl>    <span class=n>sorted_class_counts</span> <span class=o>=</span> <span class=nb>sorted</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>class_counts</span><span class=o>.</span><span class=n>items</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>        <span class=n>key</span><span class=o>=</span><span class=n>itemgetter</span><span class=p>(</span><span class=mi>1</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>reverse</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>most_frequent_class</span> <span class=o>=</span> <span class=n>sorted_class_counts</span><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=mi>0</span><span class=p>]</span>  <span class=c1># 出现最多次的类</span>
</span></span><span class=line><span class=cl>    <span class=n>n_samples</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>error</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>([</span><span class=n>class_count</span> <span class=k>for</span> <span class=n>class_value</span><span class=p>,</span> <span class=n>class_count</span> <span class=ow>in</span> <span class=n>class_counts</span><span class=o>.</span><span class=n>items</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span> <span class=k>if</span> <span class=n>class_value</span> <span class=o>!=</span> <span class=n>most_frequent_class</span><span class=p>])</span>  <span class=c1># error就是除去上面那个类的其它value的和</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>most_frequent_class</span><span class=p>,</span> <span class=n>error</span>  <span class=c1># 返回出现次数最多的类和错误率</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>predict</span><span class=p>(</span><span class=n>X_test</span><span class=p>,</span> <span class=n>model</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>variable</span> <span class=o>=</span> <span class=n>model</span><span class=p>[</span><span class=s1>&#39;variable&#39;</span><span class=p>]</span>  <span class=c1># 使用哪个feature作为OneRule进行预测</span>
</span></span><span class=line><span class=cl>    <span class=n>predictor</span> <span class=o>=</span> <span class=n>model</span><span class=p>[</span><span class=s1>&#39;predictor&#39;</span><span class=p>]</span>  <span class=c1># 一个字典，保存着feature取值对应哪一类</span>
</span></span><span class=line><span class=cl>    <span class=n>y_predicted</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=n>predictor</span><span class=p>[</span><span class=nb>int</span><span class=p>(</span><span class=n>sample</span><span class=p>[</span><span class=n>variable</span><span class=p>])]</span>
</span></span><span class=line><span class=cl>                            <span class=k>for</span> <span class=n>sample</span> <span class=ow>in</span> <span class=n>X_test</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>y_predicted</span>  <span class=c1># 返回预测结果</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s1>&#39;__main__&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>dataset</span> <span class=o>=</span> <span class=n>load_iris</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>X</span> <span class=o>=</span> <span class=n>dataset</span><span class=o>.</span><span class=n>data</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>dataset</span><span class=o>.</span><span class=n>target</span>
</span></span><span class=line><span class=cl>    <span class=n>n_samples</span><span class=p>,</span> <span class=n>n_features</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 计算每个属性的均值</span>
</span></span><span class=line><span class=cl>    <span class=n>attribute_means</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=n>attribute_means</span><span class=o>.</span><span class=n>shape</span> <span class=o>==</span> <span class=p>(</span><span class=n>n_features</span><span class=p>,)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 对数据集离散化</span>
</span></span><span class=line><span class=cl>    <span class=n>X_d</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>X</span> <span class=o>&gt;=</span> <span class=n>attribute_means</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=s1>&#39;int&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>random_state</span> <span class=o>=</span> <span class=mi>14</span>
</span></span><span class=line><span class=cl>    <span class=n>X_train</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>X_d</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=n>random_state</span><span class=p>)</span>  <span class=c1># 分割训练集和测试集</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;There are </span><span class=si>{}</span><span class=s2> training samples&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>y_train</span><span class=o>.</span><span class=n>shape</span><span class=p>))</span>  <span class=c1># 训练集数量</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;There are </span><span class=si>{}</span><span class=s2> testing samples&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>y_test</span><span class=o>.</span><span class=n>shape</span><span class=p>))</span>  <span class=c1># 测试集数量</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 对每个特征返回预测器和错误率[0：{0: x, 1: x}, sum_error， ...]</span>
</span></span><span class=line><span class=cl>    <span class=n>all_predictors</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>variable</span><span class=p>:</span> <span class=n>train</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>X_train</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>y_train</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>variable</span><span class=p>)</span> <span class=k>for</span> <span class=n>variable</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>X_train</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>])}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>errors</span> <span class=o>=</span> <span class=p>{</span><span class=n>variable</span><span class=p>:</span> <span class=n>error</span> <span class=k>for</span> <span class=n>variable</span><span class=p>,</span>
</span></span><span class=line><span class=cl>              <span class=p>(</span><span class=n>mapping</span><span class=p>,</span> <span class=n>error</span><span class=p>)</span> <span class=ow>in</span> <span class=n>all_predictors</span><span class=o>.</span><span class=n>items</span><span class=p>()}</span>  <span class=c1># 把每个预测器的值提取出来</span>
</span></span><span class=line><span class=cl>    <span class=c1># 找出最好（错误最少）的那个feature构成的预测器</span>
</span></span><span class=line><span class=cl>    <span class=n>best_variable</span><span class=p>,</span> <span class=n>best_error</span> <span class=o>=</span> <span class=nb>sorted</span><span class=p>(</span><span class=n>errors</span><span class=o>.</span><span class=n>items</span><span class=p>(),</span> <span class=n>key</span><span class=o>=</span><span class=n>itemgetter</span><span class=p>(</span><span class=mi>1</span><span class=p>))[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;The best model is based on variable </span><span class=si>{0}</span><span class=s2> and has error </span><span class=si>{1:.2f}</span><span class=s2>%&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>best_variable</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>best_error</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Choose the bset model</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;variable&#39;</span><span class=p>:</span> <span class=n>best_variable</span><span class=p>,</span>
</span></span><span class=line><span class=cl>             <span class=s1>&#39;predictor&#39;</span><span class=p>:</span> <span class=n>all_predictors</span><span class=p>[</span><span class=n>best_variable</span><span class=p>][</span><span class=mi>0</span><span class=p>]}</span>
</span></span><span class=line><span class=cl>    <span class=n>y_predicted</span> <span class=o>=</span> <span class=n>predict</span><span class=p>(</span><span class=n>X_test</span><span class=p>,</span> <span class=n>model</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>classification_report</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_predicted</span><span class=p>))</span>  <span class=c1># 生成测试结果</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>y_predicted</span> <span class=o>==</span> <span class=n>y_test</span><span class=p>)</span> <span class=o>*</span> <span class=mi>100</span><span class=p>)</span>  <span class=c1># 预测正确率</span>
</span></span></code></pre></td></tr></table></div></div><p>Output：</p><pre><code>|              | precision | recall | f1-score | support |
|      0       |   0.94    |  1.00  |   0.97   |   17    |
|      1       |   0.00    |  0.00  |   0.00   |   13    |
|      2       |   0.40    |  1.00  |   0.57   |    8    |
|              |           |        |          |         |
|   accuracy   |           |        |   0.66   |   38    |
|  macro avg   |   0.45    |  0.67  |   0.51   |   38    |
| weighted avg |   0.51    |  0.66  |   0.55   |   38    |

正确率： 65.78947368421053%
</code></pre><h2 id=第二章>第二章</h2><p>主要学习数据挖掘通用框架的搭建方法</p><ul><li>估计器(Estimator)：用于分类、聚类和回归分析</li><li>转换器(Transformer)：用于数据预处理和数据转换</li><li>流水线(Pipline)：组合数据挖掘流程，便于再次使用</li></ul><h3 id=scikit-learn-估计器>scikit-learn 估计器</h3><p>估计器用于分类，主要包含下面两个函数：</p><ul><li><code>fit()</code>: 训练算法，设置内部参数。该函数接受训练集和类别两个参数</li><li><code>predict()</code>: 参数为测试集。预测测试集类别，返回一个包含测试集各条数据类别的数组</li></ul><p><strong>近邻算法</strong></p><ul><li>用途广泛</li><li>计算量很大</li></ul><p><strong>距离度量</strong></p><ul><li>欧氏距离：即真实距离</li><li>曼哈顿距离：两个特征在标准坐标系中绝对轴距之和(x1,y1),(x2,y2)即 abs(x1-x2)+abs(y1-y2)</li><li>余弦距离：指的是特征向量夹角的余弦值，更适合解决异常值和数据稀疏问题。</li></ul><p>电离层(Ionosphere)数据集分析</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># -*- coding: utf-8 -*-</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>csv</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>matplotlib</span> <span class=kn>import</span> <span class=n>pyplot</span> <span class=k>as</span> <span class=n>plt</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.neighbors</span> <span class=kn>import</span> <span class=n>KNeighborsClassifier</span>  <span class=c1># 导入K近邻分类器</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>train_test_split</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>cross_val_score</span>  <span class=c1># 导入交叉检验的</span>
</span></span><span class=line><span class=cl><span class=c1># 把每个特征值的值域规范化到0，1之间，最小值用0代替，最大值用1代替</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.preprocessing</span> <span class=kn>import</span> <span class=n>MinMaxScaler</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.pipeline</span> <span class=kn>import</span> <span class=n>Pipeline</span>  <span class=c1># 流水线</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s1>&#39;__main__&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># 数据集大小已知有351行，每行35个值前34个为天线采集的数据，最后一个 g/b 表示数据的好坏</span>
</span></span><span class=line><span class=cl>    <span class=n>X</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=mi>351</span><span class=p>,</span> <span class=mi>34</span><span class=p>),</span> <span class=n>dtype</span><span class=o>=</span><span class=s1>&#39;float&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=mi>351</span><span class=p>,),</span> <span class=n>dtype</span><span class=o>=</span><span class=s1>&#39;bool&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 打开根目录的数据集文件</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=s2>&#34;ionosphere.data&#34;</span><span class=p>,</span> <span class=s1>&#39;r&#39;</span><span class=p>,</span> <span class=n>encoding</span><span class=o>=</span><span class=s1>&#39;utf-8&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>input_file</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># 创建csv阅读器对象</span>
</span></span><span class=line><span class=cl>        <span class=n>reader</span> <span class=o>=</span> <span class=n>csv</span><span class=o>.</span><span class=n>reader</span><span class=p>(</span><span class=n>input_file</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># 使用枚举函数为每行数据创建索引</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>row</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>reader</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=c1># 获取行数据的前34个值，并将其转化为浮点型，保存在X中</span>
</span></span><span class=line><span class=cl>            <span class=n>data</span> <span class=o>=</span> <span class=p>[</span><span class=nb>float</span><span class=p>(</span><span class=n>datum</span><span class=p>)</span> <span class=k>for</span> <span class=n>datum</span> <span class=ow>in</span> <span class=n>row</span><span class=p>[:</span><span class=o>-</span><span class=mi>1</span><span class=p>]]</span>
</span></span><span class=line><span class=cl>            <span class=c1># Set the appropriate row in our dataset</span>
</span></span><span class=line><span class=cl>            <span class=n>X</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>data</span>  <span class=c1># 数据集</span>
</span></span><span class=line><span class=cl>            <span class=c1># 1 if the class is &#39;g&#39;, 0 otherwise</span>
</span></span><span class=line><span class=cl>            <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>row</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=o>==</span> <span class=s1>&#39;g&#39;</span>  <span class=c1># 类别</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 创建训练集和测试集</span>
</span></span><span class=line><span class=cl>    <span class=n>X_train</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>14</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;There are </span><span class=si>{}</span><span class=s2> samples in the training dataset&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>X_train</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;There are </span><span class=si>{}</span><span class=s2> samples in the testing dataset&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>X_test</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Each sample has </span><span class=si>{}</span><span class=s2> features&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>X_train</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]))</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>There are 263 samples in the training dataset
There are 88 samples in the testing dataset
Each sample has 34 features
</code></pre><hr><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># 初始化一个K近邻分类器实例，该算法默认选择5个近邻作为分类依据</span>
</span></span><span class=line><span class=cl>    <span class=n>estimator</span> <span class=o>=</span> <span class=n>KNeighborsClassifier</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=c1># 用训练数据进行训练</span>
</span></span><span class=line><span class=cl>    <span class=n>estimator</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 使用测试集测试算法，评价其表现</span>
</span></span><span class=line><span class=cl>    <span class=n>y_predicted</span> <span class=o>=</span> <span class=n>estimator</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 准确性</span>
</span></span><span class=line><span class=cl>    <span class=n>accuracy</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>y_test</span> <span class=o>==</span> <span class=n>y_predicted</span><span class=p>)</span> <span class=o>*</span> <span class=mi>100</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;The accuracy is </span><span class=si>{0:.1f}</span><span class=s2>%&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>accuracy</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 使用交叉检验的方式获得平均准确性</span>
</span></span><span class=line><span class=cl>    <span class=n>scores</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>estimator</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>average_accuracy</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>)</span> <span class=o>*</span> <span class=mi>100</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;The average accuracy is </span><span class=si>{0:.1f}</span><span class=s2>%&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>average_accuracy</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>The accuracy is 86.4%
The average accuracy is 82.6%
</code></pre><hr><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># 设置参数</span>
</span></span><span class=line><span class=cl>    <span class=c1># 参数的选取跟数据集的特征息息相关</span>
</span></span><span class=line><span class=cl>    <span class=n>avg_scores</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>all_scores</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>parameter_values</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>21</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>n_neighbors</span> <span class=ow>in</span> <span class=n>parameter_values</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>estimator</span> <span class=o>=</span> <span class=n>KNeighborsClassifier</span><span class=p>(</span><span class=n>n_neighbors</span><span class=o>=</span><span class=n>n_neighbors</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>scores</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>estimator</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>avg_scores</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>all_scores</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>scores</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 作出n_neighbors不同取值和分类正确率之间的关系的折线图</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>32</span><span class=p>,</span> <span class=mi>20</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>parameter_values</span><span class=p>,</span> <span class=n>avg_scores</span><span class=p>,</span> <span class=s1>&#39;-o&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>markersize</span><span class=o>=</span><span class=mi>24</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/img/in-post/data-mining/ch2/result2.1.png data-srcset="/img/in-post/data-mining/ch2/result2.1.png, /img/in-post/data-mining/ch2/result2.1.png 1.5x, /img/in-post/data-mining/ch2/result2.1.png 2x" data-sizes=auto alt=/img/in-post/data-mining/ch2/result2.1.png title=result2.1></p><p>经过上面的例子，可以总结数据挖掘最简单基本的流程如下：</p><ul><li>载入数据集，数据分类提取到内存中</li><li>创建训练集和测试集</li><li>选择合适的算法进行训练</li><li>使用测试集测试算法，评估其表现</li></ul><p>为了保证算法的准确性，可以将大数据集分为几个部分，通过交叉检验的方法测试算法。使用 cross_val_score 函数是一个不错的选择。</p><p>在参数的设置上，可以针对不同的参数进行交叉测试，使用图表直观地表示出参数的影响。</p><h3 id=流水线在预处理中的作用>流水线在预处理中的作用</h3><p>sckit-learn 的预处理工具叫做转换器<code>Transformer</code></p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># 模拟脏数据</span>
</span></span><span class=line><span class=cl>    <span class=n>X_broken</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>X_broken</span><span class=p>[:,</span> <span class=p>::</span><span class=mi>2</span><span class=p>]</span> <span class=o>/=</span> <span class=mi>10</span>
</span></span><span class=line><span class=cl>    <span class=c1># 对比两种情况下预测准确率</span>
</span></span><span class=line><span class=cl>    <span class=n>estimator</span> <span class=o>=</span> <span class=n>KNeighborsClassifier</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>original_scores</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>estimator</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;The original average accuracy for is </span><span class=si>{0:.1f}</span><span class=s2>%&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>original_scores</span><span class=p>)</span> <span class=o>*</span> <span class=mi>100</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>broken_scores</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>estimator</span><span class=p>,</span> <span class=n>X_broken</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;The broken average accuracy for is </span><span class=si>{0:.1f}</span><span class=s2>%&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>broken_scores</span><span class=p>)</span> <span class=o>*</span> <span class=mi>100</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>The original average accuracy for is 82.6%
The broken average accuracy for is 73.8%
</code></pre><hr><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># 组合成为一个工作流</span>
</span></span><span class=line><span class=cl>    <span class=n>X_transformed</span> <span class=o>=</span> <span class=n>MinMaxScaler</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X_broken</span><span class=p>)</span>    <span class=c1># 完成训练和转换</span>
</span></span><span class=line><span class=cl>    <span class=n>estimator</span> <span class=o>=</span> <span class=n>KNeighborsClassifier</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>transformed_scores</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>estimator</span><span class=p>,</span> <span class=n>X_transformed</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;The average accuracy for is </span><span class=si>{0:.1f}</span><span class=s2>%&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>transformed_scores</span><span class=p>)</span> <span class=o>*</span> <span class=mi>100</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>The average accuracy for is 82.9%
</code></pre><p>将数据经过规范化后，正确率再次提高</p><p>其它的规范化函数举例：</p><ul><li>为使每条数据各特征值的和为 1：<code>sklearn.preprocessing.Normalizer</code></li><li>为使各特征值的均值为 0，方差为 1：<code>sklearn.preprocessing.StandardScaler</code></li><li>为将数值型特征二值化：<code>sklearn.preprocessing.Binarizer</code></li></ul><h3 id=流水线>流水线</h3><p><code>sklearn.pipeline.Pipeline</code>用于创建流水线。流水线的输入为一连串的数据挖掘步骤，最后一步必须是估计器，前几步是转换器。</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># 创建流水线</span>
</span></span><span class=line><span class=cl>    <span class=c1># 流水线的每一步都用(&#39;名称&#39;,步骤)的元组表示</span>
</span></span><span class=line><span class=cl>    <span class=n>scaling_pipeline</span> <span class=o>=</span> <span class=n>Pipeline</span><span class=p>([(</span><span class=s1>&#39;scale&#39;</span><span class=p>,</span> <span class=n>MinMaxScaler</span><span class=p>()),</span>  <span class=c1># 规范特征取值</span>
</span></span><span class=line><span class=cl>                                 <span class=p>(</span><span class=s1>&#39;predict&#39;</span><span class=p>,</span> <span class=n>KNeighborsClassifier</span><span class=p>())])</span>  <span class=c1># 预测</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 调用流水线</span>
</span></span><span class=line><span class=cl>    <span class=n>scores</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>scaling_pipeline</span><span class=p>,</span> <span class=n>X_broken</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;The pipelin scored an average accuracy for is </span><span class=si>{0:.1f}</span><span class=s2>%&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>)</span> <span class=o>*</span> <span class=mi>100</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>The pipelin scored an average accuracy for is 82.9%
</code></pre><h2 id=第三章>第三章</h2><p>决策树也是一种分类算法，它的优点如下：</p><ul><li>机器和人都能看懂</li><li>能够处理多种不同的特征</li></ul><h3 id=加载数据集>加载数据集</h3><p>pandas(Python Data Analysis 的简写)</p><p>逗号分隔值（Comma-Separated Values，CSV，有时也称为字符分隔值，因为分隔字符也可以不是逗号），其文件以纯文本形式存储表格数据（数字和文本），来源<a href="https://baike.baidu.com/item/CSV/10739?fr=aladdin" target=_blank rel="noopener noreffer">百度百科</a>。</p><p>这里使用 <code>pandas</code> 导入.csv 文件，生成一个 <code>dataframe</code> （数据框）的类。导入使用 <code>read_csv()</code> 函数，常用参数如下：</p><ul><li><code>sep=','</code> 以,为数据分隔符</li><li><code>parse_dates='col_name'</code> 将某个特征值读取为日期格式</li><li><code>error_bad_lines=False</code> 当某行数据有问题时，跳过而不报错</li><li><code>skiprows=[&lt;param>]</code> 跳过列表中所包括的行，参数可以是 0,1,&mldr;的数字序列，也可以用切片表达式<code>[0:]</code></li><li><code>usecols=[&lt;param>]</code> 选择使用哪几个特征值，参数同上</li></ul><p>在使用 <code>dataframe.ix[]</code>获取 <code>dataframe</code> 中的某几行数据时，提示错误信息，原因是 <code>pandas</code> 在 0.20.0 版本后就废弃掉了这个函数。在这里我改为使用 <code>iloc</code> 函数。</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># -*- coding: utf-8 -*-</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>collections</span> <span class=kn>import</span> <span class=n>defaultdict</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.tree</span> <span class=kn>import</span> <span class=n>DecisionTreeClassifier</span>  <span class=c1># 创建决策树的类</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>cross_val_score</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.preprocessing</span> <span class=kn>import</span> <span class=n>LabelEncoder</span>  <span class=c1># 能将字符串类型的特征转化成整型</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.preprocessing</span> <span class=kn>import</span> <span class=n>OneHotEncoder</span>  <span class=c1># 将特征转化为二进制数字</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.ensemble</span> <span class=kn>import</span> <span class=n>RandomForestClassifier</span>  <span class=c1># 随机森林</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>GridSearchCV</span>  <span class=c1># 网格搜索，找到最佳参数</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s1>&#39;__main__&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># 清洗数据集</span>
</span></span><span class=line><span class=cl>    <span class=n>results</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;NBA_data.csv&#34;</span><span class=p>,</span> <span class=n>parse_dates</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;Date&#34;</span><span class=p>],</span> <span class=n>skiprows</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=mi>0</span><span class=p>,</span> <span class=p>],</span> <span class=n>usecols</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>9</span><span class=p>])</span>  <span class=c1># 加载数据集</span>
</span></span><span class=line><span class=cl>    <span class=c1># 修复数据特征名</span>
</span></span><span class=line><span class=cl>    <span class=n>results</span><span class=o>.</span><span class=n>columns</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Date&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Visitor Team&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;VisitorPts&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Home Team&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;HomePts&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Score Type&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;OT?&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Notes&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=c1># results.ix[]已被弃用</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>results</span><span class=o>.</span><span class=n>loc</span><span class=p>[:</span><span class=mi>5</span><span class=p>])</span>  <span class=c1># 查看数据集前五行</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>        Date          Visitor Team  VisitorPts  ... Score Type  OT? Notes
0 2013-10-29         Orlando Magic          87  ...  Box Score  NaN   NaN
1 2013-10-29         Chicago Bulls          95  ...  Box Score  NaN   NaN
2 2013-10-29  Los Angeles Clippers         103  ...  Box Score  NaN   NaN
3 2013-10-30         Brooklyn Nets          94  ...  Box Score  NaN   NaN
4 2013-10-30        Boston Celtics          87  ...  Box Score  NaN   NaN
5 2013-10-30            Miami Heat         110  ...  Box Score  NaN   NaN
[6 rows x 8 columns]
</code></pre><h3 id=决策树>决策树</h3><p>创建新的特征列，可以从数据集中导入：</p><p><code>dataset["New Feature"] = feature_creator()</code></p><p>也可以一开始为新特征值设置默认的值：</p><p><code>dataset["My New Feature"] = 0</code></p><p>这里的 <code>X_previouswins = results[["HomeLastWin", "VisitorLastWin"]].values</code> 生成一个数据集，这个数据集有两个特征</p><p><code>DecisionTreeClassifier()</code> 用来创建决策树，常用参数如下：</p><ul><li><code>min_samples_split</code>: 指定了创建一个新节点至少需要多少个个体</li><li><code>min_samples_leaf</code>: 指定为了保留节点，每个节点至少应该包含的个体数量</li><li>创建决策的标准: 基尼不纯度/信息增益</li></ul><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># 提取新特征，值为这场中主场队伍是否胜利</span>
</span></span><span class=line><span class=cl>    <span class=n>results</span><span class=p>[</span><span class=s2>&#34;HomeWin&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>results</span><span class=p>[</span><span class=s2>&#34;VisitorPts&#34;</span><span class=p>]</span> <span class=o>&lt;</span> <span class=n>results</span><span class=p>[</span><span class=s2>&#34;HomePts&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>y_true</span> <span class=o>=</span> <span class=n>results</span><span class=p>[</span><span class=s2>&#34;HomeWin&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>values</span>  <span class=c1># 胜负情况</span>
</span></span><span class=line><span class=cl>    <span class=c1># 创建两个新feature，初始值都设为0，保存这场比赛的两个队伍上场比赛的情况</span>
</span></span><span class=line><span class=cl>    <span class=n>results</span><span class=p>[</span><span class=s2>&#34;HomeLastWin&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=kc>False</span>
</span></span><span class=line><span class=cl>    <span class=n>results</span><span class=p>[</span><span class=s2>&#34;VisitorLastWin&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=kc>False</span>
</span></span><span class=line><span class=cl>    <span class=n>won_last</span> <span class=o>=</span> <span class=n>defaultdict</span><span class=p>(</span><span class=nb>int</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>index</span><span class=p>,</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>results</span><span class=o>.</span><span class=n>iterrows</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>home_team</span> <span class=o>=</span> <span class=n>row</span><span class=p>[</span><span class=s2>&#34;Home Team&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>visitor_team</span> <span class=o>=</span> <span class=n>row</span><span class=p>[</span><span class=s2>&#34;Visitor Team&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=c1># 这场比赛之前两个球队上次是否获胜保存在result中</span>
</span></span><span class=line><span class=cl>        <span class=n>row</span><span class=p>[</span><span class=s2>&#34;HomeLastWin&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>won_last</span><span class=p>[</span><span class=n>home_team</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>row</span><span class=p>[</span><span class=s2>&#34;VisitorLastWin&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>won_last</span><span class=p>[</span><span class=n>visitor_team</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>results</span><span class=o>.</span><span class=n>iloc</span><span class=p>[</span><span class=n>index</span><span class=p>]</span> <span class=o>=</span> <span class=n>row</span>
</span></span><span class=line><span class=cl>        <span class=c1># 这场比赛的结果更新won_last中的情况</span>
</span></span><span class=line><span class=cl>        <span class=n>won_last</span><span class=p>[</span><span class=n>home_team</span><span class=p>]</span> <span class=o>=</span> <span class=n>row</span><span class=p>[</span><span class=s2>&#34;HomeWin&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>won_last</span><span class=p>[</span><span class=n>visitor_team</span><span class=p>]</span> <span class=o>=</span> <span class=ow>not</span> <span class=n>row</span><span class=p>[</span><span class=s2>&#34;HomeWin&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>X_previouswins</span> <span class=o>=</span> <span class=n>results</span><span class=p>[[</span><span class=s2>&#34;HomeLastWin&#34;</span><span class=p>,</span> <span class=s2>&#34;VisitorLastWin&#34;</span><span class=p>]]</span><span class=o>.</span><span class=n>values</span>
</span></span><span class=line><span class=cl>    <span class=c1># 创建决策树生成器实例</span>
</span></span><span class=line><span class=cl>    <span class=n>clf</span> <span class=o>=</span> <span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>14</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 交叉训练</span>
</span></span><span class=line><span class=cl>    <span class=n>scores</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>clf</span><span class=p>,</span> <span class=n>X_previouswins</span><span class=p>,</span> <span class=n>y_true</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Using just the last result from the home and visitor teams&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Accuracy: </span><span class=si>{0:.1f}</span><span class=s2>%&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>)</span> <span class=o>*</span> <span class=mi>100</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>Using just the last result from the home and visitor teams
Accuracy: 56.4%
</code></pre><hr><p>这里为了创建一个新的特征导入了上一年的 NBA 排名。</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=n>ladder</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s2>&#34;NBA_standings.csv&#34;</span><span class=p>,</span> <span class=n>skiprows</span><span class=o>=</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=c1># 创建一个新特征，两个队伍在上个赛季的排名哪个比较高</span>
</span></span><span class=line><span class=cl>    <span class=n>results</span><span class=p>[</span><span class=s2>&#34;HomeTeamRanksHigher&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>index</span><span class=p>,</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>results</span><span class=o>.</span><span class=n>iterrows</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>home_team</span> <span class=o>=</span> <span class=n>row</span><span class=p>[</span><span class=s2>&#34;Home Team&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>visitor_team</span> <span class=o>=</span> <span class=n>row</span><span class=p>[</span><span class=s2>&#34;Visitor Team&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=c1># 这个球队改名了</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>home_team</span> <span class=o>==</span> <span class=s2>&#34;New Orleans Pelicans&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>home_team</span> <span class=o>=</span> <span class=s2>&#34;New Orleans Hornets&#34;</span>
</span></span><span class=line><span class=cl>        <span class=k>elif</span> <span class=n>visitor_team</span> <span class=o>==</span> <span class=s2>&#34;New Orleans Pelicans&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>visitor_team</span> <span class=o>=</span> <span class=s2>&#34;New Orleans Hornets&#34;</span>
</span></span><span class=line><span class=cl>        <span class=c1># 这里源代码无法运行，少加了一个括号 ladder[(ladder[&#34;Team&#34;] == home_team)] 表示根据条件获取这一行的数据</span>
</span></span><span class=line><span class=cl>        <span class=n>home_row</span> <span class=o>=</span> <span class=n>ladder</span><span class=p>[(</span><span class=n>ladder</span><span class=p>[</span><span class=s2>&#34;Team&#34;</span><span class=p>]</span> <span class=o>==</span> <span class=n>home_team</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>        <span class=n>visitor_row</span> <span class=o>=</span> <span class=n>ladder</span><span class=p>[(</span><span class=n>ladder</span><span class=p>[</span><span class=s2>&#34;Team&#34;</span><span class=p>]</span> <span class=o>==</span> <span class=n>visitor_team</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>        <span class=n>home_rank</span> <span class=o>=</span> <span class=n>home_row</span><span class=p>[</span><span class=s2>&#34;Rk&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>values</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>visitor_rank</span> <span class=o>=</span> <span class=n>visitor_row</span><span class=p>[</span><span class=s2>&#34;Rk&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>values</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>row</span><span class=p>[</span><span class=s2>&#34;HomeTeamRanksHigher&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>home_rank</span> <span class=o>&gt;</span> <span class=n>visitor_rank</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>results</span><span class=o>.</span><span class=n>iloc</span><span class=p>[</span><span class=n>index</span><span class=p>]</span> <span class=o>=</span> <span class=n>row</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>X_homehigher</span> <span class=o>=</span> <span class=n>results</span><span class=p>[[</span><span class=s2>&#34;HomeLastWin&#34;</span><span class=p>,</span> <span class=s2>&#34;VisitorLastWin&#34;</span><span class=p>,</span> <span class=s2>&#34;HomeTeamRanksHigher&#34;</span><span class=p>]]</span><span class=o>.</span><span class=n>values</span>
</span></span><span class=line><span class=cl>    <span class=n>clf</span> <span class=o>=</span> <span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>14</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>scores</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>clf</span><span class=p>,</span> <span class=n>X_homehigher</span><span class=p>,</span> <span class=n>y_true</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Using whether the home team is ranked higher&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Accuracy: </span><span class=si>{0:.1f}</span><span class=s2>%&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>)</span> <span class=o>*</span> <span class=mi>100</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>Using whether the home team is ranked higher
Accuracy: 60.0%
</code></pre><hr><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># 创建新特征，两个队伍上一次进行比赛时的获胜者</span>
</span></span><span class=line><span class=cl>    <span class=n>last_match_winner</span> <span class=o>=</span> <span class=n>defaultdict</span><span class=p>(</span><span class=nb>int</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>results</span><span class=p>[</span><span class=s2>&#34;HomeTeamWonLast&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>index</span><span class=p>,</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>results</span><span class=o>.</span><span class=n>iterrows</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>home_team</span> <span class=o>=</span> <span class=n>row</span><span class=p>[</span><span class=s2>&#34;Home Team&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>visitor_team</span> <span class=o>=</span> <span class=n>row</span><span class=p>[</span><span class=s2>&#34;Visitor Team&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=c1># 按照英文字母表排序，不去考虑哪个是主场球队</span>
</span></span><span class=line><span class=cl>        <span class=n>teams</span> <span class=o>=</span> <span class=nb>tuple</span><span class=p>(</span><span class=nb>sorted</span><span class=p>([</span><span class=n>home_team</span><span class=p>,</span> <span class=n>visitor_team</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>        <span class=c1># 找到两支球队上次比赛的赢家，更新框中的数据，初始为0</span>
</span></span><span class=line><span class=cl>        <span class=c1># 这里的HomeTeamWonLast跟主场客场没有什么关系，也可以叫WhichTeamWonLast，这里为了和源码尽量保持一致使用了源码</span>
</span></span><span class=line><span class=cl>        <span class=n>row</span><span class=p>[</span><span class=s2>&#34;HomeTeamWonLast&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=mi>1</span> <span class=k>if</span> <span class=n>last_match_winner</span><span class=p>[</span><span class=n>teams</span><span class=p>]</span> <span class=o>==</span> <span class=n>row</span><span class=p>[</span><span class=s2>&#34;Home Team&#34;</span><span class=p>]</span> <span class=k>else</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>results</span><span class=o>.</span><span class=n>iloc</span><span class=p>[</span><span class=n>index</span><span class=p>]</span> <span class=o>=</span> <span class=n>row</span>
</span></span><span class=line><span class=cl>        <span class=n>winner</span> <span class=o>=</span> <span class=n>row</span><span class=p>[</span><span class=s2>&#34;Home Team&#34;</span><span class=p>]</span> <span class=k>if</span> <span class=n>row</span><span class=p>[</span><span class=s2>&#34;HomeWin&#34;</span><span class=p>]</span> <span class=k>else</span> <span class=n>row</span><span class=p>[</span><span class=s2>&#34;Visitor Team&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=c1># 将两个球队上次遇见比赛的情况存到字典中去</span>
</span></span><span class=line><span class=cl>        <span class=n>last_match_winner</span><span class=p>[</span><span class=n>teams</span><span class=p>]</span> <span class=o>=</span> <span class=n>winner</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>X_home_higher</span> <span class=o>=</span> <span class=n>results</span><span class=p>[[</span><span class=s2>&#34;HomeTeamRanksHigher&#34;</span><span class=p>,</span> <span class=s2>&#34;HomeTeamWonLast&#34;</span><span class=p>]]</span><span class=o>.</span><span class=n>values</span>
</span></span><span class=line><span class=cl>    <span class=n>clf</span> <span class=o>=</span> <span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>14</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>scores</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>clf</span><span class=p>,</span> <span class=n>X_home_higher</span><span class=p>,</span> <span class=n>y_true</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Using whether the home team is ranked higher&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Accuracy: </span><span class=si>{0:.1f}</span><span class=s2>%&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>)</span> <span class=o>*</span> <span class=mi>100</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>Using whether the home team is ranked higher
Accuracy: 59.9%
</code></pre><h3 id=随机森林>随机森林</h3><p><code>LabelEncoder()</code> 用来将一个字符串型的特征转化为整型</p><p><code>OneHotEncoder()</code> 将整数转化成消除差异的二进制数字，即将 1,2,3 转换成 001,010,100</p><p>stacking （向量组合），这里 <code>np.vstack()</code> 将两个队伍名向量纵向组合成一个矩阵<code>.T</code>表示将矩阵转置</p><p>决策树存在的问题：</p><ol><li>创建的多颗决策树在很大程度上是相同的，训练集相同，则生成的决策树也相同。一个解决办法是<em>装袋</em>(bagging)</li><li>用于前几个决策节点的特征非常突出，即使采用不同的训练集，创建的决策树相似性依旧很大。解决办法是随机选取部分特征作为决策数据</li></ol><p><code>RandomForestClassifier()</code> 用来调用随机森林算法，因为它调用了 DecisionTreeClassifier 的大量实例，所以他们的参数有很多是一致的。其引入的一部分新参数如下：</p><ul><li><code>n_estimators</code> 用来指定创建决策树的数量，值越高，耗时越长，准确率(可能)越高</li><li><code>oob_score</code> 如果设置为真，测试时将不适用训练模型时用过的数据</li><li><code>n_jobs</code> 采用并行算法训练时所用到的内核数量，设置为 -1 则启用全部内核</li></ul><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># 创建一个转化器实例</span>
</span></span><span class=line><span class=cl>    <span class=n>encoding</span> <span class=o>=</span> <span class=n>LabelEncoder</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=c1># 将球队名转化为整型</span>
</span></span><span class=line><span class=cl>    <span class=n>encoding</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>results</span><span class=p>[</span><span class=s2>&#34;Home Team&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>values</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 抽取所有比赛中主客场球队的球队名，组合起来形成一个矩阵</span>
</span></span><span class=line><span class=cl>    <span class=n>home_teams</span> <span class=o>=</span> <span class=n>encoding</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>results</span><span class=p>[</span><span class=s2>&#34;Home Team&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>values</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>visitor_teams</span> <span class=o>=</span> <span class=n>encoding</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>results</span><span class=p>[</span><span class=s2>&#34;Visitor Team&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>values</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 建立训练集，[[&#34;Home Team Feature&#34;，&#34;Visitor Team Feature&#34;],[&#34;Home Team Feature&#34;，&#34;Visitor Team Feature&#34;]...]</span>
</span></span><span class=line><span class=cl>    <span class=n>X_teams</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>vstack</span><span class=p>([</span><span class=n>home_teams</span><span class=p>,</span> <span class=n>visitor_teams</span><span class=p>])</span><span class=o>.</span><span class=n>T</span>
</span></span><span class=line><span class=cl>    <span class=c1># 创建转化器实例</span>
</span></span><span class=line><span class=cl>    <span class=n>onehot</span> <span class=o>=</span> <span class=n>OneHotEncoder</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=c1># 生成转化后的特征</span>
</span></span><span class=line><span class=cl>    <span class=n>X_teams</span> <span class=o>=</span> <span class=n>onehot</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X_teams</span><span class=p>)</span><span class=o>.</span><span class=n>todense</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>clf</span> <span class=o>=</span> <span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>14</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>scores</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>clf</span><span class=p>,</span> <span class=n>X_teams</span><span class=p>,</span> <span class=n>y_true</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Accuracy: </span><span class=si>{0:.1f}</span><span class=s2>%&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>)</span> <span class=o>*</span> <span class=mi>100</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>clf</span> <span class=o>=</span> <span class=n>RandomForestClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>14</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>scores</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>clf</span><span class=p>,</span> <span class=n>X_teams</span><span class=p>,</span> <span class=n>y_true</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Using full team labels is ranked higher&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Accuracy: </span><span class=si>{0:.1f}</span><span class=s2>%&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>)</span> <span class=o>*</span> <span class=mi>100</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>Accuracy: 60.5%
Using full team labels is ranked higher
Accuracy: 61.4%
</code></pre><hr><p>将上面生成的特征整合起来，创建新的决策方案</p><p>这里使用 <code>np.hstack()</code>横向拼接两个决策方案矩阵</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=n>X_all</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>hstack</span><span class=p>([</span><span class=n>X_home_higher</span><span class=p>,</span> <span class=n>X_teams</span><span class=p>])</span>  <span class=c1># 将上面计算的特征进行组合</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>X_all</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>scores</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>clf</span><span class=p>,</span> <span class=n>X_all</span><span class=p>,</span> <span class=n>y_true</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Using whether the home team is ranked higher&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Accuracy: </span><span class=si>{0:.1f}</span><span class=s2>%&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>)</span> <span class=o>*</span> <span class=mi>100</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>(1319, 62)
Using whether the home team is ranked higher
Accuracy: 61.6%
</code></pre><hr><p>使用 <code>GridSearchCV</code> （网格搜索）搜索最佳参数</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># 设置参数搜索范围</span>
</span></span><span class=line><span class=cl>    <span class=n>parameter_space</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;max_features&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=s1>&#39;auto&#39;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;n_estimators&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mi>100</span><span class=p>,</span> <span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;criterion&#34;</span><span class=p>:</span> <span class=p>[</span><span class=s2>&#34;gini&#34;</span><span class=p>,</span> <span class=s2>&#34;entropy&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;min_samples_leaf&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=n>grid</span> <span class=o>=</span> <span class=n>GridSearchCV</span><span class=p>(</span><span class=n>clf</span><span class=p>,</span> <span class=n>parameter_space</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>grid</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_all</span><span class=p>,</span> <span class=n>y_true</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Accuracy: </span><span class=si>{0:.1f}</span><span class=s2>%&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>grid</span><span class=o>.</span><span class=n>best_score_</span> <span class=o>*</span> <span class=mi>100</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=c1># 输出最佳方案</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>grid</span><span class=o>.</span><span class=n>best_estimator_</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>Accuracy: 65.6%
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                    criterion='gini', max_depth=None, max_features='auto',
                    max_leaf_nodes=None, max_samples=None,
                    min_impurity_decrease=0.0, min_impurity_split=None,
                    min_samples_leaf=2, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, n_estimators=100,
                    n_jobs=-1, oob_score=False, random_state=14, verbose=0,
                    warm_start=False)
</code></pre><h3 id=课后练习>课后练习</h3><p>拿到了数据，如何创建新的特征，如何在数据中发现其关键点，如何找出数据内部的联系，也是一个需要斟酌的方面</p><p>创建下述特征并看一下效果:</p><ul><li>球队上次打比赛距今有多长时间？</li><li>两支球队过去五场比赛结果如何？</li><li>球队是不是跟某支特定球队打比赛时发挥更好？</li></ul><p>在这里使用了上面书中的方法，完成了前两个点，第三个点实现起来有点麻烦，现在只有一个思路：建立一个字典，数据形式为 (两支球队建立一个元组:(前一个队伍获胜的次数，后一个队伍获胜的次数))</p><p>在处理 dataset 中的数据项时，对于 <code>pandas</code> 中的 <code>Timestamp</code> 类型没有了解，耗费了太长时间，查阅文档后发现可以用 <code>date()</code> 将其转化为 <code>datetime.date</code> 日期。</p><p>使用前两个特征作为决策标准时，效果还算可以，加上书上的所有特征后，准确率反而较上面的结果降低了。（不知道为什么）</p><p>这个“课后练习”使我对于标准库了解匮乏的短板显现出来，要抽出时间学习一下 <code>python</code>, <code>numpy</code> 和 <code>pandas</code> 标准库中常用函数及其参数。</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=ch>#!/usr/bin/env python3</span>
</span></span><span class=line><span class=cl><span class=c1># -*- coding: utf-8 -*-</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>datetime</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>collections</span> <span class=kn>import</span> <span class=n>defaultdict</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>cross_val_score</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.tree</span> <span class=kn>import</span> <span class=n>DecisionTreeClassifier</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.ensemble</span> <span class=kn>import</span> <span class=n>RandomForestClassifier</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>ch3.nba_test</span> <span class=kn>import</span> <span class=n>X_all</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>GridSearchCV</span>  <span class=c1># 网格搜索，找到最佳参数</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s1>&#39;__main__&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    - 球队上次打比赛距今有多长时间？
</span></span></span><span class=line><span class=cl><span class=s2>    - 两支球队过去五场比赛结果如何？
</span></span></span><span class=line><span class=cl><span class=s2>    - 球队是不是跟某支特定球队打比赛时发挥更好？
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>dataset</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;NBA_data.csv&#34;</span><span class=p>,</span> <span class=n>parse_dates</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;Date&#34;</span><span class=p>],</span> <span class=n>skiprows</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=mi>0</span><span class=p>,</span> <span class=p>],</span> <span class=n>usecols</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>9</span><span class=p>])</span>  <span class=c1># 加载数据集</span>
</span></span><span class=line><span class=cl>    <span class=n>dataset</span><span class=o>.</span><span class=n>columns</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Date&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Visitor Team&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;VisitorPts&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Home Team&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;HomePts&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Score Type&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;OT?&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Notes&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>dataset</span><span class=p>[</span><span class=s2>&#34;HomeWin&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>dataset</span><span class=p>[</span><span class=s2>&#34;VisitorPts&#34;</span><span class=p>]</span> <span class=o>&lt;</span> <span class=n>dataset</span><span class=p>[</span><span class=s2>&#34;HomePts&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>y_true</span> <span class=o>=</span> <span class=n>dataset</span><span class=p>[</span><span class=s2>&#34;HomeWin&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>values</span>  <span class=c1># 胜负情况</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 保存上次打比赛的时间</span>
</span></span><span class=line><span class=cl>    <span class=n>last_played_date</span> <span class=o>=</span> <span class=n>defaultdict</span><span class=p>(</span><span class=n>datetime</span><span class=o>.</span><span class=n>date</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 手动为每个球队初始化</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>team</span> <span class=ow>in</span> <span class=nb>set</span><span class=p>(</span><span class=n>dataset</span><span class=p>[</span><span class=s2>&#34;Home Team&#34;</span><span class=p>]):</span>
</span></span><span class=line><span class=cl>        <span class=n>last_played_date</span><span class=p>[</span><span class=n>team</span><span class=p>]</span> <span class=o>=</span> <span class=n>datetime</span><span class=o>.</span><span class=n>date</span><span class=p>(</span><span class=n>year</span><span class=o>=</span><span class=mi>2013</span><span class=p>,</span> <span class=n>month</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>day</span><span class=o>=</span><span class=mi>25</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 两支球队过去的比赛结果，每个球队的数据是[True,False,,,]的序列</span>
</span></span><span class=line><span class=cl>    <span class=n>last_five_games</span> <span class=o>=</span> <span class=n>defaultdict</span><span class=p>(</span><span class=nb>list</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 存放Home和Visitor前五次比赛的获胜次数</span>
</span></span><span class=line><span class=cl>    <span class=n>dataset</span><span class=p>[</span><span class=s2>&#34;HWinTimes&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=n>dataset</span><span class=p>[</span><span class=s2>&#34;VWinTimes&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=c1># 存放距离上次比赛的时间间隔，用天计数</span>
</span></span><span class=line><span class=cl>    <span class=n>dataset</span><span class=p>[</span><span class=s2>&#34;HLastPlayedSpan&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=n>dataset</span><span class=p>[</span><span class=s2>&#34;VLastPlayedSpan&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>index</span><span class=p>,</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>dataset</span><span class=o>.</span><span class=n>iterrows</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>home_team</span> <span class=o>=</span> <span class=n>row</span><span class=p>[</span><span class=s2>&#34;Home Team&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>visitor_team</span> <span class=o>=</span> <span class=n>row</span><span class=p>[</span><span class=s2>&#34;Visitor Team&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>row</span><span class=p>[</span><span class=s2>&#34;HWinTimes&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=n>last_five_games</span><span class=p>[</span><span class=n>home_team</span><span class=p>][</span><span class=o>-</span><span class=mi>5</span><span class=p>:])</span>
</span></span><span class=line><span class=cl>        <span class=n>row</span><span class=p>[</span><span class=s2>&#34;VWinTimes&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=n>last_five_games</span><span class=p>[</span><span class=n>visitor_team</span><span class=p>][</span><span class=o>-</span><span class=mi>5</span><span class=p>:])</span>
</span></span><span class=line><span class=cl>        <span class=n>row</span><span class=p>[</span><span class=s2>&#34;HLastPlayedSpan&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>row</span><span class=p>[</span><span class=s2>&#34;Date&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>date</span><span class=p>()</span> <span class=o>-</span>
</span></span><span class=line><span class=cl>            <span class=n>last_played_date</span><span class=p>[</span><span class=n>home_team</span><span class=p>])</span><span class=o>.</span><span class=n>days</span>
</span></span><span class=line><span class=cl>        <span class=n>row</span><span class=p>[</span><span class=s2>&#34;VLastPlayedSpan&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>row</span><span class=p>[</span><span class=s2>&#34;Date&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>date</span><span class=p>()</span> <span class=o>-</span>
</span></span><span class=line><span class=cl>            <span class=n>last_played_date</span><span class=p>[</span><span class=n>visitor_team</span><span class=p>])</span><span class=o>.</span><span class=n>days</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>dataset</span><span class=o>.</span><span class=n>iloc</span><span class=p>[</span><span class=n>index</span><span class=p>]</span> <span class=o>=</span> <span class=n>row</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>last_played_date</span><span class=p>[</span><span class=n>home_team</span><span class=p>]</span> <span class=o>=</span> <span class=n>row</span><span class=p>[</span><span class=s2>&#34;Date&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>date</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>last_played_date</span><span class=p>[</span><span class=n>visitor_team</span><span class=p>]</span> <span class=o>=</span> <span class=n>row</span><span class=p>[</span><span class=s2>&#34;Date&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>date</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>last_five_games</span><span class=p>[</span><span class=n>home_team</span><span class=p>]</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>row</span><span class=p>[</span><span class=s2>&#34;HomeWin&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=n>last_five_games</span><span class=p>[</span><span class=n>visitor_team</span><span class=p>]</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=ow>not</span> <span class=n>row</span><span class=p>[</span><span class=s2>&#34;HomeWin&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>X_1</span> <span class=o>=</span> <span class=n>dataset</span><span class=p>[[</span><span class=s2>&#34;HLastPlayedSpan&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                             <span class=s2>&#34;VLastPlayedSpan&#34;</span><span class=p>,</span> <span class=s2>&#34;HWinTimes&#34;</span><span class=p>,</span> <span class=s2>&#34;VWinTimes&#34;</span><span class=p>]]</span><span class=o>.</span><span class=n>values</span>
</span></span><span class=line><span class=cl>    <span class=n>clf</span> <span class=o>=</span> <span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>14</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>scores</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>clf</span><span class=p>,</span> <span class=n>X_1</span><span class=p>,</span> <span class=n>y_true</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;DecisionTree: Using time span and win times&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Accuracy: </span><span class=si>{0:.1f}</span><span class=s2>%&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>)</span> <span class=o>*</span> <span class=mi>100</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>clf</span> <span class=o>=</span> <span class=n>RandomForestClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>14</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>scores</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>clf</span><span class=p>,</span> <span class=n>X_1</span><span class=p>,</span> <span class=n>y_true</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;RandomForest: Using time span and win times&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Accuracy: </span><span class=si>{0:.1f}</span><span class=s2>%&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>)</span> <span class=o>*</span> <span class=mi>100</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;---------------------------------&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>X_all</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>hstack</span><span class=p>([</span><span class=n>X_1</span><span class=p>,</span> <span class=n>X_all</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>clf</span> <span class=o>=</span> <span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>14</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>scores</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>clf</span><span class=p>,</span> <span class=n>X_all</span><span class=p>,</span> <span class=n>y_true</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;DecisionTree: Using time span and win times&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Accuracy: </span><span class=si>{0:.1f}</span><span class=s2>%&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>)</span> <span class=o>*</span> <span class=mi>100</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>clf</span> <span class=o>=</span> <span class=n>RandomForestClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>14</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>scores</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>clf</span><span class=p>,</span> <span class=n>X_all</span><span class=p>,</span> <span class=n>y_true</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;RandomForest: Using time span and win times&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Accuracy: </span><span class=si>{0:.1f}</span><span class=s2>%&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>)</span> <span class=o>*</span> <span class=mi>100</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;---------------------------------&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>parameter_space</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;max_features&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=s1>&#39;auto&#39;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;n_estimators&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mi>100</span><span class=p>,</span> <span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;criterion&#34;</span><span class=p>:</span> <span class=p>[</span><span class=s2>&#34;gini&#34;</span><span class=p>,</span> <span class=s2>&#34;entropy&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;min_samples_leaf&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=n>grid</span> <span class=o>=</span> <span class=n>GridSearchCV</span><span class=p>(</span><span class=n>clf</span><span class=p>,</span> <span class=n>parameter_space</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>grid</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_all</span><span class=p>,</span> <span class=n>y_true</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Accuracy: </span><span class=si>{0:.1f}</span><span class=s2>%&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>grid</span><span class=o>.</span><span class=n>best_score_</span> <span class=o>*</span> <span class=mi>100</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>grid</span><span class=o>.</span><span class=n>best_estimator_</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>DecisionTree: Using time span and win times
Accuracy: 56.4%
RandomForest: Using time span and win times
Accuracy: 58.3%
---------------------------------
DecisionTree: Using time span and win times
Accuracy: 57.2%
RandomForest: Using time span and win times
Accuracy: 61.0%
---------------------------------
Accuracy: 64.6%
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                    criterion='entropy', max_depth=None, max_features=2,
                    max_leaf_nodes=None, max_samples=None,
                    min_impurity_decrease=0.0, min_impurity_split=None,
                    min_samples_leaf=4, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, n_estimators=100,
                    n_jobs=-1, oob_score=False, random_state=14, verbose=0,
                    warm_start=False)
</code></pre><p><img class=lazyload src=/svg/loading.min.svg data-src=/img/in-post/data-mining/ch3/homework.jpg data-srcset="/img/in-post/data-mining/ch3/homework.jpg, /img/in-post/data-mining/ch3/homework.jpg 1.5x, /img/in-post/data-mining/ch3/homework.jpg 2x" data-sizes=auto alt=/img/in-post/data-mining/ch3/homework.jpg title=数据集情况></p><h2 id=第四章>第四章</h2><p>本章重点：</p><ul><li>亲和性分析</li><li>用 Apriori 算法挖掘关联特征</li><li>数据稀疏问题</li></ul><h3 id=亲和性分析-1>亲和性分析</h3><p>Apriori 算法是经典的亲和性分析算法，它只从数据集中频繁出现的商品中选取出共同出现的商品组成频繁项集，避免了复杂度呈指数级增长的问题。一旦找到频繁项集，生成关联规则就变得容易了。</p><p>原理：确保了规则在数据集中有足够的支持度。Apriori 算法一个重要参数就是最小支持度，如果想要生成(A,B,C)的频繁项集，则其子集必须都要满足最小支持度标准。</p><p>其它亲和性算法还有 Eclat 和频繁项集挖掘算法(FP-growth)。这些算法比起基础的 Apriori 算法有很多改进，性能也有进一步提升。</p><p>第一阶段，为 Apriori 算法指定一个项集要成为频繁项集所需的最小支持度。第二阶段，根据置信度取关联规则，设定最小置信度，返回大于此值的规则。</p><h3 id=电影推荐问题>电影推荐问题</h3><p><a href=http://files.grouplens.org/datasets/movielens/ml-100k.zip target=_blank rel="noopener noreffer">下载</a>并加载数据集</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>sys</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>collections</span> <span class=kn>import</span> <span class=n>defaultdict</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>operator</span> <span class=kn>import</span> <span class=n>itemgetter</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s1>&#39;__main__&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># header=None 不把第一行当做表头</span>
</span></span><span class=line><span class=cl>    <span class=n>all_ratings</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;ml-100k/u.data&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>delimiter</span><span class=o>=</span><span class=s2>&#34;</span><span class=se>\t</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>header</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>names</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;UserID&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;MovieID&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;Rating&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;Datetime&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=c1># 转化时间戳为datetime</span>
</span></span><span class=line><span class=cl>    <span class=n>all_ratings</span><span class=p>[</span><span class=s2>&#34;Datetime&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>to_datetime</span><span class=p>(</span><span class=n>all_ratings</span><span class=p>[</span><span class=s2>&#34;Datetime&#34;</span><span class=p>],</span> <span class=n>unit</span><span class=o>=</span><span class=s1>&#39;s&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 输出用户-电影-评分稀疏矩阵</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>all_ratings</span><span class=p>[:</span><span class=mi>5</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=c1># 创建Favorite特征，将评分属性二值化为是否喜欢</span>
</span></span><span class=line><span class=cl>    <span class=n>all_ratings</span><span class=p>[</span><span class=s2>&#34;Favorable&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>all_ratings</span><span class=p>[</span><span class=s2>&#34;Rating&#34;</span><span class=p>]</span> <span class=o>&gt;</span> <span class=mi>3</span>
</span></span><span class=line><span class=cl>    <span class=c1># 取用户ID为前200的用户的打分数据</span>
</span></span><span class=line><span class=cl>    <span class=n>ratings</span> <span class=o>=</span> <span class=n>all_ratings</span><span class=p>[</span><span class=n>all_ratings</span><span class=p>[</span><span class=s2>&#34;UserID&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>isin</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=mi>200</span><span class=p>))]</span>
</span></span><span class=line><span class=cl>    <span class=n>favorable_ratings</span> <span class=o>=</span> <span class=n>ratings</span><span class=p>[</span><span class=n>ratings</span><span class=p>[</span><span class=s2>&#34;Favorable&#34;</span><span class=p>]]</span>
</span></span><span class=line><span class=cl>    <span class=c1># 创建用户喜欢哪些电影的字典</span>
</span></span><span class=line><span class=cl>    <span class=n>favorable_reviews_by_users</span> <span class=o>=</span> <span class=nb>dict</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=n>k</span><span class=p>,</span>
</span></span><span class=line><span class=cl>         <span class=nb>frozenset</span><span class=p>(</span>
</span></span><span class=line><span class=cl>             <span class=n>v</span><span class=o>.</span><span class=n>values</span><span class=p>))</span> <span class=k>for</span> <span class=n>k</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>v</span> <span class=ow>in</span> <span class=n>favorable_ratings</span><span class=o>.</span><span class=n>groupby</span><span class=p>(</span><span class=s2>&#34;UserID&#34;</span><span class=p>)[</span><span class=s2>&#34;MovieID&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=c1># 创建一个数据框，了解每部电影的影迷数量</span>
</span></span><span class=line><span class=cl>    <span class=n>num_favorable_by_movie</span> <span class=o>=</span> <span class=n>ratings</span><span class=p>[[</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;MovieID&#34;</span><span class=p>,</span> <span class=s2>&#34;Favorable&#34;</span><span class=p>]]</span><span class=o>.</span><span class=n>groupby</span><span class=p>(</span><span class=s2>&#34;MovieID&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=c1># 查看最受欢迎的五部电影</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>num_favorable_by_movie</span><span class=o>.</span><span class=n>sort_values</span><span class=p>(</span><span class=s2>&#34;Favorable&#34;</span><span class=p>,</span> <span class=n>ascending</span><span class=o>=</span><span class=kc>False</span><span class=p>)[:</span><span class=mi>5</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>UserID  MovieID  Rating            Datetime
0     196      242       3 1997-12-04 15:55:49
1     186      302       3 1998-04-04 19:22:22
2      22      377       1 1997-11-07 07:18:36
3     244       51       2 1997-11-27 05:02:03
4     166      346       1 1998-02-02 05:33:16

        Favorable
MovieID
50           100.0
100           89.0
258           83.0
181           79.0
174           74.0
</code></pre><h3 id=apriori-算法的实现>Apriori 算法的实现</h3><ol><li>把各项目放到只包含自己的项集中，生成最初的频繁项集。只使用达到最小支持度的项目。</li><li>查找现有频繁项集的超集，发现新的频繁项集，并用其生成新的备选项集。</li><li>测试新生成的备选项集的频繁程度（与最小支持度比较），如果不够频繁则舍弃。如果没有新的频繁项集，就跳到最后一步。</li><li>存储新发现的频繁项集，跳到步骤 2</li><li>返回所有的频繁项集</li></ol><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># 字典保存最新发现的频繁项集</span>
</span></span><span class=line><span class=cl>    <span class=n>frequent_itemsets</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl>    <span class=n>min_support</span> <span class=o>=</span> <span class=mi>50</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 第一步，每一步电影生成只包含它自己的项集</span>
</span></span><span class=line><span class=cl>    <span class=c1># frozenset() 返回一个冻结的集合，冻结后集合不能再添加或删除任何元素</span>
</span></span><span class=line><span class=cl>    <span class=c1># 普通集合可变，集合中不能有可变的元素，因此普通集合不能被放在集合中；冻结集合不可变，因此可以被放入集合</span>
</span></span><span class=line><span class=cl>    <span class=n>frequent_itemsets</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>=</span> <span class=nb>dict</span><span class=p>((</span><span class=nb>frozenset</span><span class=p>((</span><span class=n>movie_id</span><span class=p>,)),</span>
</span></span><span class=line><span class=cl>         <span class=n>row</span><span class=p>[</span><span class=s2>&#34;Favorable&#34;</span><span class=p>])</span> <span class=k>for</span> <span class=n>movie_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>row</span> <span class=ow>in</span> <span class=n>num_favorable_by_movie</span><span class=o>.</span><span class=n>iterrows</span><span class=p>()</span> <span class=k>if</span> <span class=n>row</span><span class=p>[</span><span class=s2>&#34;Favorable&#34;</span><span class=p>]</span> <span class=o>&gt;</span> <span class=n>min_support</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 会有重复，导致喜欢电影1,50的人分别为50,100但是 {1,50} 的集合有100个</span>
</span></span><span class=line><span class=cl>    <span class=c1># 两个原因，第一在current_superset时项集有时候会突然调换位置</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>find_frequent_itemsets</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>favorable_reviews_by_users</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>k_1_itemsets</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>min_support</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>counts</span> <span class=o>=</span> <span class=n>defaultdict</span><span class=p>(</span><span class=nb>int</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># 遍历每一个用户，获取其喜欢的电影</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>user</span><span class=p>,</span> <span class=n>reviews</span> <span class=ow>in</span> <span class=n>favorable_reviews_by_users</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=c1># 遍历每个项集</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>itemset</span> <span class=ow>in</span> <span class=n>k_1_itemsets</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=n>itemset</span><span class=o>.</span><span class=n>issubset</span><span class=p>(</span><span class=n>reviews</span><span class=p>):</span>  <span class=c1># 判断itemset是否是用户喜欢的电影的子集</span>
</span></span><span class=line><span class=cl>                    <span class=c1># 对用户喜欢的电影中除了这个子集的电影进行遍历</span>
</span></span><span class=line><span class=cl>                    <span class=k>for</span> <span class=n>other_reviewed_movie</span> <span class=ow>in</span> <span class=n>reviews</span> <span class=o>-</span> <span class=n>itemset</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                        <span class=c1># 将该电影并入项集中</span>
</span></span><span class=line><span class=cl>                        <span class=n>current_superset</span> <span class=o>=</span> <span class=n>itemset</span> <span class=o>|</span> <span class=nb>frozenset</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                            <span class=p>{</span><span class=n>other_reviewed_movie</span><span class=p>})</span>
</span></span><span class=line><span class=cl>                        <span class=n>counts</span><span class=p>[</span><span class=n>current_superset</span><span class=p>]</span> <span class=o>+=</span> <span class=mi>1</span>  <span class=c1># 这个项集的支持度+1</span>
</span></span><span class=line><span class=cl>        <span class=c1># 返回元素数目+1的项集和数量</span>
</span></span><span class=line><span class=cl>        <span class=n>res</span> <span class=o>=</span> <span class=nb>dict</span><span class=p>([(</span><span class=n>itemset</span><span class=p>,</span> <span class=n>frequency</span><span class=p>)</span> <span class=k>for</span> <span class=n>itemset</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                             <span class=n>frequency</span> <span class=ow>in</span> <span class=n>counts</span><span class=o>.</span><span class=n>items</span><span class=p>()</span> <span class=k>if</span> <span class=n>frequency</span> <span class=o>&gt;=</span> <span class=n>min_support</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>res</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>k</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>20</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>cur_frequent_itemsets</span> <span class=o>=</span> <span class=n>find_frequent_itemsets</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>favorable_reviews_by_users</span><span class=p>,</span> <span class=n>frequent_itemsets</span><span class=p>[</span><span class=n>k</span> <span class=o>-</span> <span class=mi>1</span><span class=p>],</span> <span class=n>min_support</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>frequent_itemsets</span><span class=p>[</span><span class=n>k</span><span class=p>]</span> <span class=o>=</span> <span class=n>cur_frequent_itemsets</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>cur_frequent_itemsets</span><span class=p>)</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Did not find any frequent itemsets of length </span><span class=si>{}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>k</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=n>sys</span><span class=o>.</span><span class=n>stdout</span><span class=o>.</span><span class=n>flush</span><span class=p>()</span>  <span class=c1># 将缓冲区内容输出到终端，不宜多用，输出操作带来的计算开销会拖慢程序运行速度</span>
</span></span><span class=line><span class=cl>            <span class=k>break</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;I found </span><span class=si>{}</span><span class=s2> frequent itemsets of length </span><span class=si>{}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                    <span class=nb>len</span><span class=p>(</span><span class=n>cur_frequent_itemsets</span><span class=p>),</span> <span class=n>k</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=n>sys</span><span class=o>.</span><span class=n>stdout</span><span class=o>.</span><span class=n>flush</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=c1># 除去只包含一个元素的初始集合</span>
</span></span><span class=line><span class=cl>    <span class=k>del</span> <span class=n>frequent_itemsets</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>I found 93 frequent itemsets of length 2
I found 295 frequent itemsets of length 3
I found 593 frequent itemsets of length 4
I found 785 frequent itemsets of length 5
I found 677 frequent itemsets of length 6
I found 373 frequent itemsets of length 7
I found 126 frequent itemsets of length 8
I found 24 frequent itemsets of length 9
I found 2 frequent itemsets of length 10
Did not find any frequent itemsets of length 11
</code></pre><h3 id=抽取关联规则>抽取关联规则</h3><p>对每个频繁项集，选出其中的一个元素当结论，剩下的元素都作为条件，生成规则。</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># 规则形式：如果用户喜欢前提中的所有电影，那么他们也会喜欢结论中的电影</span>
</span></span><span class=line><span class=cl>    <span class=n>candidate_rules</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>itemset_length</span><span class=p>,</span> <span class=n>itemset_counts</span> <span class=ow>in</span> <span class=n>frequent_itemsets</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>itemset</span> <span class=ow>in</span> <span class=n>itemset_counts</span><span class=o>.</span><span class=n>keys</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>conclusion</span> <span class=ow>in</span> <span class=n>itemset</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>premise</span> <span class=o>=</span> <span class=n>itemset</span> <span class=o>-</span> <span class=p>{</span><span class=n>conclusion</span><span class=p>}</span>
</span></span><span class=line><span class=cl>                <span class=n>candidate_rules</span><span class=o>.</span><span class=n>append</span><span class=p>((</span><span class=n>premise</span><span class=p>,</span> <span class=n>conclusion</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>candidate_rules</span><span class=p>[:</span><span class=mi>5</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>[(frozenset({7}), 1), (frozenset({1}), 7), (frozenset({50}), 1), (frozenset({1}), 50), (frozenset({1}), 56)]
</code></pre><hr><p>置信度计算，方法与第一章类似。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># 计算置信度</span>
</span></span><span class=line><span class=cl>    <span class=n>correct_counts</span> <span class=o>=</span> <span class=n>defaultdict</span><span class=p>(</span><span class=nb>int</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>incorrect_counts</span> <span class=o>=</span> <span class=n>defaultdict</span><span class=p>(</span><span class=nb>int</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 遍历每一个用户，获取其喜欢的电影</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>user</span><span class=p>,</span> <span class=n>reviews</span> <span class=ow>in</span> <span class=n>favorable_reviews_by_users</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=c1># 遍历每个规则</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>candidate_rule</span> <span class=ow>in</span> <span class=n>candidate_rules</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># 获取规则的条件和结论</span>
</span></span><span class=line><span class=cl>            <span class=n>premise</span><span class=p>,</span> <span class=n>conclusion</span> <span class=o>=</span> <span class=n>candidate_rule</span>
</span></span><span class=line><span class=cl>            <span class=c1># 如果条件是喜欢电影的子集（条件成立）</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>premise</span><span class=o>.</span><span class=n>issubset</span><span class=p>(</span><span class=n>reviews</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=c1># 如果用户也喜欢结论的电影</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=n>conclusion</span> <span class=ow>in</span> <span class=n>reviews</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=n>correct_counts</span><span class=p>[</span><span class=n>candidate_rule</span><span class=p>]</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>                <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=n>incorrect_counts</span><span class=p>[</span><span class=n>candidate_rule</span><span class=p>]</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>    <span class=c1># 计算置信度，结论发生的次数除以条件发生的次数</span>
</span></span><span class=line><span class=cl>    <span class=n>rule_confidence</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>candidate_rule</span><span class=p>:</span> <span class=n>correct_counts</span><span class=p>[</span><span class=n>candidate_rule</span><span class=p>]</span> <span class=o>/</span>
</span></span><span class=line><span class=cl>        <span class=nb>float</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>correct_counts</span><span class=p>[</span><span class=n>candidate_rule</span><span class=p>]</span> <span class=o>+</span>
</span></span><span class=line><span class=cl>            <span class=n>incorrect_counts</span><span class=p>[</span><span class=n>candidate_rule</span><span class=p>])</span> <span class=k>for</span> <span class=n>candidate_rule</span> <span class=ow>in</span> <span class=n>candidate_rules</span><span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=c1># 给置信度排序</span>
</span></span><span class=line><span class=cl>    <span class=n>sorted_confidence</span> <span class=o>=</span> <span class=nb>sorted</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>rule_confidence</span><span class=o>.</span><span class=n>items</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>        <span class=n>key</span><span class=o>=</span><span class=n>itemgetter</span><span class=p>(</span><span class=mi>1</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>reverse</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>index</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>5</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Rule #</span><span class=si>{}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>index</span> <span class=o>+</span> <span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=n>premise</span><span class=p>,</span> <span class=n>conclusion</span><span class=p>)</span> <span class=o>=</span> <span class=n>sorted_confidence</span><span class=p>[</span><span class=n>index</span><span class=p>][</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;Rule: If a person recommends </span><span class=si>{}</span><span class=s2> they will also recommand </span><span class=si>{}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>premise</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>conclusion</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;- Confidence: </span><span class=si>{0:.3f}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>rule_confidence</span><span class=p>[(</span><span class=n>premise</span><span class=p>,</span> <span class=n>conclusion</span><span class=p>)]))</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;--------------------&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>Rule #1
Rule: If a person recommends frozenset({98, 181}) they will also recommand 50
- Confidence: 1.000
--------------------
Rule #2
Rule: If a person recommends frozenset({172, 79}) they will also recommand 174
- Confidence: 1.000
--------------------
Rule #3
Rule: If a person recommends frozenset({258, 172}) they will also recommand 174
- Confidence: 1.000
--------------------
Rule #4
Rule: If a person recommends frozenset({1, 181, 7}) they will also recommand 50
- Confidence: 1.000
--------------------
Rule #5
Rule: If a person recommends frozenset({1, 172, 7}) they will also recommand 174
- Confidence: 1.000
--------------------
</code></pre><hr><p>调整输出，加上电影名</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=n>movie_name_data</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;ml-100k/u.item&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>delimiter</span><span class=o>=</span><span class=s1>&#39;|&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>header</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>encoding</span><span class=o>=</span><span class=s2>&#34;mac-roman&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>movie_name_data</span><span class=o>.</span><span class=n>columns</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;MovieID&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;Title&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;Release Date&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;Video Release&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;IMDB&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;&lt;UNK&gt;&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;Action&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;Adventure&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;Animation&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Children&#39;s&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;Comedy&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;Crime&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;Documentary&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;Drama&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;Fantasy&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;Film-Noir&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;Horror&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;Musical&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;Mystery&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;Romance&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;Sci-Fi&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;Thriller&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;War&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;Western&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>index</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>5</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Rule #</span><span class=si>{0}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>index</span> <span class=o>+</span> <span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=n>premise</span><span class=p>,</span> <span class=n>conclusion</span><span class=p>)</span> <span class=o>=</span> <span class=n>sorted_confidence</span><span class=p>[</span><span class=n>index</span><span class=p>][</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>premise_names</span> <span class=o>=</span> <span class=s1>&#39;, &#39;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>get_movie_name</span><span class=p>(</span><span class=n>idx</span><span class=p>)</span> <span class=k>for</span> <span class=n>idx</span> <span class=ow>in</span> <span class=n>premise</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>conclusion_name</span> <span class=o>=</span> <span class=n>get_movie_name</span><span class=p>(</span><span class=n>conclusion</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;Rule: if a person recommends </span><span class=si>{0}</span><span class=s1> they will also recommend </span><span class=si>{1}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>premise_names</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>conclusion_name</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39; - Confidence: </span><span class=si>{0:.3f}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>rule_confidence</span><span class=p>[(</span><span class=n>premise</span><span class=p>,</span> <span class=n>conclusion</span><span class=p>)]))</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;--------------------&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>Rule #1
Rule: if a person recommends Silence of the Lambs, The (1991), Return of the Jedi (1983) they will also recommend Star Wars (1977)
- Confidence: 1.000
--------------------
Rule #2
Rule: if a person recommends Empire Strikes Back, The (1980), Fugitive, The (1993) they will also recommend Raiders of the Lost Ark (1981)
- Confidence: 1.000
--------------------
Rule #3
Rule: if a person recommends Contact (1997), Empire Strikes Back, The (1980) they will also recommend Raiders of the Lost Ark (1981)
- Confidence: 1.000
--------------------
Rule #4
Rule: if a person recommends Toy Story (1995), Return of the Jedi (1983), Twelve Monkeys (1995) they will also recommend Star Wars (1977)
- Confidence: 1.000
--------------------
Rule #5
Rule: if a person recommends Toy Story (1995), Empire Strikes Back, The (1980), Twelve Monkeys (1995) they will also recommend Raiders of the Lost Ark (1981)
- Confidence: 1.000
--------------------
</code></pre><h3 id=评估测试>评估测试</h3><p>使用剩下的数据集计算规则的置信度，也是查看每条规则表现的一个方法。</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># 评估测试</span>
</span></span><span class=line><span class=cl>    <span class=n>test_dataset</span> <span class=o>=</span> <span class=n>all_ratings</span><span class=p>[</span><span class=o>~</span><span class=n>all_ratings</span><span class=p>[</span><span class=s1>&#39;UserID&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>isin</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=mi>200</span><span class=p>))]</span>
</span></span><span class=line><span class=cl>    <span class=n>test_favorable</span> <span class=o>=</span> <span class=n>test_dataset</span><span class=p>[</span><span class=n>test_dataset</span><span class=p>[</span><span class=s2>&#34;Favorable&#34;</span><span class=p>]]</span>
</span></span><span class=line><span class=cl>    <span class=n>test_favorable_by_users</span> <span class=o>=</span> <span class=nb>dict</span><span class=p>((</span><span class=n>k</span><span class=p>,</span> <span class=nb>frozenset</span><span class=p>(</span><span class=n>v</span><span class=o>.</span><span class=n>values</span><span class=p>))</span>
</span></span><span class=line><span class=cl>                                   <span class=k>for</span> <span class=n>k</span><span class=p>,</span> <span class=n>v</span> <span class=ow>in</span> <span class=n>test_favorable</span><span class=o>.</span><span class=n>groupby</span><span class=p>(</span><span class=s2>&#34;UserID&#34;</span><span class=p>)[</span><span class=s2>&#34;MovieID&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>correct_counts</span> <span class=o>=</span> <span class=n>defaultdict</span><span class=p>(</span><span class=nb>int</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>incorrect_counts</span> <span class=o>=</span> <span class=n>defaultdict</span><span class=p>(</span><span class=nb>int</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>user</span><span class=p>,</span> <span class=n>reviews</span> <span class=ow>in</span> <span class=n>test_favorable_by_users</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>candidate_rule</span> <span class=ow>in</span> <span class=n>candidate_rules</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>premise</span><span class=p>,</span> <span class=n>conclusion</span> <span class=o>=</span> <span class=n>candidate_rule</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>premise</span><span class=o>.</span><span class=n>issubset</span><span class=p>(</span><span class=n>reviews</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=n>conclusion</span> <span class=ow>in</span> <span class=n>reviews</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=n>correct_counts</span><span class=p>[</span><span class=n>candidate_rule</span><span class=p>]</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>                <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=n>incorrect_counts</span><span class=p>[</span><span class=n>candidate_rule</span><span class=p>]</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>test_confidence</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>candidate_rule</span><span class=p>:</span> <span class=n>correct_counts</span><span class=p>[</span><span class=n>candidate_rule</span><span class=p>]</span> <span class=o>/</span>
</span></span><span class=line><span class=cl>        <span class=nb>float</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>correct_counts</span><span class=p>[</span><span class=n>candidate_rule</span><span class=p>]</span> <span class=o>+</span>
</span></span><span class=line><span class=cl>            <span class=n>incorrect_counts</span><span class=p>[</span><span class=n>candidate_rule</span><span class=p>])</span> <span class=k>for</span> <span class=n>candidate_rule</span> <span class=ow>in</span> <span class=n>rule_confidence</span><span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>index</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>5</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Rule #</span><span class=si>{0}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>index</span> <span class=o>+</span> <span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=n>premise</span><span class=p>,</span> <span class=n>conclusion</span><span class=p>)</span> <span class=o>=</span> <span class=n>sorted_confidence</span><span class=p>[</span><span class=n>index</span><span class=p>][</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>premise_names</span> <span class=o>=</span> <span class=s2>&#34;, &#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>get_movie_name</span><span class=p>(</span><span class=n>idx</span><span class=p>)</span> <span class=k>for</span> <span class=n>idx</span> <span class=ow>in</span> <span class=n>premise</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>conclusion_name</span> <span class=o>=</span> <span class=n>get_movie_name</span><span class=p>(</span><span class=n>conclusion</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;Rule: if a person recommends </span><span class=si>{0}</span><span class=s1> they will also recommend </span><span class=si>{1}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>premise_names</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>conclusion_name</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39; - Confidence: </span><span class=si>{0:.3f}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>rule_confidence</span><span class=p>[(</span><span class=n>premise</span><span class=p>,</span> <span class=n>conclusion</span><span class=p>)]))</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;--------------------&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>Rule #1
Rule: if a person recommends Silence of the Lambs, The (1991), Return of the Jedi (1983) they will also recommend Star Wars (1977)
- Confidence: 1.000
--------------------
Rule #2
Rule: if a person recommends Empire Strikes Back, The (1980), Fugitive, The (1993) they will also recommend Raiders of the Lost Ark (1981)
- Confidence: 1.000
--------------------
Rule #3
Rule: if a person recommends Contact (1997), Empire Strikes Back, The (1980) they will also recommend Raiders of the Lost Ark (1981)
- Confidence: 1.000
--------------------
Rule #4
Rule: if a person recommends Toy Story (1995), Return of the Jedi (1983), Twelve Monkeys (1995) they will also recommend Star Wars (1977)
- Confidence: 1.000
--------------------
Rule #5
Rule: if a person recommends Toy Story (1995), Empire Strikes Back, The (1980), Twelve Monkeys (1995) they will also recommend Raiders of the Lost Ark (1981)
- Confidence: 1.000
--------------------
</code></pre><p>这一章用电影进行亲和度分析，由于元素的数量变多了，时间复杂度呈指数级增长，遍历的笨方法已经不适用。需要寻找更加巧妙地解决方案。</p><p>在用集合计算电影的项集时，<code>{1, 2}</code> 与 <code>{2, 1}</code> 是同一个事件，但在遍历的时候会被多次计算，可能这是一个错误的点。</p><h2 id=第五章>第五章</h2><p>本章讨论如何从数据集中抽取数值和类别型特征，并选出最佳特征。还会介绍特征抽取的常用模式和技巧。</p><h3 id=特征抽取>特征抽取</h3><p>把实体用特征表示出来，通过特征建模，再通过机器挖掘算法能够理解的近似方式来表示现实。</p><p>特征可以是数值型或类别型。数值特征可以离散化生成类别特征。</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s1>&#39;__main__&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>adult</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s2>&#34;adult.data&#34;</span><span class=p>,</span> <span class=n>header</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>names</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;Age&#34;</span><span class=p>,</span> <span class=s2>&#34;Work-Class&#34;</span><span class=p>,</span> <span class=s2>&#34;fnlwgt&#34;</span><span class=p>,</span> <span class=s2>&#34;Education&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                                          <span class=s2>&#34;Education-Num&#34;</span><span class=p>,</span> <span class=s2>&#34;Marital-Status&#34;</span><span class=p>,</span> <span class=s2>&#34;Occupation&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                                          <span class=s2>&#34;Relationship&#34;</span><span class=p>,</span> <span class=s2>&#34;Race&#34;</span><span class=p>,</span> <span class=s2>&#34;Sex&#34;</span><span class=p>,</span> <span class=s2>&#34;Capital-gain&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                                          <span class=s2>&#34;Capital-loss&#34;</span><span class=p>,</span> <span class=s2>&#34;Hours-per-week&#34;</span><span class=p>,</span> <span class=s2>&#34;Native-Country&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                                          <span class=s2>&#34;Earnings-Raw&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=c1># 去除空值</span>
</span></span><span class=line><span class=cl>    <span class=n>adult</span><span class=o>.</span><span class=n>dropna</span><span class=p>(</span><span class=n>how</span><span class=o>=</span><span class=s1>&#39;all&#39;</span><span class=p>,</span> <span class=n>inplace</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 输出详细描述</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>adult</span><span class=p>[</span><span class=s2>&#34;Hours-per-week&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>describe</span><span class=p>())</span>
</span></span><span class=line><span class=cl>    <span class=c1># 输出中位数</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>adult</span><span class=p>[</span><span class=s2>&#34;Education-Num&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>median</span><span class=p>())</span>
</span></span><span class=line><span class=cl>    <span class=c1># 输出工作的种类</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>adult</span><span class=p>[</span><span class=s2>&#34;Work-Class&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>unique</span><span class=p>())</span>
</span></span><span class=line><span class=cl>    <span class=c1># 将工作时长二值化为是否超过40h</span>
</span></span><span class=line><span class=cl>    <span class=n>adult</span><span class=p>[</span><span class=s2>&#34;LongHours&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>adult</span><span class=p>[</span><span class=s2>&#34;Hours-per-week&#34;</span><span class=p>]</span> <span class=o>&gt;</span> <span class=mi>40</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>count    32561.000000
mean        40.437456
std         12.347429
min          1.000000
25%         40.000000
50%         40.000000
75%         45.000000
max         99.000000
Name: Hours-per-week, dtype: float64
10.0
[' State-gov' ' Self-emp-not-inc' ' Private' ' Federal-gov' ' Local-gov'
' ?' ' Self-emp-inc' ' Without-pay' ' Never-worked']
</code></pre><h3 id=特征选择>特征选择</h3><p>实物的特征有很多，我们只选择其中一小部分。</p><ul><li>降低复杂度，提高算法运行速度</li><li>减低噪音，增加无关的特征会干扰算法的工作</li><li>增加模型可读性，特征较少，人们易于理解</li></ul><p>拿到数据后，先进行简单直接的分析，了解数据的特点。</p><p><code>sklearn.feature_selection.VarianceThreshold</code> 转换器可以用来删除特征值的方差达不到最低标准的特征。</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># 构造测试数据集</span>
</span></span><span class=line><span class=cl>    <span class=n>X</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>30</span><span class=p>)</span><span class=o>.</span><span class=n>reshape</span><span class=p>((</span><span class=mi>10</span><span class=p>,</span> <span class=mi>3</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>X</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>]</span> <span class=o>=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;----------------&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>vt</span> <span class=o>=</span> <span class=n>VarianceThreshold</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>Xt</span> <span class=o>=</span> <span class=n>vt</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 第二列消失了，因为第二列都是1，方差为0，不包括具有区别意义的信息</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>Xt</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;----------------&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>vt</span><span class=o>.</span><span class=n>variances_</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>[[ 0  1  2]
[ 3  1  5]
[ 6  1  8]
[ 9  1 11]
[12  1 14]
[15  1 17]
[18  1 20]
[21  1 23]
[24  1 26]
[27  1 29]]
----------------
[[ 0  2]
[ 3  5]
[ 6  8]
[ 9 11]
[12 14]
[15 17]
[18 20]
[21 23]
[24 26]
[27 29]]
----------------
[27.  0. 27.]
</code></pre><hr><p>选择最佳特征</p><p>随着特征数量的增加，寻找最佳特征组合的任务复杂度呈指数级增长。分类任务通常的做法是寻找表现好的单个特征，依据是他们能达到的精确度。</p><p>scikit-learn 提供了几个用于选择单变量特征的转换器。</p><ul><li>SelectKBest 返回 k 个最佳特征</li><li>SelectPercentile 返回表现最佳的 r%个特征</li></ul><p>这两个转换器都提供计算特征表现的一系列方法。</p><p>单个特征和某一类别之间的相关性计算方法有卡方检验(x²)、互信息和信息熵等。</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># 构造数据集</span>
</span></span><span class=line><span class=cl>    <span class=n>X</span> <span class=o>=</span> <span class=n>adult</span><span class=p>[[</span><span class=s2>&#34;Age&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>               <span class=s2>&#34;Education-Num&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>               <span class=s2>&#34;Capital-gain&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>               <span class=s2>&#34;Capital-loss&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>               <span class=s2>&#34;Hours-per-week&#34;</span><span class=p>]]</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=p>(</span><span class=n>adult</span><span class=p>[</span><span class=s2>&#34;Earnings-Raw&#34;</span><span class=p>]</span> <span class=o>==</span> <span class=s1>&#39; &gt;50K&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>values</span>
</span></span><span class=line><span class=cl>    <span class=c1># 使用SelectKBest转换器，用卡方打分</span>
</span></span><span class=line><span class=cl>    <span class=n>transformer</span> <span class=o>=</span> <span class=n>SelectKBest</span><span class=p>(</span><span class=n>score_func</span><span class=o>=</span><span class=n>chi2</span><span class=p>,</span> <span class=n>k</span><span class=o>=</span><span class=mi>3</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 调用fit_transform方法对相同的数据集进行预处理和转换</span>
</span></span><span class=line><span class=cl>    <span class=n>Xt_chi2</span> <span class=o>=</span> <span class=n>transformer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 输出每个特征的得分</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>transformer</span><span class=o>.</span><span class=n>scores_</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;----------------&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 用皮尔逊相关系数计算相关性,创建包装函数</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>mutivariate_pearsonr</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>scores</span><span class=p>,</span> <span class=n>pvalues</span> <span class=o>=</span> <span class=p>[],</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>column</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>X</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]):</span>
</span></span><span class=line><span class=cl>            <span class=n>cur_score</span><span class=p>,</span> <span class=n>cur_p</span> <span class=o>=</span> <span class=n>pearsonr</span><span class=p>(</span><span class=n>X</span><span class=p>[:,</span> <span class=n>column</span><span class=p>],</span> <span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>scores</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=nb>abs</span><span class=p>(</span><span class=n>cur_score</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=n>pvalues</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>cur_p</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>scores</span><span class=p>),</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>pvalues</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>transformer</span> <span class=o>=</span> <span class=n>SelectKBest</span><span class=p>(</span><span class=n>score_func</span><span class=o>=</span><span class=n>mutivariate_pearsonr</span><span class=p>,</span> <span class=n>k</span><span class=o>=</span><span class=mi>3</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>Xt_pearson</span> <span class=o>=</span> <span class=n>transformer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>transformer</span><span class=o>.</span><span class=n>scores_</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;----------------&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>clf</span> <span class=o>=</span> <span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>14</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>scores_chi2</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>clf</span><span class=p>,</span> <span class=n>Xt_chi2</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>scores_pearson</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>clf</span><span class=p>,</span> <span class=n>Xt_pearson</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;卡方: </span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores_chi2</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;----------------&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;pearson:  </span><span class=si>{}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores_pearson</span><span class=p>)))</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>[8.60061182e+03 2.40142178e+03 8.21924671e+07 1.37214589e+06 6.47640900e+03]
----------------
[0.2340371  0.33515395 0.22332882 0.15052631 0.22968907]
----------------
卡方: 0.8291514400795839
----------------
pearson:  0.7721507467016449
</code></pre><h3 id=创建特征>创建特征</h3><p>特征之间相关性很强，或者特征冗余，会增加算法处理难度。</p><p>这里在加载 ad 数据集之前先创建了一个转换器，用于在加载时转换数据集中的值。</p><p>源码运行会产生报错，第一个原因是，用函数初始化转换器并没有把函数名传入，因此将 defaultdict 中每一个索引都进行了初始化。第二个原因是，PCA 转换器无法对 NaN 数据进行处理，于是我在处生成数据集之前将所有含有 NaN 的行删掉。</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># -*- coding: utf-8 -*-</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>collections</span> <span class=kn>import</span> <span class=n>defaultdict</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.decomposition</span> <span class=kn>import</span> <span class=n>PCA</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.tree</span> <span class=kn>import</span> <span class=n>DecisionTreeClassifier</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>cross_val_score</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>matplotlib</span> <span class=kn>import</span> <span class=n>pyplot</span> <span class=k>as</span> <span class=n>plt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 创建转换函数</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>convert_number</span><span class=p>(</span><span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>res</span> <span class=o>=</span> <span class=nb>float</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>res</span>
</span></span><span class=line><span class=cl>    <span class=k>except</span> <span class=ne>ValueError</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>nan</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s1>&#39;__main__&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># 创建数据加载的转换器</span>
</span></span><span class=line><span class=cl>    <span class=n>converters</span> <span class=o>=</span> <span class=n>defaultdict</span><span class=p>(</span><span class=n>convert_number</span><span class=p>,</span> <span class=p>{</span><span class=n>i</span><span class=p>:</span> <span class=n>convert_number</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1588</span><span class=p>)})</span>
</span></span><span class=line><span class=cl>    <span class=n>converters</span><span class=p>[</span><span class=mi>1558</span><span class=p>]</span> <span class=o>=</span> <span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=mi>1</span> <span class=k>if</span> <span class=n>x</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span> <span class=o>==</span> <span class=s2>&#34;ad.&#34;</span> <span class=k>else</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=c1># 使用转换器读取数据集</span>
</span></span><span class=line><span class=cl>    <span class=n>temp</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s2>&#34;ad.data&#34;</span><span class=p>,</span> <span class=n>header</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>converters</span><span class=o>=</span><span class=n>converters</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 删除所有含有nan的行,axis=0是数据索引(index)，axis=1是列标签(column)</span>
</span></span><span class=line><span class=cl>    <span class=n>ads</span> <span class=o>=</span> <span class=n>temp</span><span class=o>.</span><span class=n>dropna</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>how</span><span class=o>=</span><span class=s1>&#39;any&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>ads</span><span class=p>[</span><span class=mi>10</span><span class=p>:</span><span class=mi>15</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>       0      1       2     3     4     5  ...  1553  1554  1555  1556  1557  1558
11  90.0   52.0  0.5777   1.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0     1
12  90.0   60.0  0.6666   1.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0     1
13  90.0   60.0  0.6666   1.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0     1
14  33.0  230.0  6.9696   1.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0     1
15  60.0  468.0  7.8000   1.0   0.0   0.0  ...   0.0   1.0   1.0   0.0   0.0     1
[5 rows x 1559 columns]
</code></pre><hr><p>主成分分析(PCA)</p><p>目的是找到能用较少信息描述数据集的特征组合。主成分的方差跟整体方差没有多大差距。经过分析主成分，第一个特征的方差对数据集方差的贡献率为 85.4%，第二个为 14.5%，后面越来越少。</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=n>X</span> <span class=o>=</span> <span class=n>ads</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=mi>1558</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>values</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>ads</span><span class=p>[</span><span class=mi>1558</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=c1># 参数为主成分数量</span>
</span></span><span class=line><span class=cl>    <span class=n>pca</span> <span class=o>=</span> <span class=n>PCA</span><span class=p>(</span><span class=n>n_components</span><span class=o>=</span><span class=mi>5</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>Xd</span> <span class=o>=</span> <span class=n>pca</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 设置输出选项</span>
</span></span><span class=line><span class=cl>    <span class=c1># 第一个参数为输出精度位数，第二个参数是使用定点表示法打印浮点数</span>
</span></span><span class=line><span class=cl>    <span class=n>np</span><span class=o>.</span><span class=n>set_printoptions</span><span class=p>(</span><span class=n>precision</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>suppress</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>pca</span><span class=o>.</span><span class=n>explained_variance_ratio_</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>[0.854 0.145 0.001 0.    0.   ]
</code></pre><hr><p>使用随机森林验证模型正确率，并将 pca 转换结果绘制出来。</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=n>clf</span> <span class=o>=</span> <span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>14</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>scores_reduced</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>clf</span><span class=p>,</span> <span class=n>Xd</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores_reduced</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 获取数据集类别的所有取值</span>
</span></span><span class=line><span class=cl>    <span class=n>classes</span> <span class=o>=</span> <span class=nb>set</span><span class=p>(</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 指定在图形中用什么颜色表示这两个类别</span>
</span></span><span class=line><span class=cl>    <span class=n>colors</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;red&#39;</span><span class=p>,</span> <span class=s1>&#39;green&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=c1># 同时遍历这两个容器</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>cur_class</span><span class=p>,</span> <span class=n>color</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>classes</span><span class=p>,</span> <span class=n>colors</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 为属于当前类别的所有个体创建遮罩层</span>
</span></span><span class=line><span class=cl>        <span class=n>mask</span> <span class=o>=</span> <span class=p>(</span><span class=n>y</span> <span class=o>==</span> <span class=n>cur_class</span><span class=p>)</span><span class=o>.</span><span class=n>values</span>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>Xd</span><span class=p>[</span><span class=n>mask</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span> <span class=n>Xd</span><span class=p>[</span><span class=n>mask</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=n>marker</span><span class=o>=</span><span class=s1>&#39;o&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>color</span><span class=o>=</span><span class=n>color</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=nb>int</span><span class=p>(</span><span class=n>cur_class</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>0.936405592140775
</code></pre><p><figure><a class=lightgallery href=/img/in-post/data-mining/ch5/pca.png title=pca data-thumbnail=/img/in-post/data-mining/ch5/pca.png data-sub-html="<h2>输出结果</h2><p>pca</p>"><img class=lazyload src=/svg/loading.min.svg data-src=/img/in-post/data-mining/ch5/pca.png data-srcset="/img/in-post/data-mining/ch5/pca.png, /img/in-post/data-mining/ch5/pca.png 1.5x, /img/in-post/data-mining/ch5/pca.png 2x" data-sizes=auto alt=/img/in-post/data-mining/ch5/pca.png></a><figcaption class=image-caption>输出结果</figcaption></figure></p><h3 id=创建自己的转换器>创建自己的转换器</h3><p>转换器有两个关键函数</p><ul><li><code>fit()</code> 接收训练数据，设置内部参数</li><li><code>transform()</code> 转换过程。接收训练数据集或相同格式的新数据集</li></ul><p>接口要与 scikit-learn 接口一致，便于在流水线中使用。</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># -*- coding: utf-8 -*-</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.base</span> <span class=kn>import</span> <span class=n>TransformerMixin</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.utils</span> <span class=kn>import</span> <span class=n>as_float_array</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>numpy.testing</span> <span class=kn>import</span> <span class=n>assert_array_equal</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>MeanDiscrete</span><span class=p>(</span><span class=n>TransformerMixin</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>fit</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 尝试对X进行转换，数据转换成float类型</span>
</span></span><span class=line><span class=cl>        <span class=n>X</span> <span class=o>=</span> <span class=n>as_float_array</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># 计算数据集的均值</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>mean</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># 返回它本身，进行链式调用transformer.fit(X).transform(X)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>transform</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>X</span> <span class=o>=</span> <span class=n>as_float_array</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># 检查输入是否合法</span>
</span></span><span class=line><span class=cl>        <span class=k>assert</span> <span class=n>X</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>==</span> <span class=bp>self</span><span class=o>.</span><span class=n>mean</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=c1># 返回X中大于均值的数据</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>X</span> <span class=o>&gt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>mean</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>test_meandiscrete</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>X_test</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>3</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span> <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>14</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>17</span><span class=p>],</span> <span class=p>[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>20</span><span class=p>],</span> <span class=p>[</span><span class=mi>21</span><span class=p>,</span> <span class=mi>23</span><span class=p>],</span> <span class=p>[</span><span class=mi>24</span><span class=p>,</span> <span class=mi>26</span><span class=p>],</span> <span class=p>[</span><span class=mi>27</span><span class=p>,</span> <span class=mi>29</span><span class=p>]])</span>
</span></span><span class=line><span class=cl>    <span class=n>mean_discrete</span> <span class=o>=</span> <span class=n>MeanDiscrete</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>mean_discrete</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 与正确的计算结果进行比较，检查内部参数是否正确设置</span>
</span></span><span class=line><span class=cl>    <span class=n>assert_array_equal</span><span class=p>(</span><span class=n>mean_discrete</span><span class=o>.</span><span class=n>mean</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mf>13.5</span><span class=p>,</span> <span class=mf>15.5</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>    <span class=c1># 转换后的X</span>
</span></span><span class=line><span class=cl>    <span class=n>X_transfromed</span> <span class=o>=</span> <span class=n>mean_discrete</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 验证数据</span>
</span></span><span class=line><span class=cl>    <span class=n>X_expected</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>]])</span>
</span></span><span class=line><span class=cl>    <span class=n>assert_array_equal</span><span class=p>(</span><span class=n>X_transfromed</span><span class=p>,</span> <span class=n>X_expected</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s1>&#39;__main__&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>test_meandiscrete</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code># 没有输出，说明测试通过
</code></pre><h2 id=第六章>第六章</h2><p>本章介绍如何从文本数据中提取特征。通过强大却简单的朴素贝叶斯算法消除社会媒体用语的歧义。</p><p>朴素贝叶斯算法在计算用于分类的概率时，为了简化计算，假定各特征间是相互独立的，因此名字中含有<em>朴素</em>二字。</p><h3 id=消歧>消歧</h3><p>由于无法申请到 Twitter app 暂时搁置。。。%>_&lt;%</p><h3 id=文本转换器>文本转换器</h3><p>词袋：一种最简单却非常有效的模型就是只统计数据集中每个单词的出现次数。模型主要分为以下三种</p><ul><li>使用词语实际出现的次数作为词频。缺点是当文章长度明显差异时，词频差距会非常大。</li><li>使用归一化后的词频，每篇文章中所有词语的词频之和为 1</li><li>直接使用二值特征来表示，单词在文档中出现值为 1，不出现值为 0</li></ul><p>还有一种更通用的规范化方法叫做<em>词频-逆文档频率法</em>，该加权方法用词频来代替词的出现次数，然后再用词频除以包含该词的文档的数量。</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># -*- coding: utf-8 -*-</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>collections</span> <span class=kn>import</span> <span class=n>Counter</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s1>&#39;__main__&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>s</span> <span class=o>=</span> <span class=s2>&#34;&#34;&#34;Three Rings for the Elven-kings under the sky,
</span></span></span><span class=line><span class=cl><span class=s2>Seven for the Dwarf-lords in halls of stone,
</span></span></span><span class=line><span class=cl><span class=s2>Nine for Mortal Men, doomed to die,
</span></span></span><span class=line><span class=cl><span class=s2>One for the Dark Lord on his dark throne
</span></span></span><span class=line><span class=cl><span class=s2>In the Land of Mordor where the Shadows lie.
</span></span></span><span class=line><span class=cl><span class=s2>One Ring to rule them all, One Ring to find them,
</span></span></span><span class=line><span class=cl><span class=s2>One Ring to bring them all and in the darkness bind them.
</span></span></span><span class=line><span class=cl><span class=s2>In the Land of Mordor where the Shadows lie&#34;&#34;&#34;</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>words</span> <span class=o>=</span> <span class=n>s</span><span class=o>.</span><span class=n>split</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>c</span> <span class=o>=</span> <span class=n>Counter</span><span class=p>(</span><span class=n>words</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 输出出现次数最多的前5个词</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>c</span><span class=o>.</span><span class=n>most_common</span><span class=p>(</span><span class=mi>5</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>[('the', 9), ('for', 4), ('in', 4), ('to', 4), ('one', 4)]
</code></pre><hr><p>N 元语法是指由几个连续的词组成的子序列。</p><h3 id=朴素贝叶斯>朴素贝叶斯</h3><p>我们用 C 表示某种类别，用 D 表示数据集中一篇文档，来计算贝叶斯公式所要用到的各种统计量，对于不好计算，出朴素假设，简化计算。朴素贝叶斯分类算法使用贝叶斯定理计算个体从属于某一类别的概率。</p><p><code>P(C)</code> 为某一类别的概率，可以从训练集中计算得到（方法跟上文检测垃圾邮件例子所用到的一致）。统计训练集所有文档从属于给定类别的百分比。</p><p><code>P(D)</code> 为某一文档的概率，它牵扯到各种特征，计算起来很困难，但是在计算文档属于哪个类别时，对于所有类别来说，P(D)相同，因此根本就不用计算它。稍后我们来看下怎么处理。</p><p><code>P(D|C)</code> 为文档 D 属于 C 类的概率。由于 D 包含多个特征，计算起来可能很困难，这时朴素贝叶斯算法就派上用场了。我们朴素地假定各个特征之间是相互独立的，分别计算每个特征（D1、D2、D3 等）在给定类别出现的概率，再求它们的积。</p><p><code>P(D|C) = P(D1|C) x P(D2|C) ... x P(Dn|C)</code></p><p>举例说明下计算过程，假如数据集中有以下一条用二值特征表示的数据：[1, 0, 0, 1]</p><p>训练集中有 75% 的数据属于类别 0， 25% 属于类别 1，且每个特征属于每个类别的似然度如下。</p><ul><li>类别 0：[0.3, 0.4, 0.4, 0.7]</li><li>类别 1：[0.7, 0.3, 0.4, 0.9]</li></ul><p>拿类别 0 中特征 1 的似然度举例子，上面这两行数据可以这样理解：类别 0 中有 30%的数据，特征 1 的值为 1。</p><p>我们来计算一下这条数据属于类别 0 的概率。类别为 0 时，P(C=0) = 0.75。</p><p>朴素贝叶斯算法用不到 P(D)，因此我们不用计算它。</p><p>P(D|C=0) = P(D1|C=0) x P(D2|C=0) x P(D3|C=0) x P(D4|C=0)
= 0.3 x 0.6 x 0.6 x 0.7
= 0.0756</p><p>我们就可以计算该条数据从属于每个类别的概率。我们没有计算 P(D)，因此，计算结果不是实际的概率。由于两次都不计算 P(D)，结果具有可比较性，能够区分出大小就足够了。来看下计算结果。</p><p>P(C=0|D) = P(C=0) P(D|C=0)
= 0.75 * 0.0756
= 0.0567</p><p>P(D|C=1) = P(D1|C=1) x P(D2|C=1) x P(D3|C=1) x P(D4|C=1)
= 0.7 x 0.7 x 0.6 x 0.9
= 0.2646</p><p>P(C=1|D) = P(C=1)P(D|C=1)
= 0.25 * 0.2646
= 0.06615</p><p>因此这条数据属于类别 1 的概率大于属于类别 2 的概率</p><h3 id=应用>应用</h3><p>创建流水线，接收一条消息，仅根据消息内容，确定它与编程语言 Python 是否相关。</p><ul><li>用 NLTK 的 word_tokenize 函数，将原始文档转换为由单词及其是否出现组成的字典。</li><li>用 scikit-learn 中的 DictVectorizer 转换器将字典转换为向量矩阵，这样朴素贝叶斯分类器就能使用第一步中抽取的特征。</li><li>正如前几章做过的那样，训练朴素贝叶斯分类器。</li><li>还需要新建一个笔记本文件 ch6_classify_twitter（本章最后一个），用于分类。</li></ul><p>F1 值来评估算法</p><p>F1 值是以每个类别为基础进行定义的，包括两大概念：准确率（precision）和召回率（recall）。准确率是指预测结果属于某一类的个体，实际属于该类的比例。召回率是指被正确预测为某个类别的个体数量与数据集中该类别个体总量的比例</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># -*- coding: utf-8 -*-</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>json</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.base</span> <span class=kn>import</span> <span class=n>TransformerMixin</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk</span> <span class=kn>import</span> <span class=n>word_tokenize</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.feature_extraction</span> <span class=kn>import</span> <span class=n>DictVectorizer</span>  <span class=c1># 接受元素为字典的列表，将其转换为矩阵</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>cross_val_score</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.naive_bayes</span> <span class=kn>import</span> <span class=n>BernoulliNB</span>  <span class=c1># 用于二值特征分类的 BernoulliNB 分类器，</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.pipeline</span> <span class=kn>import</span> <span class=n>Pipeline</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 创建转换器类</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>NLTKBOW</span><span class=p>(</span><span class=n>TransformerMixin</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>fit</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>transform</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>[{</span><span class=n>word</span><span class=p>:</span> <span class=kc>True</span> <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>word_tokenize</span><span class=p>(</span><span class=n>document</span><span class=p>)}</span> <span class=k>for</span> <span class=n>document</span> <span class=ow>in</span> <span class=n>X</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s1>&#39;__main__&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>tweets</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>input_filename</span> <span class=o>=</span> <span class=s2>&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>classes_filename</span> <span class=o>=</span> <span class=s2>&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>input_filename</span><span class=p>)</span> <span class=k>as</span> <span class=n>inf</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>line</span> <span class=ow>in</span> <span class=n>inf</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>line</span><span class=o>.</span><span class=n>strip</span><span class=p>())</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>continue</span>
</span></span><span class=line><span class=cl>            <span class=n>tweets</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>json</span><span class=o>.</span><span class=n>loads</span><span class=p>(</span><span class=n>line</span><span class=p>)[</span><span class=s1>&#39;text&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>classes_filename</span><span class=p>,</span> <span class=s1>&#39;r&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>inf</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>labels</span> <span class=o>=</span> <span class=n>json</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>inf</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 组装流水线</span>
</span></span><span class=line><span class=cl>    <span class=n>pipline</span> <span class=o>=</span> <span class=n>Pipeline</span><span class=p>([(</span><span class=s1>&#39;bag-of-words&#39;</span><span class=p>,</span> <span class=n>NLTKBOW</span><span class=p>()),</span> <span class=p>(</span><span class=s1>&#39;vectorizer&#39;</span><span class=p>,</span> <span class=n>DictVectorizer</span><span class=p>()),</span> <span class=p>(</span><span class=s1>&#39;naive-bayes&#39;</span><span class=p>,</span> <span class=n>BernoulliNB</span><span class=p>())])</span>
</span></span><span class=line><span class=cl>    <span class=c1># 用F1值来评估</span>
</span></span><span class=line><span class=cl>    <span class=n>scores</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>pipline</span><span class=p>,</span> <span class=n>tweets</span><span class=p>,</span> <span class=n>labels</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;f1&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Score: </span><span class=si>{:.3f}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=o>=</span> <span class=n>pipline</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>tweets</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>nb</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>named_steps</span><span class=p>[</span><span class=s1>&#39;naive-bayes&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>feature_probabilities</span> <span class=o>=</span> <span class=n>nb</span><span class=o>.</span><span class=n>feature_log_prob_</span>
</span></span><span class=line><span class=cl>    <span class=n>top_features</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argsort</span><span class=p>(</span><span class=o>-</span><span class=n>feature_probabilities</span><span class=p>[</span><span class=mi>1</span><span class=p>])[:</span><span class=mi>50</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>dv</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>named_steps</span><span class=p>[</span><span class=s1>&#39;vectorizer&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>feature_index</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>top_features</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=n>i</span><span class=p>,</span> <span class=n>dv</span><span class=o>.</span><span class=n>feature_names_</span><span class=p>[</span><span class=n>feature_index</span><span class=p>],</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=n>feature_probabilities</span><span class=p>[</span><span class=mi>1</span><span class=p>][</span><span class=n>feature_index</span><span class=p>]))</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>暂时没有数据集
</code></pre><h2 id=第七章>第七章</h2><p>本章介绍的算法引入聚类分析概念&ndash;根据相似度，把大数据集划分为几个子集。</p><h3 id=加载数据集-1>加载数据集</h3><p>由于申请不到 Twitter 开发者账号，我想办法爬了一些 b 站用户关注数据，做成了本次试验相仿的形式</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># -*- coding: utf-8 -*-</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>json</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>networkx</span> <span class=k>as</span> <span class=nn>nx</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>matplotlib</span> <span class=kn>import</span> <span class=n>pyplot</span> <span class=k>as</span> <span class=n>plt</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>scipy.optimize</span> <span class=kn>import</span> <span class=n>minimize</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.metrics</span> <span class=kn>import</span> <span class=n>silhouette_score</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s1>&#39;__main__&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=s1>&#39;bili.txt&#39;</span><span class=p>,</span> <span class=n>mode</span><span class=o>=</span><span class=s1>&#39;r&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>fin</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>temp</span> <span class=o>=</span> <span class=n>json</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>fin</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>users</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>temp</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>users</span><span class=o>.</span><span class=n>columns</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;Id&#39;</span><span class=p>,</span> <span class=s1>&#39;Friends&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>users</span><span class=p>[:</span><span class=mi>5</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>        Id                                            Friends
0  214582845  [4370617, 259345180, 186334806, 546195, 477132...
1    4370617                    [74507, 883968, 122879, 585267]
2  259345180                                                 []
3  186334806                                                 []
4     546195                                                 []
</code></pre><hr><p>将每个记录的用户左右 main_users，把他们关注的人作为边，生成有向图</p><p>由于对 matplotlib 库和 networkx 库了解太少，在作图时遇到了许多困难（根基不牢，地动山摇。(>_&lt;)）</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=n>G</span> <span class=o>=</span> <span class=n>nx</span><span class=o>.</span><span class=n>DiGraph</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>main_users</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=n>users</span><span class=p>[</span><span class=s1>&#39;Id&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>values</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>u</span> <span class=ow>in</span> <span class=n>main_users</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>G</span><span class=o>.</span><span class=n>add_node</span><span class=p>(</span><span class=n>u</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=n>u</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>user</span> <span class=ow>in</span> <span class=n>users</span><span class=o>.</span><span class=n>values</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>friends</span> <span class=o>=</span> <span class=n>user</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>friend</span> <span class=ow>in</span> <span class=n>friends</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>friend</span> <span class=ow>in</span> <span class=n>main_users</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>G</span><span class=o>.</span><span class=n>add_edge</span><span class=p>(</span><span class=n>user</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=nb>int</span><span class=p>(</span><span class=n>friend</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;graph finished&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>100</span><span class=p>,</span> <span class=mi>100</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>nx</span><span class=o>.</span><span class=n>draw</span><span class=p>(</span><span class=n>G</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span> <span class=n>edge_color</span><span class=o>=</span><span class=s1>&#39;b&#39;</span><span class=p>,</span> <span class=n>with_labels</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>font_size</span><span class=o>=</span><span class=mi>16</span><span class=p>,</span> <span class=n>node_size</span><span class=o>=</span><span class=mi>30</span><span class=p>,</span> <span class=n>node_color</span><span class=o>=</span><span class=s1>&#39;r&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>savefig</span><span class=p>(</span><span class=s1>&#39;fix1.png&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/img/in-post/data-mining/ch7/fix1.png data-srcset="/img/in-post/data-mining/ch7/fix1.png, /img/in-post/data-mining/ch7/fix1.png 1.5x, /img/in-post/data-mining/ch7/fix1.png 2x" data-sizes=auto alt=/img/in-post/data-mining/ch7/fix1.png title=fix1></p><hr><p>创建用户相似度图</p><p>由于每个用户关注的人数可能相差很大，因此使用杰卡德相似系数（两个用户关注的集合的交集除以并集），该系数在 0 到 1 之间，代表两者重合的比例。</p><p>规范化是数据挖掘的一个重要方法，要坚持使用（除非有充足的理由不这样做）</p><p>访问<a href=http://networkx.lanl.gov/reference/drawing/html target=_blank rel="noopener noreffer">http://networkx.lanl.gov/reference/drawing/html</a>了解 networkx 的布局方法</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=n>friends</span> <span class=o>=</span> <span class=p>{</span><span class=n>user</span><span class=p>:</span> <span class=nb>set</span><span class=p>(</span><span class=n>friends</span><span class=p>)</span> <span class=k>for</span> <span class=n>user</span><span class=p>,</span> <span class=n>friends</span> <span class=ow>in</span> <span class=n>users</span><span class=o>.</span><span class=n>values</span><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>compute_similarity</span><span class=p>(</span><span class=n>friends1</span><span class=p>,</span> <span class=n>friends2</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=nb>len</span><span class=p>(</span><span class=n>friends1</span> <span class=o>&amp;</span> <span class=n>friends2</span><span class=p>)</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>friends1</span> <span class=o>|</span> <span class=n>friends2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>create_graph</span><span class=p>(</span><span class=n>followers</span><span class=p>,</span> <span class=n>threshold</span><span class=o>=</span><span class=mf>0.0</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>G</span> <span class=o>=</span> <span class=n>nx</span><span class=o>.</span><span class=n>Graph</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>user1</span> <span class=ow>in</span> <span class=n>friends</span><span class=o>.</span><span class=n>keys</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>friends</span><span class=p>[</span><span class=n>user1</span><span class=p>])</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>continue</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>user2</span> <span class=ow>in</span> <span class=n>friends</span><span class=o>.</span><span class=n>keys</span><span class=p>():</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>friends</span><span class=p>[</span><span class=n>user2</span><span class=p>])</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=k>continue</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=n>user1</span> <span class=o>==</span> <span class=n>user2</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=k>continue</span>
</span></span><span class=line><span class=cl>                <span class=n>weight</span> <span class=o>=</span> <span class=n>compute_similarity</span><span class=p>(</span><span class=n>friends</span><span class=p>[</span><span class=n>user1</span><span class=p>],</span> <span class=n>friends</span><span class=p>[</span><span class=n>user2</span><span class=p>])</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=n>weight</span> <span class=o>&gt;=</span> <span class=n>threshold</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=n>G</span><span class=o>.</span><span class=n>add_node</span><span class=p>(</span><span class=n>user1</span><span class=p>,</span> <span class=n>lable</span><span class=o>=</span><span class=n>user1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>G</span><span class=o>.</span><span class=n>add_node</span><span class=p>(</span><span class=n>user2</span><span class=p>,</span> <span class=n>lable</span><span class=o>=</span><span class=n>user2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>G</span><span class=o>.</span><span class=n>add_edge</span><span class=p>(</span><span class=n>user1</span><span class=p>,</span> <span class=n>user2</span><span class=p>,</span> <span class=n>weight</span><span class=o>=</span><span class=n>weight</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>G</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>G</span> <span class=o>=</span> <span class=n>create_graph</span><span class=p>(</span><span class=n>friends</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>100</span><span class=p>,</span> <span class=mi>100</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>pos</span> <span class=o>=</span> <span class=n>nx</span><span class=o>.</span><span class=n>spring_layout</span><span class=p>(</span><span class=n>G</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>nx</span><span class=o>.</span><span class=n>draw_networkx_nodes</span><span class=p>(</span><span class=n>G</span><span class=p>,</span> <span class=n>pos</span><span class=p>,</span> <span class=n>node_size</span><span class=o>=</span><span class=mi>30</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>edgewidth</span> <span class=o>=</span> <span class=p>[</span><span class=n>d</span><span class=p>[</span><span class=s1>&#39;weight&#39;</span><span class=p>]</span> <span class=k>for</span> <span class=p>(</span><span class=n>u</span><span class=p>,</span> <span class=n>v</span><span class=p>,</span> <span class=n>d</span><span class=p>)</span> <span class=ow>in</span> <span class=n>G</span><span class=o>.</span><span class=n>edges</span><span class=p>(</span><span class=n>data</span><span class=o>=</span><span class=kc>True</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>    <span class=n>nx</span><span class=o>.</span><span class=n>draw_networkx_edges</span><span class=p>(</span><span class=n>G</span><span class=p>,</span> <span class=n>pos</span><span class=p>,</span> <span class=n>width</span><span class=o>=</span><span class=n>edgewidth</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>savefig</span><span class=p>(</span><span class=s1>&#39;fix2.png&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/img/in-post/data-mining/ch7/fix2.png data-srcset="/img/in-post/data-mining/ch7/fix2.png, /img/in-post/data-mining/ch7/fix2.png 1.5x, /img/in-post/data-mining/ch7/fix2.png 2x" data-sizes=auto alt=/img/in-post/data-mining/ch7/fix2.png title=fix2></p><h3 id=寻找子图>寻找子图</h3><p>networkx 的 <code>connected_component_subgraphs()</code> 函数在 2.1 版本中被移除了（代码过时的比较多，并且使用 Twitter 作为演示数据集让我这两章做的很头疼），我查看官方文档后发现可以使用 <code>connected_components()</code> 替代，但是此函数返回的是一个生成器，一次生成一组连通顶点，可以配合 G.subgraph(nodes) 使用获得连通分支</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># 生成新图，指定最低阈值为0.1</span>
</span></span><span class=line><span class=cl>    <span class=n>G</span> <span class=o>=</span> <span class=n>create_graph</span><span class=p>(</span><span class=n>friends</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>sub_graphs</span> <span class=o>=</span> <span class=n>nx</span><span class=o>.</span><span class=n>connected_components</span><span class=p>(</span><span class=n>G</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>sub_graphs</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>sub_graphs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>n_nodes</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>sub_graphs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Subgraph</span><span class=si>{}</span><span class=s2> has </span><span class=si>{}</span><span class=s2> nodes&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>i</span><span class=p>,</span> <span class=n>n_nodes</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;---------------------&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>G</span> <span class=o>=</span> <span class=n>create_graph</span><span class=p>(</span><span class=n>friends</span><span class=p>,</span> <span class=mf>0.15</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>sub_graphs</span> <span class=o>=</span> <span class=n>nx</span><span class=o>.</span><span class=n>connected_components</span><span class=p>(</span><span class=n>G</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>sub_graphs</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>sub_graphs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>n_nodes</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>sub_graphs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Subgraph</span><span class=si>{}</span><span class=s2> has </span><span class=si>{}</span><span class=s2> nodes&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>i</span><span class=p>,</span> <span class=n>n_nodes</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>sub_graphs</span> <span class=o>=</span> <span class=p>[</span><span class=n>c</span> <span class=k>for</span> <span class=n>c</span> <span class=ow>in</span> <span class=nb>sorted</span><span class=p>(</span><span class=n>nx</span><span class=o>.</span><span class=n>connected_components</span><span class=p>(</span><span class=n>G</span><span class=p>),</span> <span class=n>key</span><span class=o>=</span><span class=nb>len</span><span class=p>,</span> <span class=n>reverse</span><span class=o>=</span><span class=kc>True</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>    <span class=n>n_subgraphs</span> <span class=o>=</span> <span class=n>nx</span><span class=o>.</span><span class=n>number_connected_components</span><span class=p>(</span><span class=n>G</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>fig</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>20</span><span class=p>,</span> <span class=p>(</span><span class=n>n_subgraphs</span><span class=o>*</span><span class=mi>3</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>sub_graph</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>sub_graphs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># sub_graph是一个连通分支顶点的集合</span>
</span></span><span class=line><span class=cl>        <span class=n>ax</span> <span class=o>=</span> <span class=n>fig</span><span class=o>.</span><span class=n>add_subplot</span><span class=p>(</span><span class=nb>int</span><span class=p>(</span><span class=n>n_subgraphs</span> <span class=o>/</span> <span class=mi>3</span><span class=p>)</span> <span class=o>+</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># 将坐标轴标签关掉</span>
</span></span><span class=line><span class=cl>        <span class=n>ax</span><span class=o>.</span><span class=n>get_xaxis</span><span class=p>()</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>ax</span><span class=o>.</span><span class=n>get_yaxis</span><span class=p>()</span><span class=o>.</span><span class=n>set_visible</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>pos</span> <span class=o>=</span> <span class=n>nx</span><span class=o>.</span><span class=n>spring_layout</span><span class=p>(</span><span class=n>G</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>nx</span><span class=o>.</span><span class=n>draw</span><span class=p>(</span><span class=n>G</span><span class=o>=</span><span class=n>G</span><span class=o>.</span><span class=n>subgraph</span><span class=p>(</span><span class=n>sub_graph</span><span class=p>),</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span> <span class=n>edge_color</span><span class=o>=</span><span class=s1>&#39;b&#39;</span><span class=p>,</span> <span class=n>with_labels</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>font_size</span><span class=o>=</span><span class=mi>16</span><span class=p>,</span> <span class=n>node_size</span><span class=o>=</span><span class=mi>30</span><span class=p>,</span> <span class=n>node_color</span><span class=o>=</span><span class=s1>&#39;r&#39;</span><span class=p>,</span> <span class=n>ax</span><span class=o>=</span><span class=n>ax</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/img/in-post/data-mining/ch7/fix3.png data-srcset="/img/in-post/data-mining/ch7/fix3.png, /img/in-post/data-mining/ch7/fix3.png 1.5x, /img/in-post/data-mining/ch7/fix3.png 2x" data-sizes=auto alt=/img/in-post/data-mining/ch7/fix3.png title=fix3></p><hr><p>轮廓系数定义： <code>s = (b - a) / max(a, b)</code></p><p>其中 a 为簇内距离，表示与簇内其它个体之间的平均距离。b 为簇间距离，也就是最近簇内各个个体之间的平均距离</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>compute_silhouette</span><span class=p>(</span><span class=n>threshold</span><span class=p>,</span> <span class=n>friends</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>G</span> <span class=o>=</span> <span class=n>create_graph</span><span class=p>(</span><span class=n>friends</span><span class=p>,</span> <span class=n>threshold</span><span class=o>=</span><span class=n>threshold</span><span class=p>)</span>\
</span></span><span class=line><span class=cl>        <span class=c1># 图是否至少有两个顶点</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>G</span><span class=o>.</span><span class=n>nodes</span><span class=p>())</span> <span class=o>&lt;</span> <span class=mi>2</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># 返回-99表示问题无效</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=o>-</span><span class=mi>99</span>
</span></span><span class=line><span class=cl>        <span class=c1># 抽取连通分支</span>
</span></span><span class=line><span class=cl>        <span class=n>sub_graphs</span> <span class=o>=</span> <span class=n>nx</span><span class=o>.</span><span class=n>connected_components</span><span class=p>(</span><span class=n>G</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># 至少有两个连通分支</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=ow>not</span> <span class=p>(</span><span class=mi>2</span> <span class=o>&lt;=</span> <span class=n>nx</span><span class=o>.</span><span class=n>number_connected_components</span><span class=p>(</span><span class=n>G</span><span class=p>)</span> <span class=o>&lt;</span> <span class=nb>len</span><span class=p>(</span><span class=n>G</span><span class=o>.</span><span class=n>nodes</span><span class=p>())</span> <span class=o>-</span> <span class=mi>1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=o>-</span><span class=mi>99</span>
</span></span><span class=line><span class=cl>        <span class=n>label_dict</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>sub_graph</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>sub_graphs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>node</span> <span class=ow>in</span> <span class=n>sub_graph</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=c1># 给不同连通分支的顶点分配不同的标签</span>
</span></span><span class=line><span class=cl>                <span class=n>label_dict</span><span class=p>[</span><span class=n>node</span><span class=p>]</span> <span class=o>=</span> <span class=n>i</span>
</span></span><span class=line><span class=cl>        <span class=n>labels</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=n>label_dict</span><span class=p>[</span><span class=n>node</span><span class=p>]</span> <span class=k>for</span> <span class=n>node</span> <span class=ow>in</span> <span class=n>G</span><span class=o>.</span><span class=n>nodes</span><span class=p>()])</span>
</span></span><span class=line><span class=cl>        <span class=n>X</span> <span class=o>=</span> <span class=n>nx</span><span class=o>.</span><span class=n>to_scipy_sparse_matrix</span><span class=p>(</span><span class=n>G</span><span class=p>)</span><span class=o>.</span><span class=n>todense</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=c1># 这里要将相似度转换为距离，所以用最大相似度减去现有相似度，把相似度转化为距离</span>
</span></span><span class=line><span class=cl>        <span class=n>X</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>X</span>
</span></span><span class=line><span class=cl>        <span class=c1># 这里将距离矩阵的对角线处理为0，因为自己到自己的距离为0</span>
</span></span><span class=line><span class=cl>        <span class=n>np</span><span class=o>.</span><span class=n>fill_diagonal</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>silhouette_score</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>labels</span><span class=p>,</span> <span class=n>metric</span><span class=o>=</span><span class=s1>&#39;precomputed&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>inverted_silhouette</span><span class=p>(</span><span class=n>threshold</span><span class=p>,</span> <span class=n>friends</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 对轮廓系数取反，将打分函数转化成损失函数</span>
</span></span><span class=line><span class=cl>        <span class=n>res</span> <span class=o>=</span> <span class=n>compute_silhouette</span><span class=p>(</span><span class=n>threshold</span><span class=p>,</span> <span class=n>friends</span><span class=o>=</span><span class=n>friends</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=o>-</span> <span class=n>res</span>
</span></span><span class=line><span class=cl>    <span class=c1># minimize函数是一个损失函数，值越小越好</span>
</span></span><span class=line><span class=cl>    <span class=c1># 参数：inverted_silhouette要寻找的函数；0.1开始时猜测的阈值；options={&#39;maxiter&#39;: 10} 只进行10轮迭代，增加迭代次数，效果可能更好，但运行时间会增加，method=&#39;nelder-mead&#39;使用&#34;下山单纯形法&#34;优化方法</span>
</span></span><span class=line><span class=cl>    <span class=n>result</span> <span class=o>=</span> <span class=n>minimize</span><span class=p>(</span><span class=n>inverted_silhouette</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=n>args</span><span class=o>=</span><span class=p>(</span><span class=n>friends</span><span class=p>,),</span> <span class=n>options</span><span class=o>=</span><span class=p>{</span><span class=s1>&#39;maxiter&#39;</span><span class=p>:</span> <span class=mi>10</span><span class=p>})</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=o>.</span><span class=n>x</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>[0.10005086]
</code></pre><hr><p>本章探讨了社交网络和图以及如何对其进行聚类分析。目标是推荐用户，使用聚类分析方法能够找到不同的用户簇，主要步骤有根据相似度创建加权图，从图中寻找连通分支。创建图时用到了 NetworkX 库。</p><p>还比较了几对意义相反的概念。对于两者之间的相似度这个概念，值越大，表明两者之间更相像。相反，对于距离而言，值越小，两者更相像。另外一对是损失函数和打分函数。对于损失函数，值越小，效果越好（也就是损失越少）。而对于打分函数，值越大，效果越好。</p><h2 id=第八章>第八章</h2><p>本章使用神经网络分析自己生成的验证码图像</p><h3 id=人工神经网络>人工神经网络</h3><p><em>神经网络</em>算法最初是根据人类大脑的工作机制设计的。神经网络由一系列相互连接的神经元组成。每个神经元都是一个简单的函数，接收一定输入，给出相应输出。</p><p>神经元可以使用任何标准函数来处理数据，比如线性函数，这些函数统称为激活函数（activation function）。一般来说，神经网络学习算法要能正常工作，激活函数应当是可导（derivable）和光滑的。常用的激活函数有<em>逻辑斯谛</em>函数，函数表达式如下（x 为神经元的输入，k、L 通常为 1，这时函数达到最大值）。</p><p>$$
f(x) = \frac{L}{1+e^{-k(x-x_{0})}}
$$</p><p>每个神经元接收几个输入，根据这几个输入，计算输出。这样的一个个神经元连接在一起组成了神经网络，对数据挖掘应用来说，它非常强大。这些神经元紧密连接，密切配合，能够通过学习得到一个模型，使得神经网络成为机器学习领域最强大的概念之一。</p><p>数据挖掘应用的神经网络，神经元按照层级进行排列，至少有三层</p><ol><li>第一层：输入层。用来接收数据集的输入。第一层中的每个神经元对输入进行计算，把得到的结果传给第二层的神经元。这种叫作<em>前向神经网络</em></li><li>隐含层：数据表现方式令人难以理解，一层或多层</li><li>最后一层：输出层。输出结果表示的是神经网络分类器给出的分类结果</li></ol><p>神经元激活函数通常使用逻辑斯谛函数，每层神经元之间为全连接，创建和训练神经网络还需要用到其他几个参数。</p><p>创建过程，指定神经网络的规模需要用到两个参数：神经网络共有多少层，隐含层每层有多少个神经元（输入层和输出层神经元数量通常由数据集来定）。</p><h3 id=创建数据集>创建数据集</h3><p>使用长度为 4 个字母的英文单词作为验证码</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># -*- coding: utf-8 -*-</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>PIL</span> <span class=kn>import</span> <span class=n>Image</span><span class=p>,</span> <span class=n>ImageDraw</span><span class=p>,</span> <span class=n>ImageFont</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>skimage</span> <span class=kn>import</span> <span class=n>transform</span> <span class=k>as</span> <span class=n>tf</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>skimage.transform</span> <span class=kn>import</span> <span class=n>resize</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>matplotlib</span> <span class=kn>import</span> <span class=n>pyplot</span> <span class=k>as</span> <span class=n>plt</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>skimage.measure</span> <span class=kn>import</span> <span class=n>label</span><span class=p>,</span> <span class=n>regionprops</span>  <span class=c1># 用于图像分割</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.utils</span> <span class=kn>import</span> <span class=n>check_random_state</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.preprocessing</span> <span class=kn>import</span> <span class=n>OneHotEncoder</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>train_test_split</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pybrain.datasets.supervised</span> <span class=kn>import</span> <span class=n>SupervisedDataSet</span>  <span class=c1># 神经网络数据集</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pybrain.tools.shortcuts</span> <span class=kn>import</span> <span class=n>buildNetwork</span>  <span class=c1># 构建神经网络</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pybrain.supervised.trainers.backprop</span> <span class=kn>import</span> <span class=n>BackpropTrainer</span>  <span class=c1># 反向传播算法</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.metrics</span> <span class=kn>import</span> <span class=n>f1_score</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.corpus</span> <span class=kn>import</span> <span class=n>words</span>  <span class=c1># 导入语料库 用于生成单词</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.metrics</span> <span class=kn>import</span> <span class=n>confusion_matrix</span>  <span class=c1># 混淆矩阵</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.metrics</span> <span class=kn>import</span> <span class=n>edit_distance</span>  <span class=c1># 编辑距离</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>operator</span> <span class=kn>import</span> <span class=n>itemgetter</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 用于生成验证码，接收一个单词和错切值，返回用numpy数组格式表示的图像</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>create_captcha</span><span class=p>(</span><span class=n>text</span><span class=p>,</span> <span class=n>shear</span><span class=o>=</span><span class=mf>0.0</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=mi>100</span><span class=p>,</span> <span class=mi>26</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>    <span class=n>im</span> <span class=o>=</span> <span class=n>Image</span><span class=o>.</span><span class=n>new</span><span class=p>(</span><span class=s2>&#34;L&#34;</span><span class=p>,</span> <span class=n>size</span><span class=p>,</span> <span class=s2>&#34;black&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>draw</span> <span class=o>=</span> <span class=n>ImageDraw</span><span class=o>.</span><span class=n>Draw</span><span class=p>(</span><span class=n>im</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 验证码文字所用字体，该开源字体可在github下载</span>
</span></span><span class=line><span class=cl>    <span class=n>font</span> <span class=o>=</span> <span class=n>ImageFont</span><span class=o>.</span><span class=n>truetype</span><span class=p>(</span><span class=s2>&#34;FiraCode-Medium.otf&#34;</span><span class=p>,</span> <span class=mi>22</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>draw</span><span class=o>.</span><span class=n>text</span><span class=p>((</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>),</span> <span class=n>text</span><span class=p>,</span> <span class=n>fill</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>font</span><span class=o>=</span><span class=n>font</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 将PIL图像转换为numpy数组，以便用scikit-image库为图像添加错切变化效果</span>
</span></span><span class=line><span class=cl>    <span class=n>image</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>im</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 应用错切变化效果</span>
</span></span><span class=line><span class=cl>    <span class=n>affine_tf</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>AffineTransform</span><span class=p>(</span><span class=n>shear</span><span class=o>=</span><span class=n>shear</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>image</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>warp</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=n>affine_tf</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 对图像进行归一化处理，确保特征值落在0到1之间</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>image</span> <span class=o>/</span> <span class=n>image</span><span class=o>.</span><span class=n>max</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s1>&#39;__main__&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>image</span> <span class=o>=</span> <span class=n>create_captcha</span><span class=p>(</span><span class=s1>&#39;GENE&#39;</span><span class=p>,</span> <span class=n>shear</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=s1>&#39;Greys&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/img/in-post/data-mining/ch8/myplot1.png data-srcset="/img/in-post/data-mining/ch8/myplot1.png, /img/in-post/data-mining/ch8/myplot1.png 1.5x, /img/in-post/data-mining/ch8/myplot1.png 2x" data-sizes=auto alt=/img/in-post/data-mining/ch8/myplot1.png title=8.1></p><hr><p>将图像切分为单个的字母</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>segment_image</span><span class=p>(</span><span class=n>image</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        接收图像，返回小图像列表
</span></span></span><span class=line><span class=cl><span class=s2>        :param image:
</span></span></span><span class=line><span class=cl><span class=s2>        :return:
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=c1># 找出像素值相同又连接在一起的像素块，类似上一章的连通分支</span>
</span></span><span class=line><span class=cl>        <span class=n>labeled_image</span> <span class=o>=</span> <span class=n>label</span><span class=p>(</span><span class=n>image</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>subimages</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>region</span> <span class=ow>in</span> <span class=n>regionprops</span><span class=p>(</span><span class=n>labeled_image</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=c1># 获取当前位置的起始和结束坐标</span>
</span></span><span class=line><span class=cl>            <span class=n>start_x</span><span class=p>,</span> <span class=n>start_y</span><span class=p>,</span> <span class=n>end_x</span><span class=p>,</span> <span class=n>end_y</span> <span class=o>=</span> <span class=n>region</span><span class=o>.</span><span class=n>bbox</span>
</span></span><span class=line><span class=cl>            <span class=n>subimages</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>image</span><span class=p>[</span><span class=n>start_x</span><span class=p>:</span><span class=n>end_x</span><span class=p>,</span> <span class=n>start_y</span><span class=p>:</span><span class=n>end_y</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=c1># 如果没有找到小图像，则将原图像作为子图返回</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>subimages</span><span class=p>)</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=p>[</span><span class=n>image</span><span class=p>,</span> <span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>subimages</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>subimages</span> <span class=o>=</span> <span class=n>segment_image</span><span class=p>(</span><span class=n>image</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>f</span><span class=p>,</span> <span class=n>axes</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>subimages</span><span class=p>),</span> <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>3</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>subimages</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>        <span class=n>axes</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>subimages</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>cmap</span><span class=o>=</span><span class=s1>&#39;gray&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/img/in-post/data-mining/ch8/myplot2.png data-srcset="/img/in-post/data-mining/ch8/myplot2.png, /img/in-post/data-mining/ch8/myplot2.png 1.5x, /img/in-post/data-mining/ch8/myplot2.png 2x" data-sizes=auto alt=/img/in-post/data-mining/ch8/myplot2.png title=8.2></p><hr><p>创建训练集</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># 指定随机状态值</span>
</span></span><span class=line><span class=cl>    <span class=n>random_state</span> <span class=o>=</span> <span class=n>check_random_state</span><span class=p>(</span><span class=mi>14</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>letters</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=s2>&#34;ABCDEFGHIJKLMNOPQRSTUVWXYZ&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>shear_values</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>,</span> <span class=mf>0.05</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 用来生成一条训练数据</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>generate_sample</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>random_state</span> <span class=o>=</span> <span class=n>check_random_state</span><span class=p>(</span><span class=n>random_state</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>letter</span> <span class=o>=</span> <span class=n>random_state</span><span class=o>.</span><span class=n>choice</span><span class=p>(</span><span class=n>letters</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>shear</span> <span class=o>=</span> <span class=n>random_state</span><span class=o>.</span><span class=n>choice</span><span class=p>(</span><span class=n>shear_values</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>create_captcha</span><span class=p>(</span><span class=n>letter</span><span class=p>,</span> <span class=n>shear</span><span class=o>=</span><span class=n>shear</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=mi>25</span><span class=p>,</span> <span class=mi>25</span><span class=p>)),</span> <span class=n>letters</span><span class=o>.</span><span class=n>index</span><span class=p>(</span><span class=n>letter</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>image</span><span class=p>,</span> <span class=n>target</span> <span class=o>=</span> <span class=n>generate_sample</span><span class=p>(</span><span class=n>random_state</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=s1>&#39;Greys&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;The target for this image is </span><span class=si>{}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>target</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 调用3000次此函数，生成训练数据传到numpy的数组里</span>
</span></span><span class=line><span class=cl>    <span class=n>dataset</span><span class=p>,</span> <span class=n>targets</span> <span class=o>=</span> <span class=nb>zip</span><span class=p>(</span><span class=o>*</span><span class=p>(</span><span class=n>generate_sample</span><span class=p>(</span><span class=n>random_state</span><span class=p>)</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>3000</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>    <span class=n>dataset</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>dataset</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=nb>float</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>targets</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>targets</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 对26个字母类别进行编码</span>
</span></span><span class=line><span class=cl>    <span class=n>onehot</span> <span class=o>=</span> <span class=n>OneHotEncoder</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>onehot</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>targets</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>targets</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=c1># 将稀疏矩阵转换为密集矩阵</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>y</span><span class=o>.</span><span class=n>todense</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 调整图像大小</span>
</span></span><span class=line><span class=cl>    <span class=n>dataset</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=n>resize</span><span class=p>(</span><span class=n>segment_image</span><span class=p>(</span><span class=n>sample</span><span class=p>)[</span><span class=mi>0</span><span class=p>],</span> <span class=p>(</span><span class=mi>20</span><span class=p>,</span> <span class=mi>20</span><span class=p>))</span> <span class=k>for</span> <span class=n>sample</span> <span class=ow>in</span> <span class=n>dataset</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=c1># 将最后三维的dataset的后二维扁平化</span>
</span></span><span class=line><span class=cl>    <span class=n>X</span> <span class=o>=</span> <span class=n>dataset</span><span class=o>.</span><span class=n>reshape</span><span class=p>((</span><span class=n>dataset</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>dataset</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>*</span> <span class=n>dataset</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>2</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>    <span class=n>X_train</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>train_size</span><span class=o>=</span><span class=mf>0.9</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>The target for this image is 11
</code></pre><p><img class=lazyload src=/svg/loading.min.svg data-src=/img/in-post/data-mining/ch8/myplot3.png data-srcset="/img/in-post/data-mining/ch8/myplot3.png, /img/in-post/data-mining/ch8/myplot3.png 1.5x, /img/in-post/data-mining/ch8/myplot3.png 2x" data-sizes=auto alt=/img/in-post/data-mining/ch8/myplot3.png title=8.3></p><h3 id=训练和分类>训练和分类</h3><p>反向传播算法（back propagation，backprop）的工作机制为对预测错误的神经元施以惩罚。从输出层开始，向上层层查找预测错误的神经元，微调这些神经元输入值的权重，以达到修复输出错误的目的。</p><p>神经元之所以给出错误的预测，原因在于它前面为其提供输入的神经元，更确切来说是由这两个神经元之间边的权重及输入值决定的。我们可以尝试对权重进行微调。每次调整的幅度取决于以下两个方面</p><ul><li>神经元各边权重的误差函数的偏导数</li><li>一个叫作学习速率的参数（通常使用很小的值）</li></ul><p>计算出函数误差的梯度，再乘以学习速率，用总权重减去得到的值。梯度的符号由误差决定，每次对权重的修正都是朝着给出正确的预测值努力。有时候，修正结果为局部最优（local optima），比起其他权重组合要好，但所得到的各权重还不是最优组合。</p><p>反向传播算法从输出层开始，层层向上回溯到输入层。到达输入层后，所有边的权重更新完毕。</p><p>这里在导入 <code>SupervisedDataSet</code> 时发生了错误，使用 <code>pip install pybrain</code> 安装的包会有找不到方法的现象，因此我从 github-pybrain 下载了源码包，在解压后的文件夹中输入 <code>python setup.py install</code> 进行安装，解决了这个问题。还有一个问题是原文使用 <code>from pybrain.datasets import SupervisedDataSet</code> 来导入 <code>SupervisedDataSet</code> 但是我在导入时发现并没有这个类，于是看了项目结构后使用 <code>from pybrain.datasets.supervised import SupervisedDataSet</code> 进行导入。还有几处相同的问题均是这样解决的。</p><p>这里在使用 f1_score 进行评估时也出现了错误，原因见代码注释。</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># 为pybrain库创建格式适配的数据集</span>
</span></span><span class=line><span class=cl>    <span class=n>training</span> <span class=o>=</span> <span class=n>SupervisedDataSet</span><span class=p>(</span><span class=n>X</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>],</span> <span class=n>y</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>X_train</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]):</span>
</span></span><span class=line><span class=cl>        <span class=n>training</span><span class=o>.</span><span class=n>addSample</span><span class=p>(</span><span class=n>X_train</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>y_train</span><span class=p>[</span><span class=n>i</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>testing</span> <span class=o>=</span> <span class=n>SupervisedDataSet</span><span class=p>(</span><span class=n>X</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>],</span> <span class=n>y</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>X_test</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]):</span>
</span></span><span class=line><span class=cl>        <span class=n>testing</span><span class=o>.</span><span class=n>addSample</span><span class=p>(</span><span class=n>X_test</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>y_test</span><span class=p>[</span><span class=n>i</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=c1># 指定维度，创建神经网络，第一个参数为输入层神经元数量，第二个参数隐含层神经元数量，第三个参数为输出层神经元数量</span>
</span></span><span class=line><span class=cl>    <span class=c1># bias在每一层使用一个一直处于激活状态的偏置神经元</span>
</span></span><span class=line><span class=cl>    <span class=n>net</span> <span class=o>=</span> <span class=n>buildNetwork</span><span class=p>(</span><span class=n>X</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>],</span> <span class=mi>100</span><span class=p>,</span> <span class=n>y</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>],</span> <span class=n>bias</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 使用反向传播算法调整权重</span>
</span></span><span class=line><span class=cl>    <span class=n>trainer</span> <span class=o>=</span> <span class=n>BackpropTrainer</span><span class=p>(</span><span class=n>net</span><span class=p>,</span> <span class=n>training</span><span class=p>,</span> <span class=n>learningrate</span><span class=o>=</span><span class=mf>0.01</span><span class=p>,</span> <span class=n>weightdecay</span><span class=o>=</span><span class=mf>0.01</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 设定代码的运行步数</span>
</span></span><span class=line><span class=cl>    <span class=n>trainer</span><span class=o>.</span><span class=n>trainEpochs</span><span class=p>(</span><span class=n>epochs</span><span class=o>=</span><span class=mi>20</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 预测值</span>
</span></span><span class=line><span class=cl>    <span class=n>predictions</span> <span class=o>=</span> <span class=n>trainer</span><span class=o>.</span><span class=n>testOnClassData</span><span class=p>(</span><span class=n>dataset</span><span class=o>=</span><span class=n>testing</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># f1_score的average默认值为&#39;binary&#39;，如果不指定average则会发生ValueError</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;F-score:</span><span class=si>{0:.2f}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>f1_score</span><span class=p>(</span><span class=n>y_test</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span> <span class=n>predictions</span><span class=p>,</span> <span class=n>average</span><span class=o>=</span><span class=s1>&#39;weighted&#39;</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;F-score:</span><span class=si>{0:.2f}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>f1_score</span><span class=p>(</span><span class=n>y_test</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span> <span class=n>predictions</span><span class=p>,</span> <span class=n>average</span><span class=o>=</span><span class=s1>&#39;micro&#39;</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;F-score:</span><span class=si>{0:.2f}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>f1_score</span><span class=p>(</span><span class=n>y_test</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span> <span class=n>predictions</span><span class=p>,</span> <span class=n>average</span><span class=o>=</span><span class=s1>&#39;macro&#39;</span><span class=p>)))</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>F-score:1.00
F-score:1.00
F-score:1.00
</code></pre><hr><p>预测单词</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># 接收验证码，用神经网络进行训练，返回单词预测结果</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>predict_captcha</span><span class=p>(</span><span class=n>captcha_image</span><span class=p>,</span> <span class=n>neural_network</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>subimages</span> <span class=o>=</span> <span class=n>segment_image</span><span class=p>(</span><span class=n>captcha_image</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>predicted_word</span> <span class=o>=</span> <span class=s2>&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=c1># 遍历四张小图像</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>subimage</span> <span class=ow>in</span> <span class=n>subimages</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># 调整每张小图像的大小为20*20像素</span>
</span></span><span class=line><span class=cl>            <span class=n>subimage</span> <span class=o>=</span> <span class=n>resize</span><span class=p>(</span><span class=n>subimage</span><span class=p>,</span> <span class=p>(</span><span class=mi>20</span><span class=p>,</span><span class=mi>20</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=c1># 把小图像数据传入神经网络的输入层，激活神经网络。这些数据将在神经网络中进行传播，返回输出结果</span>
</span></span><span class=line><span class=cl>            <span class=n>outputs</span> <span class=o>=</span> <span class=n>net</span><span class=o>.</span><span class=n>activate</span><span class=p>(</span><span class=n>subimage</span><span class=o>.</span><span class=n>flatten</span><span class=p>())</span>
</span></span><span class=line><span class=cl>            <span class=c1># 神经网络输出26个值，每个值都有索引号，分别对应letters列表中有着相同索引的字母，每个值的大小表示与对应字母的相似度。为了获得实际的预测值，我们取到最大值的索引，再通过letters列表找到对应的字母</span>
</span></span><span class=line><span class=cl>            <span class=n>prediction</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>outputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=c1># 把上面得到的字母添加到正在预测的单词中</span>
</span></span><span class=line><span class=cl>            <span class=n>predicted_word</span> <span class=o>+=</span> <span class=n>letters</span><span class=p>[</span><span class=n>prediction</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>predicted_word</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>word</span> <span class=o>=</span> <span class=s2>&#34;GENE&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>captcha</span> <span class=o>=</span> <span class=n>create_captcha</span><span class=p>(</span><span class=n>word</span><span class=p>,</span> <span class=n>shear</span><span class=o>=</span><span class=mf>0.2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>predict_captcha</span><span class=p>(</span><span class=n>captcha</span><span class=p>,</span> <span class=n>net</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>GENE
</code></pre><hr><p>nltk 下载语料库时可能会很慢，需要的可以在这里<a href=https://pan.baidu.com/s/1mYm_1CdkNrVScHyiCyIdnQ title=e3pw target=_blank rel="noopener noreffer">下载</a>。如何离线安装 nltk 语料库自行百度。</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>test_prediction</span><span class=p>(</span><span class=n>word</span><span class=p>,</span> <span class=n>net</span><span class=p>,</span> <span class=n>shear</span><span class=o>=</span><span class=mf>0.2</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>captcha</span> <span class=o>=</span> <span class=n>create_captcha</span><span class=p>(</span><span class=n>word</span><span class=p>,</span> <span class=n>shear</span><span class=o>=</span><span class=n>shear</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>prediction</span> <span class=o>=</span> <span class=n>predict_captcha</span><span class=p>(</span><span class=n>captcha</span><span class=p>,</span> <span class=n>net</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>prediction</span> <span class=o>=</span> <span class=n>prediction</span><span class=p>[:</span><span class=mi>4</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=c1># 返回预测结果是否正确，验证码中的单词和预测结果的前四个字符</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>word</span> <span class=o>==</span> <span class=n>prediction</span><span class=p>,</span> <span class=n>word</span><span class=p>,</span> <span class=n>prediction</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 语料库中字长为4的单词列表</span>
</span></span><span class=line><span class=cl>    <span class=n>valid_words</span> <span class=o>=</span> <span class=p>[</span><span class=n>word</span><span class=o>.</span><span class=n>upper</span><span class=p>()</span> <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>words</span><span class=o>.</span><span class=n>words</span><span class=p>()</span> <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>word</span><span class=p>)</span> <span class=o>==</span> <span class=mi>4</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>num_correct</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=n>num_incorrect</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>valid_words</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>correct</span><span class=p>,</span> <span class=n>word</span><span class=p>,</span> <span class=n>prediction</span> <span class=o>=</span> <span class=n>test_prediction</span><span class=p>(</span><span class=n>word</span><span class=p>,</span> <span class=n>net</span><span class=p>,</span> <span class=n>shear</span><span class=o>=</span><span class=mf>0.2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>correct</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>num_correct</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>num_incorrect</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Number correct is </span><span class=si>{}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>num_correct</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Number incorrect is </span><span class=si>{}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>num_incorrect</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 二维混淆矩阵， 每行每列均为一个类别</span>
</span></span><span class=line><span class=cl>    <span class=n>cm</span> <span class=o>=</span> <span class=n>confusion_matrix</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span> <span class=n>predictions</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 混淆矩阵作图</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>20</span><span class=p>,</span> <span class=mi>20</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>cm</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>tick_marks</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>letters</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>xticks</span><span class=p>(</span><span class=n>tick_marks</span><span class=p>,</span> <span class=n>letters</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>yticks</span><span class=p>(</span><span class=n>tick_marks</span><span class=p>,</span> <span class=n>letters</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Actual&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Predicted&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>Number correct is 3738
Number incorrect is 1775
</code></pre><p><img class=lazyload src=/svg/loading.min.svg data-src=/img/in-post/data-mining/ch8/myplot4.png data-srcset="/img/in-post/data-mining/ch8/myplot4.png, /img/in-post/data-mining/ch8/myplot4.png 1.5x, /img/in-post/data-mining/ch8/myplot4.png 2x" data-sizes=auto alt=/img/in-post/data-mining/ch8/myplot4.png title=8.4></p><h3 id=用词典提升准确率>用词典提升准确率</h3><p>假设验证码全部都是英语单词</p><p><em>列文斯坦编辑距离</em>（Levenshtein edit distance）是一种通过比较两个短字符串，确定它们相似度的方法。它不太适合扩展，字符串很长时通常不用这种方法。编辑距离需要计算从一个单词变为另一个单词所需要的步骤数。以下操作都算一步</p><ul><li>在单词的任意位置插入一个新字母</li><li>从单词中删除任意一个字母</li><li>把一个字母替换为另外一个字母</li></ul><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># 获得两个单词的编辑距离</span>
</span></span><span class=line><span class=cl>    <span class=n>steps</span> <span class=o>=</span> <span class=n>edit_distance</span><span class=p>(</span><span class=s2>&#34;STEP&#34;</span><span class=p>,</span> <span class=s2>&#34;STOP&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;The num of steps needed is: </span><span class=si>{}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>steps</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 用词长4减去同等位置上相同的字母数量，得到的值越小表示两个词相似度越高</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>compute_distance</span><span class=p>(</span><span class=n>prediction</span><span class=p>,</span> <span class=n>word</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=nb>len</span><span class=p>(</span><span class=n>prediction</span><span class=p>)</span> <span class=o>-</span> <span class=nb>sum</span><span class=p>(</span><span class=n>prediction</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>==</span> <span class=n>word</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>prediction</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 改进预测函数</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>improved_prediction</span><span class=p>(</span><span class=n>word</span><span class=p>,</span> <span class=n>net</span><span class=p>,</span> <span class=n>dictionary</span><span class=p>,</span> <span class=n>shear</span><span class=o>=</span><span class=mf>0.2</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>captcha</span> <span class=o>=</span> <span class=n>create_captcha</span><span class=p>(</span><span class=n>word</span><span class=p>,</span> <span class=n>shear</span><span class=o>=</span><span class=n>shear</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>prediction</span> <span class=o>=</span> <span class=n>predict_captcha</span><span class=p>(</span><span class=n>captcha</span><span class=p>,</span> <span class=n>net</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>prediction</span> <span class=o>=</span> <span class=n>prediction</span><span class=p>[:</span><span class=mi>4</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=c1># 如果单词不在词典中则比较取词典中距离最小的单词</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>prediction</span> <span class=ow>not</span> <span class=ow>in</span> <span class=n>dictionary</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>distance</span> <span class=o>=</span> <span class=nb>sorted</span><span class=p>([(</span><span class=n>w</span><span class=p>,</span> <span class=n>compute_distance</span><span class=p>(</span><span class=n>prediction</span><span class=p>,</span> <span class=n>w</span><span class=p>))</span> <span class=k>for</span> <span class=n>w</span> <span class=ow>in</span> <span class=n>dictionary</span><span class=p>],</span> <span class=n>key</span><span class=o>=</span><span class=n>itemgetter</span><span class=p>(</span><span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=n>best_word</span> <span class=o>=</span> <span class=n>distance</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=n>prediction</span> <span class=o>=</span> <span class=n>best_word</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>word</span> <span class=o>==</span> <span class=n>prediction</span><span class=p>,</span> <span class=n>word</span><span class=p>,</span> <span class=n>prediction</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>num_correct</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=n>num_incorrect</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>valid_words</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>correct</span><span class=p>,</span> <span class=n>word</span><span class=p>,</span> <span class=n>prediction</span> <span class=o>=</span> <span class=n>improved_prediction</span><span class=p>(</span><span class=n>word</span><span class=p>,</span> <span class=n>net</span><span class=p>,</span> <span class=n>valid_words</span><span class=p>,</span><span class=n>shear</span><span class=o>=</span><span class=mf>0.2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>correct</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>num_correct</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>num_incorrect</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Number correct is </span><span class=si>{}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>num_correct</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Number incorrect is </span><span class=si>{}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>num_incorrect</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>The num of steps needed is: 1
Number correct is 3785
Number incorrect is 1728
</code></pre><p>正确率稍有提升</p><h2 id=第九章>第九章</h2><p>昨天跑去搞 wordpress 搭建网站了 (๑•́ ₃•̀๑) （摸鱼真舒服</p><p>本章主要介绍如下内容</p><ul><li>特征工程和如何根据应用选择特征</li><li>带着新问题，重新回顾词袋模型</li><li>特征类型和字符 N 元语法模型</li><li>支持向量机</li><li>数据集清洗</li></ul><h3 id=为作品找到作者>为作品找到作者</h3><p>作者归属可以看作是一种分类问题，已知一部分作者，数据集为多个作者的作品（训练集），目标是确定一组作者不详的作品（测试集）是谁写的。如果作者恰好是已知的作者里面的，这种问题叫作封闭问题</p><p>如果作者可能不在里面，这种问题就叫作开放问题</p><p>获取数据，书中的链接有很多已经失效，我参考网上的取得了下载方式。</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span><span class=lnt>107
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># -*- coding: utf-8 -*-</span>
</span></span><span class=line><span class=cl><span class=c1># get_data.py</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>requests</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>time</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>collections</span> <span class=kn>import</span> <span class=n>defaultdict</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>titles</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;burton&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mi>4657</span><span class=p>,</span> <span class=mi>2400</span><span class=p>,</span> <span class=mi>5760</span><span class=p>,</span> <span class=mi>6036</span><span class=p>,</span> <span class=mi>7111</span><span class=p>,</span> <span class=mi>8821</span><span class=p>,</span> <span class=mi>18506</span><span class=p>,</span> <span class=mi>4658</span><span class=p>,</span> <span class=mi>5761</span><span class=p>,</span> <span class=mi>6886</span><span class=p>,</span> <span class=mi>7113</span><span class=p>],</span>
</span></span><span class=line><span class=cl>          <span class=s1>&#39;dickens&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mi>24022</span><span class=p>,</span> <span class=mi>1392</span><span class=p>,</span> <span class=mi>1414</span><span class=p>,</span> <span class=mi>1467</span><span class=p>,</span> <span class=mi>2324</span><span class=p>,</span> <span class=mi>580</span><span class=p>,</span> <span class=mi>786</span><span class=p>,</span> <span class=mi>888</span><span class=p>,</span> <span class=mi>963</span><span class=p>,</span> <span class=mi>27924</span><span class=p>,</span> <span class=mi>1394</span><span class=p>,</span> <span class=mi>1415</span><span class=p>,</span> <span class=mi>15618</span><span class=p>,</span> <span class=mi>25985</span><span class=p>,</span> <span class=mi>588</span><span class=p>,</span> <span class=mi>807</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                      <span class=mi>914</span><span class=p>,</span> <span class=mi>967</span><span class=p>,</span> <span class=mi>30127</span><span class=p>,</span> <span class=mi>1400</span><span class=p>,</span> <span class=mi>1421</span><span class=p>,</span> <span class=mi>16023</span><span class=p>,</span> <span class=mi>28198</span><span class=p>,</span> <span class=mi>644</span><span class=p>,</span> <span class=mi>809</span><span class=p>,</span> <span class=mi>917</span><span class=p>,</span> <span class=mi>968</span><span class=p>,</span> <span class=mi>1023</span><span class=p>,</span> <span class=mi>1406</span><span class=p>,</span> <span class=mi>1422</span><span class=p>,</span> <span class=mi>17879</span><span class=p>,</span> <span class=mi>30368</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                      <span class=mi>675</span><span class=p>,</span> <span class=mi>810</span><span class=p>,</span> <span class=mi>924</span><span class=p>,</span> <span class=mi>98</span><span class=p>,</span> <span class=mi>1289</span><span class=p>,</span> <span class=mi>1413</span><span class=p>,</span> <span class=mi>1423</span><span class=p>,</span> <span class=mi>17880</span><span class=p>,</span> <span class=mi>32241</span><span class=p>,</span> <span class=mi>699</span><span class=p>,</span> <span class=mi>821</span><span class=p>,</span> <span class=mi>927</span><span class=p>],</span>
</span></span><span class=line><span class=cl>          <span class=s1>&#39;doyle&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mi>2349</span><span class=p>,</span> <span class=mi>11656</span><span class=p>,</span> <span class=mi>1644</span><span class=p>,</span> <span class=mi>22357</span><span class=p>,</span> <span class=mi>2347</span><span class=p>,</span> <span class=mi>290</span><span class=p>,</span> <span class=mi>34627</span><span class=p>,</span> <span class=mi>5148</span><span class=p>,</span> <span class=mi>8394</span><span class=p>,</span> <span class=mi>26153</span><span class=p>,</span> <span class=mi>12555</span><span class=p>,</span> <span class=mi>1661</span><span class=p>,</span> <span class=mi>23059</span><span class=p>,</span> <span class=mi>2348</span><span class=p>,</span> <span class=mi>294</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=mi>355</span><span class=p>,</span> <span class=mi>5260</span><span class=p>,</span> <span class=mi>8727</span><span class=p>,</span> <span class=mi>10446</span><span class=p>,</span> <span class=mi>126</span><span class=p>,</span> <span class=mi>17398</span><span class=p>,</span> <span class=mi>2343</span><span class=p>,</span> <span class=mi>2350</span><span class=p>,</span> <span class=mi>3070</span><span class=p>,</span> <span class=mi>356</span><span class=p>,</span> <span class=mi>5317</span><span class=p>,</span> <span class=mi>903</span><span class=p>,</span> <span class=mi>10581</span><span class=p>,</span> <span class=mi>13152</span><span class=p>,</span> <span class=mi>2038</span><span class=p>,</span> <span class=mi>2344</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=mi>244</span><span class=p>,</span> <span class=mi>32536</span><span class=p>,</span> <span class=mi>423</span><span class=p>,</span> <span class=mi>537</span><span class=p>,</span> <span class=mi>108</span><span class=p>,</span> <span class=mi>139</span><span class=p>,</span> <span class=mi>2097</span><span class=p>,</span> <span class=mi>2345</span><span class=p>,</span> <span class=mi>24951</span><span class=p>,</span> <span class=mi>32777</span><span class=p>,</span> <span class=mi>4295</span><span class=p>,</span> <span class=mi>7964</span><span class=p>,</span> <span class=mi>11413</span><span class=p>,</span> <span class=mi>1638</span><span class=p>,</span> <span class=mi>21768</span><span class=p>,</span> <span class=mi>2346</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=mi>2845</span><span class=p>,</span> <span class=mi>3289</span><span class=p>,</span> <span class=mi>439</span><span class=p>,</span> <span class=mi>834</span><span class=p>],</span>
</span></span><span class=line><span class=cl>          <span class=s1>&#39;gaboriau&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mi>1748</span><span class=p>,</span> <span class=mi>1651</span><span class=p>,</span> <span class=mi>2736</span><span class=p>,</span> <span class=mi>3336</span><span class=p>,</span> <span class=mi>4604</span><span class=p>,</span> <span class=mi>4002</span><span class=p>,</span> <span class=mi>2451</span><span class=p>,</span> <span class=mi>305</span><span class=p>,</span> <span class=mi>3802</span><span class=p>,</span> <span class=mi>547</span><span class=p>],</span>
</span></span><span class=line><span class=cl>          <span class=s1>&#39;nesbit&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mi>34219</span><span class=p>,</span> <span class=mi>23661</span><span class=p>,</span> <span class=mi>28804</span><span class=p>,</span> <span class=mi>4378</span><span class=p>,</span> <span class=mi>778</span><span class=p>,</span> <span class=mi>20404</span><span class=p>,</span> <span class=mi>28725</span><span class=p>,</span> <span class=mi>33028</span><span class=p>,</span> <span class=mi>4513</span><span class=p>,</span> <span class=mi>794</span><span class=p>],</span>
</span></span><span class=line><span class=cl>          <span class=s1>&#39;tarkington&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mi>1098</span><span class=p>,</span> <span class=mi>15855</span><span class=p>,</span> <span class=mi>1983</span><span class=p>,</span> <span class=mi>297</span><span class=p>,</span> <span class=mi>402</span><span class=p>,</span> <span class=mi>5798</span><span class=p>,</span> <span class=mi>8740</span><span class=p>,</span> <span class=mi>980</span><span class=p>,</span> <span class=mi>1158</span><span class=p>,</span> <span class=mi>1611</span><span class=p>,</span> <span class=mi>2326</span><span class=p>,</span> <span class=mi>30092</span><span class=p>,</span> <span class=mi>483</span><span class=p>,</span> <span class=mi>5949</span><span class=p>,</span> <span class=mi>8867</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                         <span class=mi>13275</span><span class=p>,</span> <span class=mi>18259</span><span class=p>,</span> <span class=mi>2595</span><span class=p>,</span> <span class=mi>3428</span><span class=p>,</span> <span class=mi>5756</span><span class=p>,</span> <span class=mi>6401</span><span class=p>,</span> <span class=mi>9659</span><span class=p>],</span>
</span></span><span class=line><span class=cl>          <span class=s1>&#39;twain&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mi>1044</span><span class=p>,</span> <span class=mi>1213</span><span class=p>,</span> <span class=mi>245</span><span class=p>,</span> <span class=mi>30092</span><span class=p>,</span> <span class=mi>3176</span><span class=p>,</span> <span class=mi>3179</span><span class=p>,</span> <span class=mi>3183</span><span class=p>,</span> <span class=mi>3189</span><span class=p>,</span> <span class=mi>74</span><span class=p>,</span> <span class=mi>86</span><span class=p>,</span> <span class=mi>1086</span><span class=p>,</span> <span class=mi>142</span><span class=p>,</span> <span class=mi>2572</span><span class=p>,</span> <span class=mi>3173</span><span class=p>,</span> <span class=mi>3177</span><span class=p>,</span> <span class=mi>3180</span><span class=p>,</span> <span class=mi>3186</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=mi>3192</span><span class=p>,</span> <span class=mi>76</span><span class=p>,</span> <span class=mi>91</span><span class=p>,</span> <span class=mi>119</span><span class=p>,</span> <span class=mi>1837</span><span class=p>,</span> <span class=mi>2895</span><span class=p>,</span> <span class=mi>3174</span><span class=p>,</span> <span class=mi>3178</span><span class=p>,</span> <span class=mi>3181</span><span class=p>,</span> <span class=mi>3187</span><span class=p>,</span> <span class=mi>3432</span><span class=p>,</span> <span class=mi>8525</span><span class=p>]}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>assert</span> <span class=nb>len</span><span class=p>(</span><span class=n>titles</span><span class=p>)</span> <span class=o>==</span> <span class=mi>7</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>assert</span> <span class=nb>len</span><span class=p>(</span><span class=n>titles</span><span class=p>[</span><span class=s1>&#39;tarkington&#39;</span><span class=p>])</span> <span class=o>==</span> <span class=mi>22</span>
</span></span><span class=line><span class=cl><span class=k>assert</span> <span class=nb>len</span><span class=p>(</span><span class=n>titles</span><span class=p>[</span><span class=s1>&#39;dickens&#39;</span><span class=p>])</span> <span class=o>==</span> <span class=mi>44</span>
</span></span><span class=line><span class=cl><span class=k>assert</span> <span class=nb>len</span><span class=p>(</span><span class=n>titles</span><span class=p>[</span><span class=s1>&#39;nesbit&#39;</span><span class=p>])</span> <span class=o>==</span> <span class=mi>10</span>
</span></span><span class=line><span class=cl><span class=k>assert</span> <span class=nb>len</span><span class=p>(</span><span class=n>titles</span><span class=p>[</span><span class=s1>&#39;doyle&#39;</span><span class=p>])</span> <span class=o>==</span> <span class=mi>51</span>
</span></span><span class=line><span class=cl><span class=k>assert</span> <span class=nb>len</span><span class=p>(</span><span class=n>titles</span><span class=p>[</span><span class=s1>&#39;twain&#39;</span><span class=p>])</span> <span class=o>==</span> <span class=mi>29</span>
</span></span><span class=line><span class=cl><span class=k>assert</span> <span class=nb>len</span><span class=p>(</span><span class=n>titles</span><span class=p>[</span><span class=s1>&#39;burton&#39;</span><span class=p>])</span> <span class=o>==</span> <span class=mi>11</span>
</span></span><span class=line><span class=cl><span class=k>assert</span> <span class=nb>len</span><span class=p>(</span><span class=n>titles</span><span class=p>[</span><span class=s1>&#39;gaboriau&#39;</span><span class=p>])</span> <span class=o>==</span> <span class=mi>10</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>url_base</span> <span class=o>=</span> <span class=s1>&#39;http://www.gutenberg.org/files/&#39;</span>
</span></span><span class=line><span class=cl><span class=n>url_format</span> <span class=o>=</span> <span class=s1>&#39;</span><span class=si>{url_base}{id}</span><span class=s1>/</span><span class=si>{id}</span><span class=s1>-0.txt&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 修复URL</span>
</span></span><span class=line><span class=cl><span class=n>url_fix_format</span> <span class=o>=</span> <span class=s1>&#39;http://www.gutenberg.org/cache/epub/</span><span class=si>{id}</span><span class=s1>/pg</span><span class=si>{id}</span><span class=s1>.txt&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>fiexes</span> <span class=o>=</span> <span class=n>defaultdict</span><span class=p>(</span><span class=nb>list</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># fixes = {}</span>
</span></span><span class=line><span class=cl><span class=c1># fixes[4657] = &#39;http://www.gutenberg.org/cache/epub/4657/pg4657.txt&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># make parent folder if not exists</span>
</span></span><span class=line><span class=cl><span class=c1># data_folder = os.path.join(os.path.expanduser(&#39;~&#39;),&#39;Data&#39;,&#39;books&#39;) #</span>
</span></span><span class=line><span class=cl><span class=c1># 这是在用户user目录中存储</span>
</span></span><span class=line><span class=cl><span class=n>data_folder</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>dirname</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>abspath</span><span class=p>(</span><span class=vm>__file__</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s1>&#39;__main__&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=ow>not</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>exists</span><span class=p>(</span><span class=n>data_folder</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>os</span><span class=o>.</span><span class=n>makedirs</span><span class=p>(</span><span class=n>data_folder</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>data_folder</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>author</span> <span class=ow>in</span> <span class=n>titles</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Downloading titles from&#39;</span><span class=p>,</span> <span class=n>author</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># make author&#39;s folder if not exists</span>
</span></span><span class=line><span class=cl>        <span class=n>author_folder</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>data_folder</span><span class=p>,</span> <span class=n>author</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=ow>not</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>exists</span><span class=p>(</span><span class=n>author_folder</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>os</span><span class=o>.</span><span class=n>makedirs</span><span class=p>(</span><span class=n>author_folder</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># download each title to this folder</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>bookid</span> <span class=ow>in</span> <span class=n>titles</span><span class=p>[</span><span class=n>author</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>            <span class=c1># if bookid in fixes:</span>
</span></span><span class=line><span class=cl>            <span class=c1>#     print(&#39; - Applying fix to book with id&#39;, bookid)</span>
</span></span><span class=line><span class=cl>            <span class=c1>#     url = fixes[bookid]</span>
</span></span><span class=line><span class=cl>            <span class=c1># else:</span>
</span></span><span class=line><span class=cl>            <span class=c1>#     print(&#39; - Getting book with id&#39;, bookid)</span>
</span></span><span class=line><span class=cl>            <span class=c1>#     url = url_format.format(url_base=url_base, id=bookid)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>url</span> <span class=o>=</span> <span class=n>url_format</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>url_base</span><span class=o>=</span><span class=n>url_base</span><span class=p>,</span> <span class=nb>id</span><span class=o>=</span><span class=n>bookid</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s1>&#39; - &#39;</span><span class=p>,</span> <span class=n>url</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>filename</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>author_folder</span><span class=p>,</span> <span class=s1>&#39;</span><span class=si>%s</span><span class=s1>.txt&#39;</span> <span class=o>%</span> <span class=n>bookid</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>exists</span><span class=p>(</span><span class=n>filename</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=nb>print</span><span class=p>(</span><span class=s1>&#39; - File already exists, skipping&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>r</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>url</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=n>r</span><span class=o>.</span><span class=n>status_code</span> <span class=o>==</span> <span class=mi>404</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;url 404:&#39;</span><span class=p>,</span> <span class=n>author</span><span class=p>,</span> <span class=n>bookid</span><span class=p>,</span> <span class=s1>&#39;add to fixes list&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>fiexes</span><span class=p>[</span><span class=n>author</span><span class=p>]</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>bookid</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=n>txt</span> <span class=o>=</span> <span class=n>r</span><span class=o>.</span><span class=n>text</span>
</span></span><span class=line><span class=cl>                    <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>filename</span><span class=p>,</span> <span class=s1>&#39;w&#39;</span><span class=p>,</span> <span class=n>encoding</span><span class=o>=</span><span class=s1>&#39;utf-8&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                        <span class=n>f</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>txt</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>time</span><span class=o>.</span><span class=n>sleep</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Download complete&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;开始下载修复列表&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>author</span> <span class=ow>in</span> <span class=n>fiexes</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;开始下载&lt;</span><span class=si>%s</span><span class=s1>&gt;的作品&#39;</span> <span class=o>%</span> <span class=n>author</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>author_folder</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>data_folder</span><span class=p>,</span> <span class=n>author</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=ow>not</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>exists</span><span class=p>(</span><span class=n>author_folder</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>os</span><span class=o>.</span><span class=n>makedirs</span><span class=p>(</span><span class=n>author_folder</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>bookid</span> <span class=ow>in</span> <span class=n>fiexes</span><span class=p>[</span><span class=n>author</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>            <span class=n>filename</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>author_folder</span><span class=p>,</span> <span class=s1>&#39;</span><span class=si>%s</span><span class=s1>.txt&#39;</span> <span class=o>%</span> <span class=n>bookid</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>exists</span><span class=p>(</span><span class=n>filename</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;文件已经下载，跳过&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>url_fix</span> <span class=o>=</span> <span class=n>url_fix_format</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=nb>id</span><span class=o>=</span><span class=n>bookid</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=nb>print</span><span class=p>(</span><span class=s1>&#39; - &#39;</span><span class=p>,</span> <span class=n>url_fix</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>r</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>url_fix</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=n>r</span><span class=o>.</span><span class=n>status_code</span> <span class=o>==</span> <span class=mi>404</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;又出错了！&#39;</span><span class=p>,</span> <span class=n>author</span><span class=p>,</span> <span class=n>bookid</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>filename</span><span class=p>,</span> <span class=s1>&#39;w&#39;</span><span class=p>,</span> <span class=n>encoding</span><span class=o>=</span><span class=s1>&#39;utf-8&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                        <span class=n>f</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>r</span><span class=o>.</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>time</span><span class=o>.</span><span class=n>sleep</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;修复列表下载完毕&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>最后下载完成有 177 本书</p><hr><p>支持向量机是一种二类分类器，扩展后可用来对多个类别进行分类 9（对于多种类别的分类问题，我们创建多个 SVM 分类器——每个还是二类分类器）</p><p>C 参数对于训练 SVM 来说很重要，C 参数与分类器正确分类比例相关，但可能带来过拟合的风险。C 值越高，间隔越小，表示要尽可能把所有数据正确分类。C 值越小，间隔越大——有些数据将无法正确分类。C 值低，过拟合训练数据的可能性就低，但是分类效果可能会相对较差</p><p>SVM（基础形式）局限性之一就是只能用来对线性可分的数据进行分类。如果数据线性不可分，就要用到内核函数，将其置入更高维的空间中，加入更多伪特征直到数据线性可分。常用的内核函数有几种。线性内核最简单，它无外乎两个个体的特征向量的点积、带权重的特征和偏置项。多项式核提高点积的阶数（比如 2）。此外，还有高斯内核（rbf）、Sigmoind 内核</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span><span class=lnt>107
</span><span class=lnt>108
</span><span class=lnt>109
</span><span class=lnt>110
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># -*- coding: utf-8 -*-</span>
</span></span><span class=line><span class=cl><span class=c1># author_test.py</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.feature_extraction.text</span> <span class=kn>import</span> <span class=n>CountVectorizer</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.svm</span> <span class=kn>import</span> <span class=n>SVC</span>  <span class=c1># 支持向量机</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>cross_val_score</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.pipeline</span> <span class=kn>import</span> <span class=n>Pipeline</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>GridSearchCV</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>ch9</span> <span class=kn>import</span> <span class=n>getdata</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 去掉古藤堡的说明</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>clean_book</span><span class=p>(</span><span class=n>document</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>lines</span> <span class=o>=</span> <span class=n>document</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>start</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=n>end</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>lines</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>lines</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>        <span class=n>line</span> <span class=o>=</span> <span class=n>lines</span><span class=p>[</span><span class=n>i</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>line</span><span class=o>.</span><span class=n>startswith</span><span class=p>(</span><span class=s2>&#34;*** START OF THIS PROJECT GUTENBERG&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>start</span> <span class=o>=</span> <span class=n>i</span> <span class=o>+</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>        <span class=k>elif</span> <span class=n>line</span><span class=o>.</span><span class=n>startswith</span><span class=p>(</span><span class=s2>&#34;*** END OF THIS PROJECT GUTENBERG&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>end</span> <span class=o>=</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=s2>&#34;</span><span class=se>\n</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>lines</span><span class=p>[</span><span class=n>start</span><span class=p>:</span><span class=n>end</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>load_books_data</span><span class=p>(</span><span class=n>folder</span><span class=o>=</span><span class=n>getdata</span><span class=o>.</span><span class=n>data_folder</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># 存储文档和作者</span>
</span></span><span class=line><span class=cl>    <span class=n>documents</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>authors</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=c1># 遍历子文件夹</span>
</span></span><span class=line><span class=cl>    <span class=n>subfolders</span> <span class=o>=</span> <span class=p>[</span><span class=n>subfolder</span> <span class=k>for</span> <span class=n>subfolder</span> <span class=ow>in</span> <span class=n>os</span><span class=o>.</span><span class=n>listdir</span><span class=p>(</span><span class=n>folder</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                  <span class=k>if</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>isdir</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>folder</span><span class=p>,</span> <span class=n>subfolder</span><span class=p>))]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>author_number</span><span class=p>,</span> <span class=n>subfolder</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>subfolders</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>full_subfolder_path</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>folder</span><span class=p>,</span> <span class=n>subfolder</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>document_name</span> <span class=ow>in</span> <span class=n>os</span><span class=o>.</span><span class=n>listdir</span><span class=p>(</span><span class=n>full_subfolder_path</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=c1># 跳过目录下的getdata.py文件</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>document_name</span> <span class=o>==</span> <span class=s1>&#39;getdata.cpython-38.pyc&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>continue</span>
</span></span><span class=line><span class=cl>            <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>full_subfolder_path</span><span class=p>,</span> <span class=n>document_name</span><span class=p>),</span> <span class=s1>&#39;r&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>inf</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>documents</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>clean_book</span><span class=p>(</span><span class=n>inf</span><span class=o>.</span><span class=n>read</span><span class=p>()))</span>
</span></span><span class=line><span class=cl>                <span class=n>authors</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>author_number</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>documents</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>authors</span><span class=p>,</span> <span class=s1>&#39;int&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 功能词</span>
</span></span><span class=line><span class=cl><span class=n>function_words</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&#34;a&#34;</span><span class=p>,</span> <span class=s2>&#34;able&#34;</span><span class=p>,</span> <span class=s2>&#34;aboard&#34;</span><span class=p>,</span> <span class=s2>&#34;about&#34;</span><span class=p>,</span> <span class=s2>&#34;above&#34;</span><span class=p>,</span> <span class=s2>&#34;absent&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;according&#34;</span><span class=p>,</span> <span class=s2>&#34;accordingly&#34;</span><span class=p>,</span> <span class=s2>&#34;across&#34;</span><span class=p>,</span> <span class=s2>&#34;after&#34;</span><span class=p>,</span> <span class=s2>&#34;against&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;ahead&#34;</span><span class=p>,</span> <span class=s2>&#34;albeit&#34;</span><span class=p>,</span> <span class=s2>&#34;all&#34;</span><span class=p>,</span> <span class=s2>&#34;along&#34;</span><span class=p>,</span> <span class=s2>&#34;alongside&#34;</span><span class=p>,</span> <span class=s2>&#34;although&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;am&#34;</span><span class=p>,</span> <span class=s2>&#34;amid&#34;</span><span class=p>,</span> <span class=s2>&#34;amidst&#34;</span><span class=p>,</span> <span class=s2>&#34;among&#34;</span><span class=p>,</span> <span class=s2>&#34;amongst&#34;</span><span class=p>,</span> <span class=s2>&#34;amount&#34;</span><span class=p>,</span> <span class=s2>&#34;an&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;and&#34;</span><span class=p>,</span> <span class=s2>&#34;another&#34;</span><span class=p>,</span> <span class=s2>&#34;anti&#34;</span><span class=p>,</span> <span class=s2>&#34;any&#34;</span><span class=p>,</span> <span class=s2>&#34;anybody&#34;</span><span class=p>,</span> <span class=s2>&#34;anyone&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;anything&#34;</span><span class=p>,</span> <span class=s2>&#34;are&#34;</span><span class=p>,</span> <span class=s2>&#34;around&#34;</span><span class=p>,</span> <span class=s2>&#34;as&#34;</span><span class=p>,</span> <span class=s2>&#34;aside&#34;</span><span class=p>,</span> <span class=s2>&#34;astraddle&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;astride&#34;</span><span class=p>,</span> <span class=s2>&#34;at&#34;</span><span class=p>,</span> <span class=s2>&#34;away&#34;</span><span class=p>,</span> <span class=s2>&#34;bar&#34;</span><span class=p>,</span> <span class=s2>&#34;barring&#34;</span><span class=p>,</span> <span class=s2>&#34;be&#34;</span><span class=p>,</span> <span class=s2>&#34;because&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;been&#34;</span><span class=p>,</span> <span class=s2>&#34;before&#34;</span><span class=p>,</span> <span class=s2>&#34;behind&#34;</span><span class=p>,</span> <span class=s2>&#34;being&#34;</span><span class=p>,</span> <span class=s2>&#34;below&#34;</span><span class=p>,</span> <span class=s2>&#34;beneath&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;beside&#34;</span><span class=p>,</span> <span class=s2>&#34;besides&#34;</span><span class=p>,</span> <span class=s2>&#34;better&#34;</span><span class=p>,</span> <span class=s2>&#34;between&#34;</span><span class=p>,</span> <span class=s2>&#34;beyond&#34;</span><span class=p>,</span> <span class=s2>&#34;bit&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;both&#34;</span><span class=p>,</span> <span class=s2>&#34;but&#34;</span><span class=p>,</span> <span class=s2>&#34;by&#34;</span><span class=p>,</span> <span class=s2>&#34;can&#34;</span><span class=p>,</span> <span class=s2>&#34;certain&#34;</span><span class=p>,</span> <span class=s2>&#34;circa&#34;</span><span class=p>,</span> <span class=s2>&#34;close&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;concerning&#34;</span><span class=p>,</span> <span class=s2>&#34;consequently&#34;</span><span class=p>,</span> <span class=s2>&#34;considering&#34;</span><span class=p>,</span> <span class=s2>&#34;could&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;couple&#34;</span><span class=p>,</span> <span class=s2>&#34;dare&#34;</span><span class=p>,</span> <span class=s2>&#34;deal&#34;</span><span class=p>,</span> <span class=s2>&#34;despite&#34;</span><span class=p>,</span> <span class=s2>&#34;down&#34;</span><span class=p>,</span> <span class=s2>&#34;due&#34;</span><span class=p>,</span> <span class=s2>&#34;during&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;each&#34;</span><span class=p>,</span> <span class=s2>&#34;eight&#34;</span><span class=p>,</span> <span class=s2>&#34;eighth&#34;</span><span class=p>,</span> <span class=s2>&#34;either&#34;</span><span class=p>,</span> <span class=s2>&#34;enough&#34;</span><span class=p>,</span> <span class=s2>&#34;every&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;everybody&#34;</span><span class=p>,</span> <span class=s2>&#34;everyone&#34;</span><span class=p>,</span> <span class=s2>&#34;everything&#34;</span><span class=p>,</span> <span class=s2>&#34;except&#34;</span><span class=p>,</span> <span class=s2>&#34;excepting&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;excluding&#34;</span><span class=p>,</span> <span class=s2>&#34;failing&#34;</span><span class=p>,</span> <span class=s2>&#34;few&#34;</span><span class=p>,</span> <span class=s2>&#34;fewer&#34;</span><span class=p>,</span> <span class=s2>&#34;fifth&#34;</span><span class=p>,</span> <span class=s2>&#34;first&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;five&#34;</span><span class=p>,</span> <span class=s2>&#34;following&#34;</span><span class=p>,</span> <span class=s2>&#34;for&#34;</span><span class=p>,</span> <span class=s2>&#34;four&#34;</span><span class=p>,</span> <span class=s2>&#34;fourth&#34;</span><span class=p>,</span> <span class=s2>&#34;from&#34;</span><span class=p>,</span> <span class=s2>&#34;front&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;given&#34;</span><span class=p>,</span> <span class=s2>&#34;good&#34;</span><span class=p>,</span> <span class=s2>&#34;great&#34;</span><span class=p>,</span> <span class=s2>&#34;had&#34;</span><span class=p>,</span> <span class=s2>&#34;half&#34;</span><span class=p>,</span> <span class=s2>&#34;have&#34;</span><span class=p>,</span> <span class=s2>&#34;he&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;heaps&#34;</span><span class=p>,</span> <span class=s2>&#34;hence&#34;</span><span class=p>,</span> <span class=s2>&#34;her&#34;</span><span class=p>,</span> <span class=s2>&#34;hers&#34;</span><span class=p>,</span> <span class=s2>&#34;herself&#34;</span><span class=p>,</span> <span class=s2>&#34;him&#34;</span><span class=p>,</span> <span class=s2>&#34;himself&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;his&#34;</span><span class=p>,</span> <span class=s2>&#34;however&#34;</span><span class=p>,</span> <span class=s2>&#34;i&#34;</span><span class=p>,</span> <span class=s2>&#34;if&#34;</span><span class=p>,</span> <span class=s2>&#34;in&#34;</span><span class=p>,</span> <span class=s2>&#34;including&#34;</span><span class=p>,</span> <span class=s2>&#34;inside&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;instead&#34;</span><span class=p>,</span> <span class=s2>&#34;into&#34;</span><span class=p>,</span> <span class=s2>&#34;is&#34;</span><span class=p>,</span> <span class=s2>&#34;it&#34;</span><span class=p>,</span> <span class=s2>&#34;its&#34;</span><span class=p>,</span> <span class=s2>&#34;itself&#34;</span><span class=p>,</span> <span class=s2>&#34;keeping&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;lack&#34;</span><span class=p>,</span> <span class=s2>&#34;less&#34;</span><span class=p>,</span> <span class=s2>&#34;like&#34;</span><span class=p>,</span> <span class=s2>&#34;little&#34;</span><span class=p>,</span> <span class=s2>&#34;loads&#34;</span><span class=p>,</span> <span class=s2>&#34;lots&#34;</span><span class=p>,</span> <span class=s2>&#34;majority&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;many&#34;</span><span class=p>,</span> <span class=s2>&#34;masses&#34;</span><span class=p>,</span> <span class=s2>&#34;may&#34;</span><span class=p>,</span> <span class=s2>&#34;me&#34;</span><span class=p>,</span> <span class=s2>&#34;might&#34;</span><span class=p>,</span> <span class=s2>&#34;mine&#34;</span><span class=p>,</span> <span class=s2>&#34;minority&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;minus&#34;</span><span class=p>,</span> <span class=s2>&#34;more&#34;</span><span class=p>,</span> <span class=s2>&#34;most&#34;</span><span class=p>,</span> <span class=s2>&#34;much&#34;</span><span class=p>,</span> <span class=s2>&#34;must&#34;</span><span class=p>,</span> <span class=s2>&#34;my&#34;</span><span class=p>,</span> <span class=s2>&#34;myself&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;near&#34;</span><span class=p>,</span> <span class=s2>&#34;need&#34;</span><span class=p>,</span> <span class=s2>&#34;neither&#34;</span><span class=p>,</span> <span class=s2>&#34;nevertheless&#34;</span><span class=p>,</span> <span class=s2>&#34;next&#34;</span><span class=p>,</span> <span class=s2>&#34;nine&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;ninth&#34;</span><span class=p>,</span> <span class=s2>&#34;no&#34;</span><span class=p>,</span> <span class=s2>&#34;nobody&#34;</span><span class=p>,</span> <span class=s2>&#34;none&#34;</span><span class=p>,</span> <span class=s2>&#34;nor&#34;</span><span class=p>,</span> <span class=s2>&#34;nothing&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;notwithstanding&#34;</span><span class=p>,</span> <span class=s2>&#34;number&#34;</span><span class=p>,</span> <span class=s2>&#34;numbers&#34;</span><span class=p>,</span> <span class=s2>&#34;of&#34;</span><span class=p>,</span> <span class=s2>&#34;off&#34;</span><span class=p>,</span> <span class=s2>&#34;on&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;once&#34;</span><span class=p>,</span> <span class=s2>&#34;one&#34;</span><span class=p>,</span> <span class=s2>&#34;onto&#34;</span><span class=p>,</span> <span class=s2>&#34;opposite&#34;</span><span class=p>,</span> <span class=s2>&#34;or&#34;</span><span class=p>,</span> <span class=s2>&#34;other&#34;</span><span class=p>,</span> <span class=s2>&#34;ought&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;our&#34;</span><span class=p>,</span> <span class=s2>&#34;ours&#34;</span><span class=p>,</span> <span class=s2>&#34;ourselves&#34;</span><span class=p>,</span> <span class=s2>&#34;out&#34;</span><span class=p>,</span> <span class=s2>&#34;outside&#34;</span><span class=p>,</span> <span class=s2>&#34;over&#34;</span><span class=p>,</span> <span class=s2>&#34;part&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;past&#34;</span><span class=p>,</span> <span class=s2>&#34;pending&#34;</span><span class=p>,</span> <span class=s2>&#34;per&#34;</span><span class=p>,</span> <span class=s2>&#34;pertaining&#34;</span><span class=p>,</span> <span class=s2>&#34;place&#34;</span><span class=p>,</span> <span class=s2>&#34;plenty&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;plethora&#34;</span><span class=p>,</span> <span class=s2>&#34;plus&#34;</span><span class=p>,</span> <span class=s2>&#34;quantities&#34;</span><span class=p>,</span> <span class=s2>&#34;quantity&#34;</span><span class=p>,</span> <span class=s2>&#34;quarter&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;regarding&#34;</span><span class=p>,</span> <span class=s2>&#34;remainder&#34;</span><span class=p>,</span> <span class=s2>&#34;respecting&#34;</span><span class=p>,</span> <span class=s2>&#34;rest&#34;</span><span class=p>,</span> <span class=s2>&#34;round&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;save&#34;</span><span class=p>,</span> <span class=s2>&#34;saving&#34;</span><span class=p>,</span> <span class=s2>&#34;second&#34;</span><span class=p>,</span> <span class=s2>&#34;seven&#34;</span><span class=p>,</span> <span class=s2>&#34;seventh&#34;</span><span class=p>,</span> <span class=s2>&#34;several&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;shall&#34;</span><span class=p>,</span> <span class=s2>&#34;she&#34;</span><span class=p>,</span> <span class=s2>&#34;should&#34;</span><span class=p>,</span> <span class=s2>&#34;similar&#34;</span><span class=p>,</span> <span class=s2>&#34;since&#34;</span><span class=p>,</span> <span class=s2>&#34;six&#34;</span><span class=p>,</span> <span class=s2>&#34;sixth&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;so&#34;</span><span class=p>,</span> <span class=s2>&#34;some&#34;</span><span class=p>,</span> <span class=s2>&#34;somebody&#34;</span><span class=p>,</span> <span class=s2>&#34;someone&#34;</span><span class=p>,</span> <span class=s2>&#34;something&#34;</span><span class=p>,</span> <span class=s2>&#34;spite&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;such&#34;</span><span class=p>,</span> <span class=s2>&#34;ten&#34;</span><span class=p>,</span> <span class=s2>&#34;tenth&#34;</span><span class=p>,</span> <span class=s2>&#34;than&#34;</span><span class=p>,</span> <span class=s2>&#34;thanks&#34;</span><span class=p>,</span> <span class=s2>&#34;that&#34;</span><span class=p>,</span> <span class=s2>&#34;the&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;their&#34;</span><span class=p>,</span> <span class=s2>&#34;theirs&#34;</span><span class=p>,</span> <span class=s2>&#34;them&#34;</span><span class=p>,</span> <span class=s2>&#34;themselves&#34;</span><span class=p>,</span> <span class=s2>&#34;then&#34;</span><span class=p>,</span> <span class=s2>&#34;thence&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;therefore&#34;</span><span class=p>,</span> <span class=s2>&#34;these&#34;</span><span class=p>,</span> <span class=s2>&#34;they&#34;</span><span class=p>,</span> <span class=s2>&#34;third&#34;</span><span class=p>,</span> <span class=s2>&#34;this&#34;</span><span class=p>,</span> <span class=s2>&#34;those&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;though&#34;</span><span class=p>,</span> <span class=s2>&#34;three&#34;</span><span class=p>,</span> <span class=s2>&#34;through&#34;</span><span class=p>,</span> <span class=s2>&#34;throughout&#34;</span><span class=p>,</span> <span class=s2>&#34;thru&#34;</span><span class=p>,</span> <span class=s2>&#34;thus&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;till&#34;</span><span class=p>,</span> <span class=s2>&#34;time&#34;</span><span class=p>,</span> <span class=s2>&#34;to&#34;</span><span class=p>,</span> <span class=s2>&#34;tons&#34;</span><span class=p>,</span> <span class=s2>&#34;top&#34;</span><span class=p>,</span> <span class=s2>&#34;toward&#34;</span><span class=p>,</span> <span class=s2>&#34;towards&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;two&#34;</span><span class=p>,</span> <span class=s2>&#34;under&#34;</span><span class=p>,</span> <span class=s2>&#34;underneath&#34;</span><span class=p>,</span> <span class=s2>&#34;unless&#34;</span><span class=p>,</span> <span class=s2>&#34;unlike&#34;</span><span class=p>,</span> <span class=s2>&#34;until&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;unto&#34;</span><span class=p>,</span> <span class=s2>&#34;up&#34;</span><span class=p>,</span> <span class=s2>&#34;upon&#34;</span><span class=p>,</span> <span class=s2>&#34;us&#34;</span><span class=p>,</span> <span class=s2>&#34;used&#34;</span><span class=p>,</span> <span class=s2>&#34;various&#34;</span><span class=p>,</span> <span class=s2>&#34;versus&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;via&#34;</span><span class=p>,</span> <span class=s2>&#34;view&#34;</span><span class=p>,</span> <span class=s2>&#34;wanting&#34;</span><span class=p>,</span> <span class=s2>&#34;was&#34;</span><span class=p>,</span> <span class=s2>&#34;we&#34;</span><span class=p>,</span> <span class=s2>&#34;were&#34;</span><span class=p>,</span> <span class=s2>&#34;what&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;whatever&#34;</span><span class=p>,</span> <span class=s2>&#34;when&#34;</span><span class=p>,</span> <span class=s2>&#34;whenever&#34;</span><span class=p>,</span> <span class=s2>&#34;where&#34;</span><span class=p>,</span> <span class=s2>&#34;whereas&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;wherever&#34;</span><span class=p>,</span> <span class=s2>&#34;whether&#34;</span><span class=p>,</span> <span class=s2>&#34;which&#34;</span><span class=p>,</span> <span class=s2>&#34;whichever&#34;</span><span class=p>,</span> <span class=s2>&#34;while&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;whilst&#34;</span><span class=p>,</span> <span class=s2>&#34;who&#34;</span><span class=p>,</span> <span class=s2>&#34;whoever&#34;</span><span class=p>,</span> <span class=s2>&#34;whole&#34;</span><span class=p>,</span> <span class=s2>&#34;whom&#34;</span><span class=p>,</span> <span class=s2>&#34;whomever&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;whose&#34;</span><span class=p>,</span> <span class=s2>&#34;will&#34;</span><span class=p>,</span> <span class=s2>&#34;with&#34;</span><span class=p>,</span> <span class=s2>&#34;within&#34;</span><span class=p>,</span> <span class=s2>&#34;without&#34;</span><span class=p>,</span> <span class=s2>&#34;would&#34;</span><span class=p>,</span> <span class=s2>&#34;yet&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=s2>&#34;you&#34;</span><span class=p>,</span> <span class=s2>&#34;your&#34;</span><span class=p>,</span> <span class=s2>&#34;yours&#34;</span><span class=p>,</span> <span class=s2>&#34;yourself&#34;</span><span class=p>,</span> <span class=s2>&#34;yourselves&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s1>&#39;__main__&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># 获取数据</span>
</span></span><span class=line><span class=cl>    <span class=n>documents</span><span class=p>,</span> <span class=n>classes</span> <span class=o>=</span> <span class=n>load_books_data</span><span class=p>(</span><span class=n>getdata</span><span class=o>.</span><span class=n>data_folder</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 提取特征词</span>
</span></span><span class=line><span class=cl>    <span class=n>extractor</span> <span class=o>=</span> <span class=n>CountVectorizer</span><span class=p>(</span><span class=n>vocabulary</span><span class=o>=</span><span class=n>function_words</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 参数字典</span>
</span></span><span class=line><span class=cl>    <span class=n>parameters</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;kernel&#39;</span><span class=p>:</span> <span class=p>(</span><span class=s1>&#39;linear&#39;</span><span class=p>,</span> <span class=s1>&#39;rbf&#39;</span><span class=p>),</span> <span class=s1>&#39;C&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>10</span><span class=p>]}</span>
</span></span><span class=line><span class=cl>    <span class=n>svr</span> <span class=o>=</span> <span class=n>SVC</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=c1># 使用网格搜索最优参数值</span>
</span></span><span class=line><span class=cl>    <span class=n>grid</span> <span class=o>=</span> <span class=n>GridSearchCV</span><span class=p>(</span><span class=n>svr</span><span class=p>,</span> <span class=n>parameters</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 使用功能词分类</span>
</span></span><span class=line><span class=cl>    <span class=n>pipeline1</span> <span class=o>=</span> <span class=n>Pipeline</span><span class=p>([(</span><span class=s1>&#39;feature_extraction&#39;</span><span class=p>,</span> <span class=n>extractor</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                          <span class=p>(</span><span class=s1>&#39;clf&#39;</span><span class=p>,</span> <span class=n>grid</span><span class=p>)])</span>
</span></span><span class=line><span class=cl>    <span class=n>scores</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>pipeline1</span><span class=p>,</span> <span class=n>documents</span><span class=p>,</span> <span class=n>classes</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;f1_macro&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>0.7738985477640941
Score: 0.813
</code></pre><h3 id=n-元语法>N 元语法</h3><p>N 元语法由一系列的 N 个为一组的对象组成，N 为每组对象的个数</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># 用N元语法分类</span>
</span></span><span class=line><span class=cl>    <span class=n>pipeline</span> <span class=o>=</span> <span class=n>Pipeline</span><span class=p>([(</span><span class=s1>&#39;feature_extraction&#39;</span><span class=p>,</span> <span class=n>CountVectorizer</span><span class=p>(</span><span class=n>analyzer</span><span class=o>=</span><span class=s1>&#39;char&#39;</span><span class=p>,</span> <span class=n>ngram_range</span><span class=o>=</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>3</span><span class=p>))),</span>  <span class=c1># 长度为3的N元语法</span>
</span></span><span class=line><span class=cl>                         <span class=p>(</span><span class=s1>&#39;classifier&#39;</span><span class=p>,</span> <span class=n>grid</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                         <span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>scores</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>pipeline</span><span class=p>,</span> <span class=n>documents</span><span class=p>,</span> <span class=n>classes</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;f1_macro&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Score: </span><span class=si>{:.3f}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>)))</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>Score: 0.813
</code></pre><h3 id=安然邮件数据集>安然邮件数据集</h3><ul><li>读取数据集</li><li>清洗数据</li><li>组装流水线</li><li>使用 F 值评估</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span><span class=lnt>70
</span><span class=lnt>71
</span><span class=lnt>72
</span><span class=lnt>73
</span><span class=lnt>74
</span><span class=lnt>75
</span><span class=lnt>76
</span><span class=lnt>77
</span><span class=lnt>78
</span><span class=lnt>79
</span><span class=lnt>80
</span><span class=lnt>81
</span><span class=lnt>82
</span><span class=lnt>83
</span><span class=lnt>84
</span><span class=lnt>85
</span><span class=lnt>86
</span><span class=lnt>87
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># -*- coding: utf-8 -*-</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>email.parser</span> <span class=kn>import</span> <span class=n>Parser</span>  <span class=c1># 邮件解析器</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.feature_extraction.text</span> <span class=kn>import</span> <span class=n>CountVectorizer</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>GridSearchCV</span><span class=p>,</span> <span class=n>cross_val_score</span><span class=p>,</span> <span class=n>train_test_split</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.pipeline</span> <span class=kn>import</span> <span class=n>Pipeline</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.svm</span> <span class=kn>import</span> <span class=n>SVC</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.utils</span> <span class=kn>import</span> <span class=n>check_random_state</span>  <span class=c1># 随机状态实例</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.metrics</span> <span class=kn>import</span> <span class=n>confusion_matrix</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>matplotlib</span> <span class=kn>import</span> <span class=n>pyplot</span> <span class=k>as</span> <span class=n>plt</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>quotequail</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>enron_data_folder</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>dirname</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>abspath</span><span class=p>(</span><span class=vm>__file__</span><span class=p>)),</span> <span class=s2>&#34;maildir&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s1>&#39;__main__&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>p</span> <span class=o>=</span> <span class=n>Parser</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>get_enron_corpus</span><span class=p>(</span><span class=n>num_authors</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>data_folder</span><span class=o>=</span><span class=n>enron_data_folder</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                         <span class=n>min_docs_author</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>max_docs_author</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                         <span class=n>random_state</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>random_state</span> <span class=o>=</span> <span class=n>check_random_state</span><span class=p>(</span><span class=n>random_state</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># 随机对得到的邮箱列表进行排序</span>
</span></span><span class=line><span class=cl>        <span class=c1># os.listdir函数每次返回结果不一定相同，在使用该函数前先排序，从而保持返回结果的一致性</span>
</span></span><span class=line><span class=cl>        <span class=n>email_addresses</span> <span class=o>=</span> <span class=nb>sorted</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>listdir</span><span class=p>(</span><span class=n>data_folder</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>random_state</span><span class=o>.</span><span class=n>shuffle</span><span class=p>(</span><span class=n>email_addresses</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>documents</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=n>classes</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=n>author_num</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>authors</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 遍历邮箱文件夹，查找它下面名字中含有“sent”的表示发件箱的子文件夹</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>user</span> <span class=ow>in</span> <span class=n>email_addresses</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>users_email_folder</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>data_folder</span><span class=p>,</span> <span class=n>user</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>mail_folders</span> <span class=o>=</span> <span class=p>[</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>users_email_folder</span><span class=p>,</span> <span class=n>subfolder</span><span class=p>)</span> <span class=k>for</span> <span class=n>subfolder</span> <span class=ow>in</span> <span class=n>os</span><span class=o>.</span><span class=n>listdir</span><span class=p>(</span><span class=n>users_email_folder</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                            <span class=k>if</span> <span class=s2>&#34;sent&#34;</span> <span class=ow>in</span> <span class=n>subfolder</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=c1># 获取子文件夹中的每一封邮件，跳过其中的子文件夹</span>
</span></span><span class=line><span class=cl>                <span class=n>authored_emails</span> <span class=o>=</span> <span class=p>[</span><span class=nb>open</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>mail_folder</span><span class=p>,</span> <span class=n>email_filename</span><span class=p>),</span> <span class=n>encoding</span><span class=o>=</span><span class=s1>&#39;cp1252&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>read</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                                   <span class=k>for</span> <span class=n>mail_folder</span> <span class=ow>in</span> <span class=n>mail_folders</span>
</span></span><span class=line><span class=cl>                                   <span class=k>for</span> <span class=n>email_filename</span> <span class=ow>in</span> <span class=n>os</span><span class=o>.</span><span class=n>listdir</span><span class=p>(</span><span class=n>mail_folder</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>            <span class=k>except</span> <span class=ne>IsADirectoryError</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>continue</span>
</span></span><span class=line><span class=cl>            <span class=c1># 获得至少十封邮件</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>authored_emails</span><span class=p>)</span> <span class=o>&lt;</span> <span class=n>min_docs_author</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>continue</span>
</span></span><span class=line><span class=cl>            <span class=c1># 最多获取前100封邮件</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>authored_emails</span><span class=p>)</span> <span class=o>&gt;</span> <span class=n>max_docs_author</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>authored_emails</span> <span class=o>=</span> <span class=n>authored_emails</span><span class=p>[:</span><span class=n>max_docs_author</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=c1># 解析邮件，获取邮件内容</span>
</span></span><span class=line><span class=cl>            <span class=n>contents</span> <span class=o>=</span> <span class=p>[</span><span class=n>p</span><span class=o>.</span><span class=n>parsestr</span><span class=p>(</span><span class=n>email</span><span class=p>)</span><span class=o>.</span><span class=n>_payload</span> <span class=k>for</span> <span class=n>email</span> <span class=ow>in</span> <span class=n>authored_emails</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=n>documents</span><span class=o>.</span><span class=n>extend</span><span class=p>(</span><span class=n>contents</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=c1># 将发件人添加到类列表中，每封邮件添加一次</span>
</span></span><span class=line><span class=cl>            <span class=n>classes</span><span class=o>.</span><span class=n>extend</span><span class=p>([</span><span class=n>author_num</span><span class=p>]</span> <span class=o>*</span> <span class=nb>len</span><span class=p>(</span><span class=n>authored_emails</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=c1># 记录收件人编号，再把编号+1</span>
</span></span><span class=line><span class=cl>            <span class=n>authors</span><span class=p>[</span><span class=n>user</span><span class=p>]</span> <span class=o>=</span> <span class=n>author_num</span>
</span></span><span class=line><span class=cl>            <span class=n>author_num</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>            <span class=c1># 收件人数量达到设置的值跳出循环</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>author_num</span> <span class=o>&gt;=</span> <span class=n>num_authors</span> <span class=ow>or</span> <span class=n>author_num</span> <span class=o>&gt;=</span> <span class=nb>len</span><span class=p>(</span><span class=n>email_addresses</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=k>break</span>
</span></span><span class=line><span class=cl>        <span class=c1># 返回邮件数据集以及收件人字典</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>documents</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>classes</span><span class=p>),</span> <span class=n>authors</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>documents</span><span class=p>,</span> <span class=n>classes</span><span class=p>,</span> <span class=n>authors</span> <span class=o>=</span> <span class=n>get_enron_corpus</span><span class=p>(</span><span class=n>data_folder</span><span class=o>=</span><span class=n>enron_data_folder</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>14</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 移除邮件的回复信息</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>remove_replies</span><span class=p>(</span><span class=n>email_contents</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>r</span> <span class=o>=</span> <span class=n>quotequail</span><span class=o>.</span><span class=n>unwrap</span><span class=p>(</span><span class=n>email_contents</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>r</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=n>email_contents</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=s1>&#39;text_top&#39;</span> <span class=ow>in</span> <span class=n>r</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=n>r</span><span class=p>[</span><span class=s1>&#39;text_top&#39;</span><span class=p>]</span>  <span class=c1># 字典r中存在text_top，返回它的值</span>
</span></span><span class=line><span class=cl>        <span class=k>elif</span> <span class=s1>&#39;text&#39;</span> <span class=ow>in</span> <span class=n>r</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=n>r</span><span class=p>[</span><span class=s1>&#39;text&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>email_contents</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>documents</span> <span class=o>=</span> <span class=p>[</span><span class=n>remove_replies</span><span class=p>(</span><span class=n>document</span><span class=p>)</span> <span class=k>for</span> <span class=n>document</span> <span class=ow>in</span> <span class=n>documents</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>parameters</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;kernel&#39;</span><span class=p>:</span> <span class=p>(</span><span class=s1>&#39;linear&#39;</span><span class=p>,</span> <span class=s1>&#39;rbf&#39;</span><span class=p>),</span> <span class=s1>&#39;C&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>10</span><span class=p>]}</span>
</span></span><span class=line><span class=cl>    <span class=n>svr</span> <span class=o>=</span> <span class=n>SVC</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>grid</span> <span class=o>=</span> <span class=n>GridSearchCV</span><span class=p>(</span><span class=n>svr</span><span class=p>,</span> <span class=n>parameters</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>pipeline</span> <span class=o>=</span> <span class=n>Pipeline</span><span class=p>([(</span><span class=s1>&#39;feature_extraction&#39;</span><span class=p>,</span> <span class=n>CountVectorizer</span><span class=p>(</span><span class=n>analyzer</span><span class=o>=</span><span class=s1>&#39;char&#39;</span><span class=p>,</span> <span class=n>ngram_range</span><span class=o>=</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>3</span><span class=p>))),</span>
</span></span><span class=line><span class=cl>                         <span class=p>(</span><span class=s1>&#39;classifier&#39;</span><span class=p>,</span> <span class=n>grid</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                         <span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>scores</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>pipeline</span><span class=p>,</span> <span class=n>documents</span><span class=p>,</span> <span class=n>classes</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;f1_macro&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Score: </span><span class=si>{:.3f}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>scores</span><span class=p>)))</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>Score: 0.664
</code></pre><hr><p>从流水线中获得最好的参数组合</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=n>training_documents</span><span class=p>,</span> <span class=n>test_documents</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span><span class=n>documents</span><span class=p>,</span> <span class=n>classes</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>14</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>pipeline</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>training_documents</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y_pred</span> <span class=o>=</span> <span class=n>pipeline</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>test_documents</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>pipeline</span><span class=o>.</span><span class=n>named_steps</span><span class=p>[</span><span class=s1>&#39;classifier&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>best_params_</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>{'C': 10, 'kernel': 'rbf'}
</code></pre><hr><p>绘制混淆矩阵查看分类情况</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=n>cm</span> <span class=o>=</span> <span class=n>confusion_matrix</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>cm</span> <span class=o>=</span> <span class=n>cm</span> <span class=o>/</span> <span class=n>cm</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>float</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>sorted_authors</span> <span class=o>=</span> <span class=nb>sorted</span><span class=p>(</span><span class=n>authors</span><span class=o>.</span><span class=n>keys</span><span class=p>(),</span> <span class=n>key</span><span class=o>=</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=n>authors</span><span class=p>[</span><span class=n>x</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>20</span><span class=p>,</span> <span class=mi>20</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>cm</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=s1>&#39;Blues&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>tick_marks</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>sorted_authors</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>xticks</span><span class=p>(</span><span class=n>tick_marks</span><span class=p>,</span> <span class=n>sorted_authors</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>yticks</span><span class=p>(</span><span class=n>tick_marks</span><span class=p>,</span> <span class=n>sorted_authors</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Actual&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Predicted&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/img/in-post/data-mining/ch9/myplot9.1.png data-srcset="/img/in-post/data-mining/ch9/myplot9.1.png, /img/in-post/data-mining/ch9/myplot9.1.png 1.5x, /img/in-post/data-mining/ch9/myplot9.1.png 2x" data-sizes=auto alt=/img/in-post/data-mining/ch9/myplot9.1.png title=9.1></p><h2 id=第十章>第十章</h2><p>这两天在鼓捣 jupyterlab，一开始在服务器上建了一个 lab 环境，可每次连接都要登上几分钟，不知道是服务器 CPU 不行还是网络不行。然后又在本地鼓捣，在 debian 装 nodejs 和 npm 的时候把系统依赖搞崩了，于是狠下心来重装了电脑。。。发生的事情太多，心累。。</p><p>昨天重装了 Ubuntu，搞了下美化，安装了必须的软件（别说 Ubuntu 还挺好用，真香）</p><p>我保证这是最后一句吐槽了，一定</p><p>本章介绍如何对新闻语料进行聚类，以发现其中的趋势和主题。</p><h3 id=获取新闻文章>获取新闻文章</h3><p>这一章的数据集是从 reddit 获得的网页链接，reddit 的 app 审核机制不是很严格(?)因此我终于拿到了墙外的 api，使用 requests 下载又费了一番功夫，使用书上源码的 url 下载总是 403 错误，研究了好半天 reddit 的 api，发现 reddit 的 url 改成了(new, top, &mldr;)，修改之后总算完成了链接的索引</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span><span class=lnt>70
</span><span class=lnt>71
</span><span class=lnt>72
</span><span class=lnt>73
</span><span class=lnt>74
</span><span class=lnt>75
</span><span class=lnt>76
</span><span class=lnt>77
</span><span class=lnt>78
</span><span class=lnt>79
</span><span class=lnt>80
</span><span class=lnt>81
</span><span class=lnt>82
</span><span class=lnt>83
</span><span class=lnt>84
</span><span class=lnt>85
</span><span class=lnt>86
</span><span class=lnt>87
</span><span class=lnt>88
</span><span class=lnt>89
</span><span class=lnt>90
</span><span class=lnt>91
</span><span class=lnt>92
</span><span class=lnt>93
</span><span class=lnt>94
</span><span class=lnt>95
</span><span class=lnt>96
</span><span class=lnt>97
</span><span class=lnt>98
</span><span class=lnt>99
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># get_links.py</span>
</span></span><span class=line><span class=cl><span class=c1># -*- coding: utf-8 -*-</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>json</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>requests</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>getpass</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>time</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 需要的一些凭证</span>
</span></span><span class=line><span class=cl><span class=n>CLIENT_ID</span> <span class=o>=</span> <span class=s2>&#34;xxxxxxxxxxx&#34;</span>
</span></span><span class=line><span class=cl><span class=n>CLIENT_SECRET</span> <span class=o>=</span> <span class=s2>&#34;xxxxxxxxxxx&#34;</span>
</span></span><span class=line><span class=cl><span class=n>USER_AGENT</span> <span class=o>=</span> <span class=s2>&#34;python:xxxxxxxxx (by /u/xxxxxxxxx)&#34;</span>
</span></span><span class=line><span class=cl><span class=n>USERNAME</span> <span class=o>=</span> <span class=s2>&#34;xxxxxxxx&#34;</span>
</span></span><span class=line><span class=cl><span class=n>PASSWORD</span> <span class=o>=</span> <span class=s2>&#34;xxxxxxxxxxxxxx&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># requests使用代理</span>
</span></span><span class=line><span class=cl><span class=n>proxies</span> <span class=o>=</span> <span class=p>{</span><span class=s2>&#34;http&#34;</span><span class=p>:</span> <span class=s2>&#34;socks5://xxxxxx&#34;</span><span class=p>,</span> <span class=s2>&#34;https&#34;</span><span class=p>:</span> <span class=s2>&#34;socks5://xxxxxx&#34;</span><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>login</span><span class=p>(</span><span class=n>username</span><span class=p>,</span> <span class=n>password</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>password</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>password</span> <span class=o>=</span> <span class=n>getpass</span><span class=o>.</span><span class=n>getpass</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;Enter reddit password for user </span><span class=si>{}</span><span class=s2>: &#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>username</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>headers</span> <span class=o>=</span> <span class=p>{</span><span class=s2>&#34;User-Agent&#34;</span><span class=p>:</span> <span class=n>USER_AGENT</span><span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=c1># 使用凭据设置身份验证对象</span>
</span></span><span class=line><span class=cl>    <span class=n>client_auth</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>auth</span><span class=o>.</span><span class=n>HTTPBasicAuth</span><span class=p>(</span><span class=n>CLIENT_ID</span><span class=p>,</span> <span class=n>CLIENT_SECRET</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>post_data</span> <span class=o>=</span> <span class=p>{</span><span class=s2>&#34;grant_type&#34;</span><span class=p>:</span> <span class=s2>&#34;password&#34;</span><span class=p>,</span> <span class=s2>&#34;username&#34;</span><span class=p>:</span> <span class=n>username</span><span class=p>,</span> <span class=s2>&#34;password&#34;</span><span class=p>:</span> <span class=n>password</span><span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=n>response</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>post</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;https://www.reddit.com/api/v1/access_token&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>proxies</span><span class=o>=</span><span class=n>proxies</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>auth</span><span class=o>=</span><span class=n>client_auth</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>data</span><span class=o>=</span><span class=n>post_data</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>headers</span><span class=o>=</span><span class=n>headers</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>response</span><span class=o>.</span><span class=n>json</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># 调用login获取token</span>
</span></span><span class=line><span class=cl>    <span class=c1># token = login(USERNAME, PASSWORD)</span>
</span></span><span class=line><span class=cl>    <span class=c1># print(token)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>token</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;access_token&#34;</span><span class=p>:</span> <span class=s2>&#34;xxxxxxxxxxxxxxxxxxxxxxxx&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;token_type&#34;</span><span class=p>:</span> <span class=s2>&#34;xxxxx&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;expires_in&#34;</span><span class=p>:</span> <span class=mi>3600</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;scope&#34;</span><span class=p>:</span> <span class=s2>&#34;*&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>get_links</span><span class=p>(</span><span class=n>subreddit</span><span class=p>,</span> <span class=n>token</span><span class=p>,</span> <span class=n>n_pages</span><span class=o>=</span><span class=mi>5</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 存放链接信息</span>
</span></span><span class=line><span class=cl>        <span class=n>stories</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=n>after</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>page_number</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_pages</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=c1># 进行调用之前等待，以避免超过API限制</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;等待2s...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>time</span><span class=o>.</span><span class=n>sleep</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=c1># 设置标头进行调用</span>
</span></span><span class=line><span class=cl>            <span class=n>headers</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;Authorization&#34;</span><span class=p>:</span> <span class=s2>&#34;bearer </span><span class=si>{}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>token</span><span class=p>[</span><span class=s2>&#34;access_token&#34;</span><span class=p>]),</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;User-Agent&#34;</span><span class=p>:</span> <span class=n>USER_AGENT</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span>
</span></span><span class=line><span class=cl>            <span class=c1># top为最热链接，这里也可以换成new</span>
</span></span><span class=line><span class=cl>            <span class=n>url</span> <span class=o>=</span> <span class=s2>&#34;https://oauth.reddit.com/r/</span><span class=si>{}</span><span class=s2>/top?limit=100&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>subreddit</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>after</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>url</span> <span class=o>+=</span> <span class=s2>&#34;&amp;after=</span><span class=si>{}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>after</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>while</span> <span class=kc>True</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=n>response</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>get</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                        <span class=n>url</span><span class=p>,</span> <span class=n>proxies</span><span class=o>=</span><span class=n>proxies</span><span class=p>,</span> <span class=n>headers</span><span class=o>=</span><span class=n>headers</span><span class=p>,</span> <span class=n>timeout</span><span class=o>=</span><span class=mi>10</span>
</span></span><span class=line><span class=cl>                    <span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>result</span> <span class=o>=</span> <span class=n>response</span><span class=o>.</span><span class=n>json</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                    <span class=c1># 获取下一个循环的cursor</span>
</span></span><span class=line><span class=cl>                    <span class=n>after</span> <span class=o>=</span> <span class=n>result</span><span class=p>[</span><span class=s2>&#34;data&#34;</span><span class=p>][</span><span class=s2>&#34;after&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                <span class=k>except</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;requests出错等待...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>time</span><span class=o>.</span><span class=n>sleep</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=k>break</span>
</span></span><span class=line><span class=cl>            <span class=c1># 将所有新闻项添加到story列表中</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>story</span> <span class=ow>in</span> <span class=n>result</span><span class=p>[</span><span class=s2>&#34;data&#34;</span><span class=p>][</span><span class=s2>&#34;children&#34;</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>                <span class=n>stories</span><span class=o>.</span><span class=n>append</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                    <span class=p>(</span>
</span></span><span class=line><span class=cl>                        <span class=n>story</span><span class=p>[</span><span class=s2>&#34;data&#34;</span><span class=p>][</span><span class=s2>&#34;title&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                        <span class=n>story</span><span class=p>[</span><span class=s2>&#34;data&#34;</span><span class=p>][</span><span class=s2>&#34;url&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                        <span class=n>story</span><span class=p>[</span><span class=s2>&#34;data&#34;</span><span class=p>][</span><span class=s2>&#34;score&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                    <span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>stories</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>stories</span> <span class=o>=</span> <span class=n>get_links</span><span class=p>(</span><span class=s2>&#34;worldnews&#34;</span><span class=p>,</span> <span class=n>token</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>base_folder</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>dirname</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>abspath</span><span class=p>(</span><span class=vm>__file__</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>data_folder</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>base_folder</span><span class=p>,</span> <span class=s2>&#34;raw&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 这里我将所有的链接都存在了文件里，因为获取这些网站的内容要很久</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>base_folder</span><span class=p>,</span> <span class=s2>&#34;stories2.txt&#34;</span><span class=p>),</span> <span class=s2>&#34;w&#34;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>link</span> <span class=ow>in</span> <span class=n>stories</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>f</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>json</span><span class=o>.</span><span class=n>dumps</span><span class=p>(</span><span class=nb>list</span><span class=p>(</span><span class=n>link</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>            <span class=n>f</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=从网站抽取文本>从网站抽取文本</h3><p>api/top 总共有 500 个网站，我又获取了 api/new 的 490 个，总共下载了半个小时，失败了 300。。。</p><p>最后成功下载的网站数为 365</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># get_data.py</span>
</span></span><span class=line><span class=cl><span class=c1># -*- coding: utf-8 -*-</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>hashlib</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>requests</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>json</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>proxies</span> <span class=o>=</span> <span class=p>{</span><span class=s2>&#34;http&#34;</span><span class=p>:</span> <span class=s2>&#34;socks5://xxxxxxxxxxxx&#34;</span><span class=p>,</span> <span class=s2>&#34;https&#34;</span><span class=p>:</span> <span class=s2>&#34;socks5://xxxxxxxxxxxxx&#34;</span><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>base_folder</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>dirname</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>abspath</span><span class=p>(</span><span class=vm>__file__</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>data_folder</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>base_folder</span><span class=p>,</span> <span class=s2>&#34;raw&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 读取链接数据</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>base_folder</span><span class=p>,</span> <span class=s2>&#34;stories1.txt&#34;</span><span class=p>),</span> <span class=s2>&#34;r&#34;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>temp</span> <span class=o>=</span> <span class=n>f</span><span class=o>.</span><span class=n>readlines</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>stories</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>l</span> <span class=ow>in</span> <span class=n>temp</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>stories</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>json</span><span class=o>.</span><span class=n>loads</span><span class=p>(</span><span class=n>l</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 获取网页内容</span>
</span></span><span class=line><span class=cl>    <span class=n>number_errors</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>title</span><span class=p>,</span> <span class=n>url</span><span class=p>,</span> <span class=n>score</span> <span class=ow>in</span> <span class=n>stories</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=n>url</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>output_filename</span> <span class=o>=</span> <span class=n>hashlib</span><span class=o>.</span><span class=n>md5</span><span class=p>(</span><span class=n>url</span><span class=o>.</span><span class=n>encode</span><span class=p>())</span><span class=o>.</span><span class=n>hexdigest</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>fullpath</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>data_folder</span><span class=p>,</span> <span class=n>output_filename</span> <span class=o>+</span> <span class=s2>&#34;.txt&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>response</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>url</span><span class=p>,</span> <span class=n>proxies</span><span class=o>=</span><span class=n>proxies</span><span class=p>,</span> <span class=n>timeout</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>data</span> <span class=o>=</span> <span class=n>response</span><span class=o>.</span><span class=n>text</span>
</span></span><span class=line><span class=cl>            <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>fullpath</span><span class=p>,</span> <span class=s2>&#34;w&#34;</span><span class=p>)</span> <span class=k>as</span> <span class=n>outf</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>outf</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>number_errors</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>            <span class=c1># 输出出错数量</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;出错：</span><span class=si>{}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>number_errors</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><hr><p>下载下来的网页全是 html 文件，要从中提取出有用的信息，这里使用较为通用的 lxml 库，其它处理 html 的库还有 BeautifulSoup 等。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># get_content.py</span>
</span></span><span class=line><span class=cl><span class=c1># -*- coding: utf-8 -*-</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>lxml</span> <span class=kn>import</span> <span class=n>html</span><span class=p>,</span> <span class=n>etree</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>base_folder</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>dirname</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>abspath</span><span class=p>(</span><span class=vm>__file__</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>data_folder</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>base_folder</span><span class=p>,</span> <span class=s2>&#34;raw&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 输出变成纯文本文件的路径</span>
</span></span><span class=line><span class=cl>    <span class=n>text_output_folder</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>base_folder</span><span class=p>,</span> <span class=s2>&#34;textonly&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>filenames</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>data_folder</span><span class=p>,</span> <span class=n>filename</span><span class=p>)</span> <span class=k>for</span> <span class=n>filename</span> <span class=ow>in</span> <span class=n>os</span><span class=o>.</span><span class=n>listdir</span><span class=p>(</span><span class=n>data_folder</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=c1># 存放不可能包含新闻内容的节点</span>
</span></span><span class=line><span class=cl>    <span class=n>skip_node_types</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&#34;script&#34;</span><span class=p>,</span> <span class=s2>&#34;head&#34;</span><span class=p>,</span> <span class=s2>&#34;style&#34;</span><span class=p>,</span> <span class=n>etree</span><span class=o>.</span><span class=n>Comment</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=c1># 把html文件解析成lxml对象</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>get_text_from_file</span><span class=p>(</span><span class=n>filename</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>filename</span><span class=p>,</span> <span class=s2>&#34;r&#34;</span><span class=p>)</span> <span class=k>as</span> <span class=n>inf</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>html_tree</span> <span class=o>=</span> <span class=n>html</span><span class=o>.</span><span class=n>parse</span><span class=p>(</span><span class=n>inf</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>get_text_from_node</span><span class=p>(</span><span class=n>html_tree</span><span class=o>.</span><span class=n>getroot</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 抽取子节点中的文本内容，最后返回拼接在一起的所有子节点的文本</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>get_text_from_node</span><span class=p>(</span><span class=n>node</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>node</span><span class=p>)</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># 没有子节点，直接返回内容</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>node</span><span class=o>.</span><span class=n>text</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>return</span> <span class=n>node</span><span class=o>.</span><span class=n>text</span>
</span></span><span class=line><span class=cl>            <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>return</span> <span class=s2>&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># 有子节点，递归调用得到内容</span>
</span></span><span class=line><span class=cl>            <span class=n>results</span> <span class=o>=</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>get_text_from_node</span><span class=p>(</span><span class=n>child</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=k>for</span> <span class=n>child</span> <span class=ow>in</span> <span class=n>node</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=n>child</span><span class=o>.</span><span class=n>tag</span> <span class=ow>not</span> <span class=ow>in</span> <span class=n>skip_node_types</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>result</span> <span class=o>=</span> <span class=nb>str</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>,</span> <span class=p>(</span><span class=n>r</span> <span class=k>for</span> <span class=n>r</span> <span class=ow>in</span> <span class=n>results</span> <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>r</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=c1># 检查文本长度</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>result</span><span class=p>)</span> <span class=o>&gt;=</span> <span class=mi>100</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=n>result</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=s2>&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>filename</span> <span class=ow>in</span> <span class=n>os</span><span class=o>.</span><span class=n>listdir</span><span class=p>(</span><span class=n>data_folder</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>text</span> <span class=o>=</span> <span class=n>get_text_from_file</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>data_folder</span><span class=p>,</span> <span class=n>filename</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>text_output_folder</span><span class=p>,</span> <span class=n>filename</span><span class=p>),</span> <span class=s2>&#34;w&#34;</span><span class=p>)</span> <span class=k>as</span> <span class=n>outf</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>outf</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=新闻语料聚类>新闻语料聚类</h3><p>k-means 算法</p><p>k-means 聚类算法迭代寻找最能够代表数据的聚类质心点。算法开始时使用从训练数据中随机选取的几个数据点作为质心点。k-means 中的 k 表示寻找多少个质心点，同时也是算法将会找到的簇的数量。步骤：</p><ul><li>为每一个数据点分配簇标签<br>为每个个体设置一个标签，将它和最近的质心点联系起来，标签相同的个体属于同一个簇</li><li>更新各簇的质心点</li></ul><p>每次更新质心点时，所有质心点将会小范围移动，这会轻微改变每个数据点在簇内的位置，从而引发下一次迭代时质心点的变动</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># -*- coding: utf-8 -*-</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.cluster</span> <span class=kn>import</span> <span class=n>KMeans</span>
</span></span><span class=line><span class=cl><span class=c1># TfidfVectorizer向量化工具，根据词语出现在多少篇文章中，对词语计数进行加权</span>
</span></span><span class=line><span class=cl><span class=c1># 出现在较多文档中的词语权重较低（用文档集数量除以词语出现在的文档的数量，然后取对数）</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.feature_extraction.text</span> <span class=kn>import</span> <span class=n>TfidfVectorizer</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.pipeline</span> <span class=kn>import</span> <span class=n>Pipeline</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>collections</span> <span class=kn>import</span> <span class=n>Counter</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>scipy.sparse</span> <span class=kn>import</span> <span class=n>csr_matrix</span>  <span class=c1># 稀疏矩阵</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>scipy.sparse.csgraph</span> <span class=kn>import</span> <span class=n>minimum_spanning_tree</span>  <span class=c1># 计算最小生成树MST</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>scipy.sparse.csgraph</span> <span class=kn>import</span> <span class=n>connected_components</span>  <span class=c1># 连通分支</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.base</span> <span class=kn>import</span> <span class=n>BaseEstimator</span><span class=p>,</span> <span class=n>ClusterMixin</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.cluster</span> <span class=kn>import</span> <span class=n>MiniBatchKMeans</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.feature_extraction.text</span> <span class=kn>import</span> <span class=n>HashingVectorizer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>base_folder</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>dirname</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>abspath</span><span class=p>(</span><span class=vm>__file__</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>data_folder</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>base_folder</span><span class=p>,</span> <span class=s2>&#34;raw&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>text_output_folder</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>base_folder</span><span class=p>,</span> <span class=s2>&#34;textonly&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># 分簇的数量</span>
</span></span><span class=line><span class=cl>    <span class=n>n_clusters</span> <span class=o>=</span> <span class=mi>10</span>
</span></span><span class=line><span class=cl>    <span class=n>pipeline</span> <span class=o>=</span> <span class=n>Pipeline</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=p>(</span><span class=s2>&#34;feature_extraction&#34;</span><span class=p>,</span> <span class=n>TfidfVectorizer</span><span class=p>(</span><span class=n>max_df</span><span class=o>=</span><span class=mf>0.4</span><span class=p>)),</span>  <span class=c1># 特征抽取，忽略出现在40%文档中的词语（删除功能词）</span>
</span></span><span class=line><span class=cl>            <span class=p>(</span><span class=s2>&#34;clusterer&#34;</span><span class=p>,</span> <span class=n>KMeans</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=n>n_clusters</span><span class=p>)),</span>  <span class=c1># 调用k-means算法</span>
</span></span><span class=line><span class=cl>        <span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>documents</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=nb>open</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>text_output_folder</span><span class=p>,</span> <span class=n>filename</span><span class=p>))</span><span class=o>.</span><span class=n>read</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>filename</span> <span class=ow>in</span> <span class=n>os</span><span class=o>.</span><span class=n>listdir</span><span class=p>(</span><span class=n>text_output_folder</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=c1># 不为fit函数指定目标类别，进行训练</span>
</span></span><span class=line><span class=cl>    <span class=n>pipeline</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>documents</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 使用训练过的算法预测</span>
</span></span><span class=line><span class=cl>    <span class=c1># labels包含每个数据点的簇标签，标签相同的数据点属于同一个簇，标签本身没有含义</span>
</span></span><span class=line><span class=cl>    <span class=n>labels</span> <span class=o>=</span> <span class=n>pipeline</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>documents</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 使用Counter类查看每个簇的数据点数量</span>
</span></span><span class=line><span class=cl>    <span class=n>c</span> <span class=o>=</span> <span class=n>Counter</span><span class=p>(</span><span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>cluster_number</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_clusters</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;Cluster </span><span class=si>{}</span><span class=s2> contains </span><span class=si>{}</span><span class=s2> samples&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>cluster_number</span><span class=p>,</span> <span class=n>c</span><span class=p>[</span><span class=n>cluster_number</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>Cluster 0 contains 2 samples
Cluster 1 contains 4 samples
Cluster 2 contains 1 samples
Cluster 3 contains 2 samples
Cluster 4 contains 329 samples
Cluster 5 contains 7 samples
Cluster 6 contains 2 samples
Cluster 7 contains 13 samples
Cluster 8 contains 3 samples
Cluster 9 contains 2 samples
</code></pre><hr><p>聚类分析主要是探索性分析，因此很难有效地评估结果的好坏，如果有测试集，可以对其分析来评价效果</p><p>对于 k-means 算法，寻找新质心点的标准是，最小化每个数据点到最近质心点的距离。这叫作算法的惯性权重（inertia），任何经过训练的 KMeans 实例都有该属性</p><p>下面将 n_clusters 依次取 2 到 20 之间的值，每取一个值，k-means 算法运行 10 次。每次运行算法都记录惯性权重。</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># 惯性权重，这个值没有意义，但是可以用来确定n_clusters</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>pipeline</span><span class=o>.</span><span class=n>named_steps</span><span class=p>[</span><span class=s2>&#34;clusterer&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>inertia_</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>inertia_scores</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>n_clusters_values</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>20</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>n_clusters</span> <span class=ow>in</span> <span class=n>n_clusters_values</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># 当前的惯性权重组</span>
</span></span><span class=line><span class=cl>        <span class=n>cur_inertia_scores</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=n>X</span> <span class=o>=</span> <span class=n>TfidfVectorizer</span><span class=p>(</span><span class=n>max_df</span><span class=o>=</span><span class=mf>0.4</span><span class=p>)</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>documents</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>10</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>km</span> <span class=o>=</span> <span class=n>KMeans</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=n>n_clusters</span><span class=p>)</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>cur_inertia_scores</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>km</span><span class=o>.</span><span class=n>inertia_</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>inertia_scores</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>cur_inertia_scores</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=si>{}</span><span class=s2> : </span><span class=si>{}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>n_clusters</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>cur_inertia_scores</span><span class=p>)))</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>291.45747555507467

2 : 310.72961350285766
3 : 305.7904332223444
4 : 302.18859768191396
5 : 300.28785590112705
6 : 297.48005120447067
7 : 294.226862724111
8 : 292.340968109182
9 : 291.18707107605024
10 : 289.46981977256536
11 : 287.9333326469133
12 : 285.0561596766078
13 : 284.33745019948356
14 : 282.71178879028537
15 : 280.94991762471807
16 : 279.9555799316599
17 : 278.3825941905214
18 : 274.94616060558434
19 : 275.0297854253871
</code></pre><hr><p>将上表作图</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=kn>import</span> <span class=nn>plotly</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span> <span class=o>=</span> <span class=n>plotly</span><span class=o>.</span><span class=n>graph_objs</span><span class=o>.</span><span class=n>Scatter</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span><span class=o>=</span><span class=nb>list</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=mi>18</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=mf>310.73</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=mf>305.79</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=mf>302.18</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=mf>300.28</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=mf>297.48</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=mf>294.22</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=mf>292.34</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=mf>291.18</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=mf>289.46</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=mf>287.93</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=mf>285.05</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=mf>284.33</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=mf>282.71</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=mf>280.94</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=mf>279.95</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=mf>278.38</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=mf>274.94</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=mf>275.02</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>fig</span> <span class=o>=</span> <span class=n>plotly</span><span class=o>.</span><span class=n>graph_objs</span><span class=o>.</span><span class=n>Figure</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>fig</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/img/in-post/data-mining/ch10/10.1.png data-srcset="/img/in-post/data-mining/ch10/10.1.png, /img/in-post/data-mining/ch10/10.1.png 1.5x, /img/in-post/data-mining/ch10/10.1.png 2x" data-sizes=auto alt=/img/in-post/data-mining/ch10/10.1.png title=10.1></p><hr><p>根据上图可以发现在 n_clusters=9 和 15 时拐点比较明显，这里为了方便计算，我们按照书上选择 6</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># 设置n_clusters值为6， 重新运行算法</span>
</span></span><span class=line><span class=cl>    <span class=n>n_clusters</span> <span class=o>=</span> <span class=mi>6</span>
</span></span><span class=line><span class=cl>    <span class=n>pipeline</span> <span class=o>=</span> <span class=n>Pipeline</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=p>(</span><span class=s2>&#34;feature_extraction&#34;</span><span class=p>,</span> <span class=n>TfidfVectorizer</span><span class=p>(</span><span class=n>max_df</span><span class=o>=</span><span class=mf>0.4</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>            <span class=p>(</span><span class=s2>&#34;clusterer&#34;</span><span class=p>,</span> <span class=n>KMeans</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=n>n_clusters</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>        <span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>pipeline</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>documents</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>labels</span> <span class=o>=</span> <span class=n>pipeline</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>documents</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 获取特征的所对应的词</span>
</span></span><span class=line><span class=cl>    <span class=n>terms</span> <span class=o>=</span> <span class=n>pipeline</span><span class=o>.</span><span class=n>named_steps</span><span class=p>[</span><span class=s2>&#34;feature_extraction&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>get_feature_names</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=c1># 统计6个簇中每个簇的元素个数</span>
</span></span><span class=line><span class=cl>    <span class=n>c</span> <span class=o>=</span> <span class=n>Counter</span><span class=p>(</span><span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>cluster_number</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_clusters</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;Cluster </span><span class=si>{}</span><span class=s2> contains </span><span class=si>{}</span><span class=s2> samples&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>cluster_number</span><span class=p>,</span> <span class=n>c</span><span class=p>[</span><span class=n>cluster_number</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34; Most important terms&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>centroid</span> <span class=o>=</span> <span class=n>pipeline</span><span class=o>.</span><span class=n>named_steps</span><span class=p>[</span><span class=s2>&#34;clusterer&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>cluster_centers_</span><span class=p>[</span><span class=n>cluster_number</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>most_important</span> <span class=o>=</span> <span class=n>centroid</span><span class=o>.</span><span class=n>argsort</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>5</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=c1># 排列是非降序排列</span>
</span></span><span class=line><span class=cl>            <span class=n>term_index</span> <span class=o>=</span> <span class=n>most_important</span><span class=p>[</span><span class=o>-</span><span class=p>(</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>            <span class=c1># 输出序号，词语，得分</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34; </span><span class=si>{0}</span><span class=s2> </span><span class=si>{1}</span><span class=s2> (score: </span><span class=si>{2:.4f}</span><span class=s2>)&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                    <span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>,</span> <span class=n>terms</span><span class=p>[</span><span class=n>term_index</span><span class=p>],</span> <span class=n>centroid</span><span class=p>[</span><span class=n>term_index</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                <span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>Cluster 0 contains 15 samples
Most important terms
1 games (score: 0.2351)
2 olympic (score: 0.1921)
3 athletes (score: 0.1555)
4 ioc (score: 0.1383)
5 tokyo (score: 0.1365)
Cluster 1 contains 48 samples
Most important terms
1 she (score: 0.0442)
2 her (score: 0.0409)
3 masks (score: 0.0381)
4 monday (score: 0.0298)
5 23 (score: 0.0294)
Cluster 2 contains 150 samples
Most important terms
1 you (score: 0.0342)
2 measures (score: 0.0246)
3 would (score: 0.0246)
4 country (score: 0.0233)
5 our (score: 0.0231)
Cluster 3 contains 14 samples
Most important terms
1 your (score: 0.1922)
2 you (score: 0.1833)
3 robot (score: 0.1644)
4 unusual (score: 0.1505)
5 box (score: 0.1478)
Cluster 4 contains 128 samples
Most important terms
1 india (score: 0.0222)
2 et (score: 0.0189)
3 tablet (score: 0.0156)
4 app (score: 0.0140)
5 2020 (score: 0.0129)
Cluster 5 contains 10 samples
Most important terms
1 cache (score: 0.2858)
2 found (score: 0.2672)
3 server (score: 0.2484)
4 error (score: 0.2358)
5 mod_security (score: 0.1450)
</code></pre><hr><p>上面代码在流水线最后一步的 k-means 实例上调用转换方法。得到的矩阵有六个特征，数据量跟文档的长度相同，shape=(365,6)</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># 用K-means算法转化特征</span>
</span></span><span class=line><span class=cl>    <span class=n>X</span> <span class=o>=</span> <span class=n>pipeline</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>documents</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=聚类融合>聚类融合</h3><p>聚类算法也可以进行融合，这样做的主要原因是，融合后得到的算法能够平滑算法多次运行所得到的不同结果。多次运行 k-means 算法得到的结果因最初选择的质心点不同而不同。多次运行算法，综合考虑所得到的多个结果，可以减少波动。聚类融合方法还可以降低参数选择对最终结果的影响。大多数聚类算法对参数选择很敏感,参数稍有不同将带来不同的聚类结果</p><p>最基本的融合方法是对数据进行多次聚类，每次都记录各个数据点的簇标签。然后计算每两个数据点被分到同一个簇的次数。这就是<em>证据累积</em>算法（Evidence Accumulation Clustering，EAC）的精髓</p><ul><li>第一步，使用 k-means 等低水平的聚类算法对数据集进行多次聚类，记录每一次迭代两个数据点出现在同一簇的频率，将结果保存到共协矩阵（coassociation）中</li><li>第二步，使用另外一种聚类算法——分级聚类对第一步得到的共协矩阵进行聚类分析。分级聚类一个比较有趣的特性是，它等价于寻找一棵把所有节点连接到一起的树，并把权重低的边去掉。</li></ul><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># 遍历所有标签，记录具有相同标签的两个数据点的位置，创建共协矩阵</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>create_coassociation_matrix</span><span class=p>(</span><span class=n>labels</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>rows</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=n>cols</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=c1># labels种类</span>
</span></span><span class=line><span class=cl>        <span class=n>unique_labels</span> <span class=o>=</span> <span class=nb>set</span><span class=p>(</span><span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>label</span> <span class=ow>in</span> <span class=n>unique_labels</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># 找出label值相同的数据点</span>
</span></span><span class=line><span class=cl>            <span class=n>indices</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>where</span><span class=p>(</span><span class=n>labels</span> <span class=o>==</span> <span class=n>label</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=c1># 记录他们的位置：如1、3点的数据均为1，即1和1相同，1和3相同，3和1相同，3和3相同</span>
</span></span><span class=line><span class=cl>            <span class=c1># 行和列均增加了4个indices*indices个数字</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>index1</span> <span class=ow>in</span> <span class=n>indices</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>for</span> <span class=n>index2</span> <span class=ow>in</span> <span class=n>indices</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=n>rows</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>index1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>cols</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>index2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># 返回给定shape和type的值全为1的矩阵</span>
</span></span><span class=line><span class=cl>        <span class=n>data</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>ones</span><span class=p>((</span><span class=nb>len</span><span class=p>(</span><span class=n>rows</span><span class=p>),))</span>
</span></span><span class=line><span class=cl>        <span class=c1># 创建稀疏矩阵满足：a[rows[k], cols[k]] = data[k]</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>csr_matrix</span><span class=p>((</span><span class=n>data</span><span class=p>,</span> <span class=p>(</span><span class=n>rows</span><span class=p>,</span> <span class=n>cols</span><span class=p>)),</span> <span class=n>dtype</span><span class=o>=</span><span class=s2>&#34;float&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 使用标签生成共协矩阵</span>
</span></span><span class=line><span class=cl>    <span class=n>C</span> <span class=o>=</span> <span class=n>create_coassociation_matrix</span><span class=p>(</span><span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 这里书上说多输入几次C看看结果，我没有用notebook，但是使用print输出是一样的，因此没有搞懂书上的含义</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>C</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>((</span><span class=mi>365</span> <span class=o>**</span> <span class=mi>2</span> <span class=o>-</span> <span class=n>create_coassociation_matrix</span><span class=p>(</span><span class=n>labels</span><span class=p>)</span><span class=o>.</span><span class=n>nnz</span><span class=p>)</span> <span class=o>/</span> <span class=mi>365</span> <span class=o>**</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>mst</span> <span class=o>=</span> <span class=n>minimum_spanning_tree</span><span class=p>(</span><span class=n>C</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>mst</span> <span class=o>=</span> <span class=n>minimum_spanning_tree</span><span class=p>(</span><span class=o>-</span><span class=n>C</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>pipeline</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>documents</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>labels2</span> <span class=o>=</span> <span class=n>pipeline</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>documents</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>C2</span> <span class=o>=</span> <span class=n>create_coassociation_matrix</span><span class=p>(</span><span class=n>labels2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>C_sum</span> <span class=o>=</span> <span class=p>(</span><span class=n>C</span> <span class=o>+</span> <span class=n>C2</span><span class=p>)</span> <span class=o>/</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl>    <span class=n>mst</span> <span class=o>=</span> <span class=n>minimum_spanning_tree</span><span class=p>(</span><span class=o>-</span><span class=n>C_sum</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 删除低于阈值的边</span>
</span></span><span class=line><span class=cl>    <span class=n>mst</span><span class=o>.</span><span class=n>data</span><span class=p>[</span><span class=n>mst</span><span class=o>.</span><span class=n>data</span> <span class=o>&gt;</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=n>number_of_clusters</span><span class=p>,</span> <span class=n>labels</span> <span class=o>=</span> <span class=n>connected_components</span><span class=p>(</span><span class=n>mst</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>(0, 0)	1.0
(0, 1)	1.0
(0, 2)	1.0
(0, 3)	1.0
(0, 4)	1.0
(0, 5)	1.0
(0, 6)	1.0
(0, 7)	1.0
(0, 8)	1.0
(0, 9)	1.0
(0, 10)	1.0
(0, 11)	1.0
(0, 12)	1.0
(0, 13)	1.0
:	:
(364, 350)	1.0
(364, 351)	1.0
(364, 352)	1.0
(364, 353)	1.0
(364, 354)	1.0
(364, 355)	1.0
(364, 356)	1.0
(364, 357)	1.0
(364, 358)	1.0
(364, 359)	1.0
(364, 360)	1.0
(364, 361)	1.0
(364, 362)	1.0
(364, 363)	1.0
(364, 364)	1.0
0.11092512666541565
</code></pre><hr><p>从图的理论角度看，生成树为所有节点都连接到一起的图。<em>最小生成树</em>（Minimum Spanning Tree，MST）即总权重最低的生成树。结合我们的应用来讲，图中的节点对应数据集中的个体，边的权重对应两个顶点被分到同一簇的次数——也就是共协矩阵所记录的值。</p><p>矩阵 C 中，值越高表示一组数据点被分到同一簇的次数越多——这个值表示相似度。相反，minimum_spanning_tree 函数的输入为距离，高的值反而表示相似度越小。这里又用到了一次取反</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=n>mst</span> <span class=o>=</span> <span class=n>minimum_spanning_tree</span><span class=p>(</span><span class=n>C</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 对C取反再计算最小生成树</span>
</span></span><span class=line><span class=cl>    <span class=n>mst</span> <span class=o>=</span> <span class=n>minimum_spanning_tree</span><span class=p>(</span><span class=o>-</span><span class=n>C</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 创建额外的标签</span>
</span></span><span class=line><span class=cl>    <span class=n>pipeline</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>documents</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>labels2</span> <span class=o>=</span> <span class=n>pipeline</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>documents</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>C2</span> <span class=o>=</span> <span class=n>create_coassociation_matrix</span><span class=p>(</span><span class=n>labels2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>C_sum</span> <span class=o>=</span> <span class=p>(</span><span class=n>C</span> <span class=o>+</span> <span class=n>C2</span><span class=p>)</span> <span class=o>/</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl>    <span class=c1># 生成阈值不全为1和0的最小生成树</span>
</span></span><span class=line><span class=cl>    <span class=n>mst</span> <span class=o>=</span> <span class=n>minimum_spanning_tree</span><span class=p>(</span><span class=o>-</span><span class=n>C_sum</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 删除低于阈值的边</span>
</span></span><span class=line><span class=cl>    <span class=n>mst</span><span class=o>.</span><span class=n>data</span><span class=p>[</span><span class=n>mst</span><span class=o>.</span><span class=n>data</span> <span class=o>&gt;</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=n>number_of_clusters</span><span class=p>,</span> <span class=n>labels</span> <span class=o>=</span> <span class=n>connected_components</span><span class=p>(</span><span class=n>mst</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>number_of_clusters</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>labels</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>2
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0, 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0, 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
</code></pre><hr><p>k-means 算法不考虑特征的权重，它寻找的是圆形簇（circular clusters）</p><p>证据累积算法的工作原理为重新把特征映射到新空间，每次运行 k-means 算法都相当于使用转换器对特征进行一次转换。</p><p>证据累积算法只关心数据点之间的距离而不是它们在原来特征空间的位置。对于没有规范化过的特征，仍然存在问题。因此，特征规范很重要，无论如何都要做（我们用 tf-idf 规范特征值，从而使特征具有相同的值域）</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># 创建证据累积算法类</span>
</span></span><span class=line><span class=cl>    <span class=k>class</span> <span class=nc>EAC</span><span class=p>(</span><span class=n>BaseEstimator</span><span class=p>,</span> <span class=n>ClusterMixin</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=p>,</span> <span class=n>n_clusterings</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>cut_threshold</span><span class=o>=</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>n_clusters_range</span><span class=o>=</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>n_clusterings</span> <span class=o>=</span> <span class=n>n_clusterings</span>  <span class=c1># k-means算法运行次数</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>cut_threshold</span> <span class=o>=</span> <span class=n>cut_threshold</span>  <span class=c1># 用来删除边的阈值</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>n_clusters_range</span> <span class=o>=</span> <span class=n>n_clusters_range</span>  <span class=c1># 每次运行k-means算法要找到的簇的数量</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>def</span> <span class=nf>fit</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=c1># 进行指定次数的共协矩阵累加</span>
</span></span><span class=line><span class=cl>            <span class=n>C</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=p>(</span>
</span></span><span class=line><span class=cl>                    <span class=n>create_coassociation_matrix</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_single_clustering</span><span class=p>(</span><span class=n>X</span><span class=p>))</span>
</span></span><span class=line><span class=cl>                    <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>n_clusterings</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>mst</span> <span class=o>=</span> <span class=n>minimum_spanning_tree</span><span class=p>(</span><span class=o>-</span><span class=n>C</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>mst</span><span class=o>.</span><span class=n>data</span><span class=p>[</span><span class=n>mst</span><span class=o>.</span><span class=n>data</span> <span class=o>&gt;</span> <span class=o>-</span><span class=bp>self</span><span class=o>.</span><span class=n>cut_threshold</span><span class=p>]</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>n_components</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>labels_</span> <span class=o>=</span> <span class=n>connected_components</span><span class=p>(</span><span class=n>mst</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=bp>self</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 进行一次集群</span>
</span></span><span class=line><span class=cl>        <span class=k>def</span> <span class=nf>_single_clustering</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=c1># 在给定范围中随机选择一个集群数</span>
</span></span><span class=line><span class=cl>            <span class=n>n_clusters</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=o>*</span><span class=bp>self</span><span class=o>.</span><span class=n>n_clusters_range</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>km</span> <span class=o>=</span> <span class=n>KMeans</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=n>n_clusters</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=c1># 返回由k-means计算得到的簇标签</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=n>km</span><span class=o>.</span><span class=n>fit_predict</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>pipeline</span> <span class=o>=</span> <span class=n>Pipeline</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=p>[(</span><span class=s2>&#34;feature_extraction&#34;</span><span class=p>,</span> <span class=n>TfidfVectorizer</span><span class=p>(</span><span class=n>max_df</span><span class=o>=</span><span class=mf>0.4</span><span class=p>)),</span> <span class=p>(</span><span class=s2>&#34;clusterer&#34;</span><span class=p>,</span> <span class=n>EAC</span><span class=p>())]</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>pipeline</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>documents</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>number_of_clusters</span><span class=p>,</span> <span class=n>labels</span> <span class=o>=</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>pipeline</span><span class=p>[</span><span class=s2>&#34;clusterer&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>n_components</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>pipeline</span><span class=p>[</span><span class=s2>&#34;clusterer&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>labels_</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>number_of_clusters</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>labels</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>1
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
</code></pre><p>总感觉有什么问题。。。 <code>(￣ε(#￣)☆╰╮o(￣皿￣///))</code></p><h3 id=线上学习>线上学习</h3><p>线上学习是指用新数据增量地改进模型。支持线上学习的算法可以先用一条或少量数据进行训练，随着更多新数据的添加，更新模型。</p><p>线上学习与流式学习（streaming-based learning）有关，但有几个重要的不同点。线上学习能够重新评估先前创建模型时所用到的数据，而对于后者，所有数据都只使用一次。</p><p>scikit-learn 提供了 MiniBatchKMeans 算法，可以用它来实现线上学习功能。这个类实现了 <code>partial_fit</code> 函数，接收一组数据，更新模型。调用<code>fit()</code>将会删除之前的训练结果，重新根据新数据进行训练。</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># 使用TfIDFVectorizer从数据集中抽取特征，创建矩阵X</span>
</span></span><span class=line><span class=cl>    <span class=n>n_clusters</span> <span class=o>=</span> <span class=mi>6</span>
</span></span><span class=line><span class=cl>    <span class=n>vec</span> <span class=o>=</span> <span class=n>TfidfVectorizer</span><span class=p>(</span><span class=n>max_df</span><span class=o>=</span><span class=mf>0.4</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>X</span> <span class=o>=</span> <span class=n>vec</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>documents</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>mbkm</span> <span class=o>=</span> <span class=n>MiniBatchKMeans</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>14</span><span class=p>,</span> <span class=n>n_clusters</span><span class=o>=</span><span class=mi>3</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>batch_size</span> <span class=o>=</span> <span class=mi>10</span>
</span></span><span class=line><span class=cl>    <span class=c1># 随机从X矩阵中选择数据，模拟来自外部的新数据</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>iteration</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>int</span><span class=p>(</span><span class=n>X</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>/</span> <span class=n>batch_size</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>        <span class=n>start</span> <span class=o>=</span> <span class=n>batch_size</span> <span class=o>*</span> <span class=n>iteration</span>
</span></span><span class=line><span class=cl>        <span class=n>end</span> <span class=o>=</span> <span class=n>batch_size</span> <span class=o>*</span> <span class=p>(</span><span class=n>iteration</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>mbkm</span><span class=o>.</span><span class=n>partial_fit</span><span class=p>(</span><span class=n>X</span><span class=p>[</span><span class=n>start</span><span class=p>:</span><span class=n>end</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=c1># 获取数据集聚类结果</span>
</span></span><span class=line><span class=cl>    <span class=n>labels</span> <span class=o>=</span> <span class=n>mbkm</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>c</span> <span class=o>=</span> <span class=n>Counter</span><span class=p>(</span><span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>cluster_number</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_clusters</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;Cluster </span><span class=si>{}</span><span class=s2> contains </span><span class=si>{}</span><span class=s2> samples&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>cluster_number</span><span class=p>,</span> <span class=n>c</span><span class=p>[</span><span class=n>cluster_number</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>Cluster 0 contains 2 samples
Cluster 1 contains 362 samples
Cluster 2 contains 1 samples
Cluster 3 contains 0 samples
Cluster 4 contains 0 samples
Cluster 5 contains 0 samples
</code></pre><hr><p>由于 TfIDFVectorizer 不是在线算法，因此无法在流水线中使用</p><p>为了解决这个问题，我们使用 HashingVectorizer 类，它巧妙地使用散列算法极大地降低了计算词袋模型所需的内存开销，将数据的内容转换成散列值</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=k>class</span> <span class=nc>PartialFitPipeline</span><span class=p>(</span><span class=n>Pipeline</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>def</span> <span class=nf>partial_fit</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>Xt</span> <span class=o>=</span> <span class=n>X</span>
</span></span><span class=line><span class=cl>            <span class=c1># 经过最后一步之前的所有步转换</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>transform</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>steps</span><span class=p>[:</span><span class=o>-</span><span class=mi>1</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>                <span class=n>Xt</span> <span class=o>=</span> <span class=n>transform</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>Xt</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=c1>#　调用MiniBatchKMeans的partial_fit函数</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>steps</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>][</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>partial_fit</span><span class=p>(</span><span class=n>Xt</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>pipeline</span> <span class=o>=</span> <span class=n>PartialFitPipeline</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=p>(</span><span class=s2>&#34;feature_extraction&#34;</span><span class=p>,</span> <span class=n>HashingVectorizer</span><span class=p>()),</span>
</span></span><span class=line><span class=cl>            <span class=p>(</span><span class=s2>&#34;clusterer&#34;</span><span class=p>,</span> <span class=n>MiniBatchKMeans</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>14</span><span class=p>,</span> <span class=n>n_clusters</span><span class=o>=</span><span class=mi>3</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>        <span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>batch_size</span> <span class=o>=</span> <span class=mi>10</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>iteration</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>int</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>documents</span><span class=p>)</span> <span class=o>/</span> <span class=n>batch_size</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>        <span class=n>start</span> <span class=o>=</span> <span class=n>batch_size</span> <span class=o>*</span> <span class=n>iteration</span>
</span></span><span class=line><span class=cl>        <span class=n>end</span> <span class=o>=</span> <span class=n>batch_size</span> <span class=o>*</span> <span class=p>(</span><span class=n>iteration</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>pipeline</span><span class=o>.</span><span class=n>partial_fit</span><span class=p>(</span><span class=n>documents</span><span class=p>[</span><span class=n>start</span><span class=p>:</span><span class=n>end</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>labels</span> <span class=o>=</span> <span class=n>pipeline</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>documents</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>c</span> <span class=o>=</span> <span class=n>Counter</span><span class=p>(</span><span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>cluster_number</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_clusters</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;Cluster </span><span class=si>{}</span><span class=s2> contains </span><span class=si>{}</span><span class=s2> samples&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>cluster_number</span><span class=p>,</span> <span class=n>c</span><span class=p>[</span><span class=n>cluster_number</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>Cluster 0 contains 4 samples
Cluster 1 contains 76 samples
Cluster 2 contains 285 samples
Cluster 3 contains 0 samples
Cluster 4 contains 0 samples
Cluster 5 contains 0 samples
</code></pre><p>这一章的内容比较多，也学了挺久，虽然中间结果跟书上的差的有点多。。可能是因为最近新冠肺炎吧(￣_,￣ )</p><h2 id=第十一章>第十一章</h2><p>本章介绍如何使用深度神经网络识别图像中的物体</p><h3 id=深度神经网络>深度神经网络</h3><p>深度神经网络和第 8 章中的基本神经网络的差别在于规模大小。至少包含两层隐含层的神经网络被称为深度神经网络。神经网络的核心其实就是一系列矩阵运算，两个网络之间连接的权重可以用矩阵来表示。其中行表示前一层神经元，列表示后一层神经元，一个神经网络就可以用一组这样的矩阵来表示。除了神经元外，每层增加一个偏置项，它是一个特殊的神经元，永远处于激活状态，并且跟下一层的每一个神经元都有连接。</p><p>神经网络使用卷积层（一般来说，仅卷积神经网络包含该层）和池化层（pooling layer），池化层接收某个区域最大输出值，可以降低图像中的微小变动带来的噪音，减少（down-sample，降采样）信息量，这样后续各层所需工作量也会相应减少。</p><p>使用 Iris 数据集进行对比实验</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.datasets</span> <span class=kn>import</span> <span class=n>load_iris</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.preprocessing</span> <span class=kn>import</span> <span class=n>OneHotEncoder</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>train_test_split</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.metrics</span> <span class=kn>import</span> <span class=n>classification_report</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>keras.layers</span> <span class=kn>import</span> <span class=n>Dense</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>keras.models</span> <span class=kn>import</span> <span class=n>Sequential</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>matplotlib</span> <span class=kn>import</span> <span class=n>pyplot</span> <span class=k>as</span> <span class=n>plt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>iris</span> <span class=o>=</span> <span class=n>load_iris</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=n>iris</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>y_true</span> <span class=o>=</span> <span class=n>iris</span><span class=o>.</span><span class=n>target</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>int32</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 预处理数据集</span>
</span></span><span class=line><span class=cl><span class=n>y_onehot</span> <span class=o>=</span> <span class=n>OneHotEncoder</span><span class=p>()</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>y_true</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>y_onehot</span> <span class=o>=</span> <span class=n>y_onehot</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>int64</span><span class=p>)</span><span class=o>.</span><span class=n>todense</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>X_train</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y_onehot</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>14</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>input_layer_size</span><span class=p>,</span> <span class=n>hidden_layer_size</span><span class=p>,</span> <span class=n>output_layer_size</span> <span class=o>=</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>3</span>
</span></span><span class=line><span class=cl><span class=c1># 隐含层</span>
</span></span><span class=line><span class=cl><span class=n>hidden_layer</span> <span class=o>=</span> <span class=n>Dense</span><span class=p>(</span><span class=n>output_dim</span><span class=o>=</span><span class=n>hidden_layer_size</span><span class=p>,</span> <span class=n>input_dim</span><span class=o>=</span><span class=n>input_layer_size</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 输出层</span>
</span></span><span class=line><span class=cl><span class=n>output_layer</span> <span class=o>=</span> <span class=n>Dense</span><span class=p>(</span><span class=n>output_layer_size</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;sigmoid&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 创建顺序模型</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>Sequential</span><span class=p>(</span><span class=n>layers</span><span class=o>=</span><span class=p>[</span><span class=n>hidden_layer</span><span class=p>,</span> <span class=n>output_layer</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=c1># 为训练神经网络配置模型</span>
</span></span><span class=line><span class=cl><span class=c1># 损失函数设置为均方误差，优化器设置为adam(亚当)即遵循原始文件中的默认参数，指定精度衡量标准</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>compile</span><span class=p>(</span><span class=n>loss</span><span class=o>=</span><span class=s1>&#39;mean_squared_error&#39;</span><span class=p>,</span> <span class=n>optimizer</span><span class=o>=</span><span class=s1>&#39;adam&#39;</span><span class=p>,</span> <span class=n>metrics</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;accuracy&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=c1># 当一个完整的数据集通过了神经网络一次并且返回了一次，这个过程称为一次epoch</span>
</span></span><span class=line><span class=cl><span class=c1># 为模型训练固定的epoch（数据集上的迭代）</span>
</span></span><span class=line><span class=cl><span class=c1># 输出模式。0不输出，1每个epoch一个进度条，2一行每个epoch。</span>
</span></span><span class=line><span class=cl><span class=n>history</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>nb_epoch</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 记录了连续几个epoch的训练损失值和度量值，以及验证损失值和验证度量值(如果适用的话)</span>
</span></span><span class=line><span class=cl><span class=n>history</span><span class=o>.</span><span class=n>history</span>
</span></span><span class=line><span class=cl><span class=c1># 作图，绘制出epoch和loss关系图</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>history</span><span class=o>.</span><span class=n>epoch</span><span class=p>,</span> <span class=n>history</span><span class=o>.</span><span class=n>history</span><span class=p>[</span><span class=s1>&#39;loss&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s2>&#34;Epoch&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s2>&#34;Loss&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 为输入样本生成输出预测，计算是分批进行的</span>
</span></span><span class=line><span class=cl><span class=c1># 返回的是数值[0.9356668, 0.20588416, 0.00021186471],代表样本属于每个类别的概率</span>
</span></span><span class=line><span class=cl><span class=n>y_pred</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 返回一串预测结果，样本属于哪一个类别</span>
</span></span><span class=line><span class=cl><span class=n>y_pred</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict_classes</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>y_pred</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict_classes</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>classification_report</span><span class=p>(</span><span class=n>y_true</span><span class=o>=</span><span class=n>y_test</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span> <span class=n>y_pred</span><span class=o>=</span><span class=n>y_pred</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/img/in-post/data-mining/ch11/iris_100_epoch.png data-srcset="/img/in-post/data-mining/ch11/iris_100_epoch.png, /img/in-post/data-mining/ch11/iris_100_epoch.png 1.5x, /img/in-post/data-mining/ch11/iris_100_epoch.png 2x" data-sizes=auto alt=/img/in-post/data-mining/ch11/iris_100_epoch.png title=iris_1></p><pre><code>              precision    recall  f1-score   support

           0       1.00      1.00      1.00        17
           1       1.00      0.08      0.14        13
           2       0.40      1.00      0.57         8

    accuracy                           0.68        38
   macro avg       0.80      0.69      0.57        38
weighted avg       0.87      0.68      0.62        38
</code></pre><hr><p>重复上面的操作，这次运行 1000 步，对比实验结果</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>hidden_layer</span> <span class=o>=</span> <span class=n>Dense</span><span class=p>(</span><span class=n>output_dim</span><span class=o>=</span><span class=n>hidden_layer_size</span><span class=p>,</span> <span class=n>input_dim</span><span class=o>=</span><span class=n>input_layer_size</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>output_layer</span> <span class=o>=</span> <span class=n>Dense</span><span class=p>(</span><span class=n>output_layer_size</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;sigmoid&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>Sequential</span><span class=p>(</span><span class=n>layers</span><span class=o>=</span><span class=p>[</span><span class=n>hidden_layer</span><span class=p>,</span> <span class=n>output_layer</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>compile</span><span class=p>(</span><span class=n>loss</span><span class=o>=</span><span class=s1>&#39;mean_squared_error&#39;</span><span class=p>,</span> <span class=n>optimizer</span><span class=o>=</span><span class=s1>&#39;adam&#39;</span><span class=p>,</span> <span class=n>metrics</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;accuracy&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>history</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>nb_epoch</span><span class=o>=</span><span class=mi>1000</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>history</span><span class=o>.</span><span class=n>epoch</span><span class=p>,</span> <span class=n>history</span><span class=o>.</span><span class=n>history</span><span class=p>[</span><span class=s1>&#39;loss&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s2>&#34;Epoch&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s2>&#34;Loss&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>(</span><span class=s2>&#34;keras_on_iris_2.png&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>y_pred</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict_classes</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>classification_report</span><span class=p>(</span><span class=n>y_true</span><span class=o>=</span><span class=n>y_test</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span> <span class=n>y_pred</span><span class=o>=</span><span class=n>y_pred</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/img/in-post/data-mining/ch11/iris_1000_epoch.png data-srcset="/img/in-post/data-mining/ch11/iris_1000_epoch.png, /img/in-post/data-mining/ch11/iris_1000_epoch.png 1.5x, /img/in-post/data-mining/ch11/iris_1000_epoch.png 2x" data-sizes=auto alt=/img/in-post/data-mining/ch11/iris_1000_epoch.png title=iris_2></p><pre><code>              precision    recall  f1-score   support

           0       1.00      1.00      1.00        17
           1       1.00      1.00      1.00        13
           2       1.00      1.00      1.00         8

    accuracy                           1.00        38
   macro avg       1.00      1.00      1.00        38
weighted avg       1.00      1.00      1.00        38
</code></pre><p>从结果可以看出，经过 100 步训练的神经网络正确率达到了 68%，经过 1000 步训练后正确率达到了 100%</p><hr><p>验证码识别实验</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>PIL</span> <span class=kn>import</span> <span class=n>Image</span><span class=p>,</span> <span class=n>ImageDraw</span><span class=p>,</span> <span class=n>ImageFont</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>skimage</span> <span class=kn>import</span> <span class=n>transform</span> <span class=k>as</span> <span class=n>tf</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>matplotlib</span> <span class=kn>import</span> <span class=n>pyplot</span> <span class=k>as</span> <span class=n>plt</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.utils</span> <span class=kn>import</span> <span class=n>check_random_state</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.preprocessing</span> <span class=kn>import</span> <span class=n>OneHotEncoder</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>train_test_split</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>keras.layers</span> <span class=kn>import</span> <span class=n>Dense</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>keras.models</span> <span class=kn>import</span> <span class=n>Sequential</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>skimage.measure</span> <span class=kn>import</span> <span class=n>label</span><span class=p>,</span> <span class=n>regionprops</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>create_captcha</span><span class=p>(</span><span class=n>text</span><span class=p>,</span> <span class=n>shear</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=mi>100</span><span class=p>,</span> <span class=mi>30</span><span class=p>),</span> <span class=n>scale</span><span class=o>=</span><span class=mi>1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>im</span> <span class=o>=</span> <span class=n>Image</span><span class=o>.</span><span class=n>new</span><span class=p>(</span><span class=s2>&#34;L&#34;</span><span class=p>,</span> <span class=n>size</span><span class=p>,</span> <span class=s2>&#34;black&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>draw</span> <span class=o>=</span> <span class=n>ImageDraw</span><span class=o>.</span><span class=n>Draw</span><span class=p>(</span><span class=n>im</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>font</span> <span class=o>=</span> <span class=n>ImageFont</span><span class=o>.</span><span class=n>truetype</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;/home/saltfish/Programming/Python/data_mining/ch11/FiraCode-Medium.otf&#34;</span><span class=p>,</span> <span class=mi>22</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>draw</span><span class=o>.</span><span class=n>text</span><span class=p>((</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>),</span> <span class=n>text</span><span class=p>,</span> <span class=n>fill</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>font</span><span class=o>=</span><span class=n>font</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>image</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>im</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>affine_tf</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>AffineTransform</span><span class=p>(</span><span class=n>shear</span><span class=o>=</span><span class=n>shear</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>image</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>warp</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=n>affine_tf</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>image</span> <span class=o>=</span> <span class=n>image</span> <span class=o>/</span> <span class=n>image</span><span class=o>.</span><span class=n>max</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>shape</span> <span class=o>=</span> <span class=n>image</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>    <span class=c1># Apply scale</span>
</span></span><span class=line><span class=cl>    <span class=n>shapex</span><span class=p>,</span> <span class=n>shapey</span> <span class=o>=</span> <span class=p>(</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>*</span> <span class=n>scale</span><span class=p>,</span> <span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>*</span> <span class=n>scale</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>image</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>resize</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=p>(</span><span class=n>shapex</span><span class=p>,</span> <span class=n>shapey</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>image</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>image</span> <span class=o>=</span> <span class=n>create_captcha</span><span class=p>(</span><span class=s2>&#34;FISH&#34;</span><span class=p>,</span> <span class=n>shear</span><span class=o>=</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mf>0.6</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=s2>&#34;Greys&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/img/in-post/data-mining/ch11/captcha_1.png data-srcset="/img/in-post/data-mining/ch11/captcha_1.png, /img/in-post/data-mining/ch11/captcha_1.png 1.5x, /img/in-post/data-mining/ch11/captcha_1.png 2x" data-sizes=auto alt=/img/in-post/data-mining/ch11/captcha_1.png title=captcha_1></p><hr><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>segment_image</span><span class=p>(</span><span class=n>image</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># 标记找到连通的非黑色像素的子图像</span>
</span></span><span class=line><span class=cl>    <span class=n>labeled_image</span> <span class=o>=</span> <span class=n>label</span><span class=p>(</span><span class=n>image</span> <span class=o>&gt;</span> <span class=mf>0.2</span><span class=p>,</span> <span class=n>connectivity</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>background</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>subimages</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=c1># 拆分子图</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>region</span> <span class=ow>in</span> <span class=n>regionprops</span><span class=p>(</span><span class=n>labeled_image</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 提取子图</span>
</span></span><span class=line><span class=cl>        <span class=n>start_x</span><span class=p>,</span> <span class=n>start_y</span><span class=p>,</span> <span class=n>end_x</span><span class=p>,</span> <span class=n>end_y</span> <span class=o>=</span> <span class=n>region</span><span class=o>.</span><span class=n>bbox</span>
</span></span><span class=line><span class=cl>        <span class=n>subimages</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>image</span><span class=p>[</span><span class=n>start_x</span><span class=p>:</span><span class=n>end_x</span><span class=p>,</span> <span class=n>start_y</span><span class=p>:</span><span class=n>end_y</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>subimages</span><span class=p>)</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># 未找到子图，返回这个图片本身</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=n>image</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>subimages</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>subimages</span> <span class=o>=</span> <span class=n>segment_image</span><span class=p>(</span><span class=n>image</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 选出四张小图片</span>
</span></span><span class=line><span class=cl><span class=n>f</span><span class=p>,</span> <span class=n>axes</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>subimages</span><span class=p>),</span> <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>3</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>subimages</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>    <span class=n>axes</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>subimages</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>cmap</span><span class=o>=</span><span class=s2>&#34;gray&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/img/in-post/data-mining/ch11/captcha_2.png data-srcset="/img/in-post/data-mining/ch11/captcha_2.png, /img/in-post/data-mining/ch11/captcha_2.png 1.5x, /img/in-post/data-mining/ch11/captcha_2.png 2x" data-sizes=auto alt=/img/in-post/data-mining/ch11/captcha_2.png title=captcha_2></p><hr><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>random_state</span> <span class=o>=</span> <span class=n>check_random_state</span><span class=p>(</span><span class=mi>14</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>letters</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=s2>&#34;ABCDEFGHIJKLMNOPQRSTUVWXYZ&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>assert</span> <span class=nb>len</span><span class=p>(</span><span class=n>letters</span><span class=p>)</span> <span class=o>==</span> <span class=mi>26</span>
</span></span><span class=line><span class=cl><span class=n>shear_values</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mf>0.8</span><span class=p>,</span> <span class=mf>0.05</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>scale_values</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mf>0.9</span><span class=p>,</span> <span class=mf>1.1</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 随机生成一个字母的图片</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>generate_sample</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>random_state</span> <span class=o>=</span> <span class=n>check_random_state</span><span class=p>(</span><span class=n>random_state</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>letter</span> <span class=o>=</span> <span class=n>random_state</span><span class=o>.</span><span class=n>choice</span><span class=p>(</span><span class=n>letters</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>shear</span> <span class=o>=</span> <span class=n>random_state</span><span class=o>.</span><span class=n>choice</span><span class=p>(</span><span class=n>shear_values</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>scale</span> <span class=o>=</span> <span class=n>random_state</span><span class=o>.</span><span class=n>choice</span><span class=p>(</span><span class=n>scale_values</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>create_captcha</span><span class=p>(</span><span class=n>letter</span><span class=p>,</span> <span class=n>shear</span><span class=o>=</span><span class=n>shear</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=mi>30</span><span class=p>,</span> <span class=mi>30</span><span class=p>),</span> <span class=n>scale</span><span class=o>=</span><span class=n>scale</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>letters</span><span class=o>.</span><span class=n>index</span><span class=p>(</span><span class=n>letter</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>image</span><span class=p>,</span> <span class=n>target</span> <span class=o>=</span> <span class=n>generate_sample</span><span class=p>(</span><span class=n>random_state</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=s2>&#34;Greys&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;The target for this image is: </span><span class=si>{0}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>letters</span><span class=p>[</span><span class=n>target</span><span class=p>]))</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>The target for this image is: L
</code></pre><p><img class=lazyload src=/svg/loading.min.svg data-src=/img/in-post/data-mining/ch11/captcha_3.png data-srcset="/img/in-post/data-mining/ch11/captcha_3.png, /img/in-post/data-mining/ch11/captcha_3.png 1.5x, /img/in-post/data-mining/ch11/captcha_3.png 2x" data-sizes=auto alt=/img/in-post/data-mining/ch11/captcha_3.png title=captcha_3></p><hr><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 生成数据集</span>
</span></span><span class=line><span class=cl><span class=n>dataset</span><span class=p>,</span> <span class=n>targets</span> <span class=o>=</span> <span class=nb>zip</span><span class=p>(</span><span class=o>*</span><span class=p>(</span><span class=n>generate_sample</span><span class=p>(</span><span class=n>random_state</span><span class=p>)</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1000</span><span class=p>)))</span>
</span></span><span class=line><span class=cl><span class=n>dataset</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=n>tf</span><span class=o>.</span><span class=n>resize</span><span class=p>(</span><span class=n>segment_image</span><span class=p>(</span><span class=n>sample</span><span class=p>)[</span><span class=mi>0</span><span class=p>],</span> <span class=p>(</span><span class=mi>20</span><span class=p>,</span> <span class=mi>20</span><span class=p>))</span> <span class=k>for</span> <span class=n>sample</span> <span class=ow>in</span> <span class=n>dataset</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>dataset</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>dataset</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=s2>&#34;float&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>targets</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>targets</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>onehot</span> <span class=o>=</span> <span class=n>OneHotEncoder</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>y</span> <span class=o>=</span> <span class=n>onehot</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>targets</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>targets</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>y</span> <span class=o>=</span> <span class=n>y</span><span class=o>.</span><span class=n>todense</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=n>dataset</span><span class=o>.</span><span class=n>reshape</span><span class=p>((</span><span class=n>dataset</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>dataset</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>*</span> <span class=n>dataset</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>2</span><span class=p>]))</span>
</span></span><span class=line><span class=cl><span class=n>X_train</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>train_size</span><span class=o>=</span><span class=mf>0.9</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>hidden_layer</span> <span class=o>=</span> <span class=n>Dense</span><span class=p>(</span><span class=mi>100</span><span class=p>,</span> <span class=n>input_dim</span><span class=o>=</span><span class=n>X_train</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>output_layer</span> <span class=o>=</span> <span class=n>Dense</span><span class=p>(</span><span class=n>y_train</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>Sequential</span><span class=p>(</span><span class=n>layers</span><span class=o>=</span><span class=p>[</span><span class=n>hidden_layer</span><span class=p>,</span> <span class=n>output_layer</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>compile</span><span class=p>(</span><span class=n>loss</span><span class=o>=</span><span class=s2>&#34;mean_squared_error&#34;</span><span class=p>,</span> <span class=n>optimizer</span><span class=o>=</span><span class=s2>&#34;adam&#34;</span><span class=p>,</span> <span class=n>metrics</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;accuracy&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>epochs</span><span class=o>=</span><span class=mi>1000</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>y_pred</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>f1_score</span><span class=p>(</span><span class=n>y_pred</span><span class=o>=</span><span class=n>y_pred</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span> <span class=n>y_true</span><span class=o>=</span><span class=n>y_test</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span> <span class=n>average</span><span class=o>=</span><span class=s2>&#34;macro&#34;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>classification_report</span><span class=p>(</span><span class=n>y_pred</span><span class=o>=</span><span class=n>y_pred</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span> <span class=n>y_true</span><span class=o>=</span><span class=n>y_test</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)))</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>1.0

              precision    recall  f1-score   support

           0       1.00      1.00      1.00         4
           1       1.00      1.00      1.00         4
           2       1.00      1.00      1.00         3
           3       1.00      1.00      1.00        10
           4       1.00      1.00      1.00         3
           5       1.00      1.00      1.00         3
           6       1.00      1.00      1.00         1
           7       1.00      1.00      1.00         3
           8       1.00      1.00      1.00         5
           9       1.00      1.00      1.00         3
          10       1.00      1.00      1.00         3
          11       1.00      1.00      1.00         6
          12       1.00      1.00      1.00         3
          13       1.00      1.00      1.00         5
          14       1.00      1.00      1.00         4
          15       1.00      1.00      1.00         6
          16       1.00      1.00      1.00         1
          17       1.00      1.00      1.00         3
          18       1.00      1.00      1.00         2
          19       1.00      1.00      1.00         3
          20       1.00      1.00      1.00         5
          21       1.00      1.00      1.00         7
          22       1.00      1.00      1.00         4
          23       1.00      1.00      1.00         2
          24       1.00      1.00      1.00         2
          25       1.00      1.00      1.00         5

    accuracy                           1.00       100
   macro avg       1.00      1.00      1.00       100
weighted avg       1.00      1.00      1.00       100
</code></pre><h3 id=使用-gpu-优化>使用 GPU 优化</h3><p>为了让我的 GPU 能跑程序，可费了我好大功夫，结果我这 960M 的 2G 内存还跑不了太大的程序/(ㄒ o ㄒ)/~~</p><p>第 101 次想念我的台式机，可恶的病毒</p><p>配置的过程跟 <a href=https://tensorflow.google.cn/install/gpu target=_blank rel="noopener noreffer">TensorFlow</a> 官网给的方法没啥区别，在这就不多说了（官网给出的 NVIDIA 显卡驱动版本是 430，我这里是 440，CUDA 版本是 10.2，依然能运行程序，可能只需要 <code>development and runtime libraries</code> 正确安装就行？）</p><p>使用 tensorflow 在执行 <code>modle.compile()</code> 的时候需要较长的时间，运行时的速度还是很快的</p><p>初次接触神经网络，不了解的东西太多了，还是先多做几个训练再说吧。。</p><h3 id=应用-1>应用</h3><p>书上使用 CIFAR 图像数据集的代码太老了（原谅我太菜了解决不了依赖问题），因此我跟着 Tensorflow 官网的代码做完了这个实验</p><p>服装识别</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># -*- coding: utf-8 -*-</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>__future__</span> <span class=kn>import</span> <span class=n>absolute_import</span><span class=p>,</span> <span class=n>division</span><span class=p>,</span> <span class=n>print_function</span><span class=p>,</span> <span class=n>unicode_literals</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>tensorflow</span> <span class=k>as</span> <span class=nn>tf</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>tensorflow</span> <span class=kn>import</span> <span class=n>keras</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># --------加载、了解、预处理数据集--------</span>
</span></span><span class=line><span class=cl>    <span class=n>fashion_mnist</span> <span class=o>=</span> <span class=n>keras</span><span class=o>.</span><span class=n>datasets</span><span class=o>.</span><span class=n>fashion_mnist</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=n>train_images</span><span class=p>,</span> <span class=n>train_labels</span><span class=p>),</span> <span class=p>(</span><span class=n>test_images</span><span class=p>,</span> <span class=n>test_labels</span><span class=p>)</span> <span class=o>=</span> <span class=n>fashion_mnist</span><span class=o>.</span><span class=n>load_data</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>class_names</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;T-shirt/top&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Trouser&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Pullover&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Dress&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Coat&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Sandal&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Shirt&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Sneaker&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Bag&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Ankle boot&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=c1># 查看数据集</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>train_images</span><span class=o>.</span><span class=n>shape</span><span class=p>,</span>  <span class=c1># (60000，28，28)</span>
</span></span><span class=line><span class=cl>        <span class=nb>len</span><span class=p>(</span><span class=n>train_labels</span><span class=p>),</span>  <span class=c1># 60000</span>
</span></span><span class=line><span class=cl>        <span class=n>train_labels</span><span class=p>,</span>  <span class=c1># [9 0 0 ... 3 0 5]</span>
</span></span><span class=line><span class=cl>        <span class=n>test_images</span><span class=o>.</span><span class=n>shape</span><span class=p>,</span>  <span class=c1># (10000, 28, 28)</span>
</span></span><span class=line><span class=cl>        <span class=nb>len</span><span class=p>(</span><span class=n>test_labels</span><span class=p>),</span>  <span class=c1># 10000</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>(60000, 28, 28) 60000 [9 0 0 ... 3 0 5] (10000, 28, 28) 10000
</code></pre><hr><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># 查看图像</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>train_images</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>colorbar</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=c1># 预处理标准化</span>
</span></span><span class=line><span class=cl>    <span class=n>train_images</span> <span class=o>=</span> <span class=n>train_images</span> <span class=o>/</span> <span class=mf>255.0</span>
</span></span><span class=line><span class=cl>    <span class=n>test_images</span> <span class=o>=</span> <span class=n>test_images</span> <span class=o>/</span> <span class=mf>255.0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 查看数据集</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>25</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>xticks</span><span class=p>([])</span>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>yticks</span><span class=p>([])</span>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>train_images</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>cmap</span><span class=o>=</span><span class=n>plt</span><span class=o>.</span><span class=n>cm</span><span class=o>.</span><span class=n>binary</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=n>class_names</span><span class=p>[</span><span class=n>train_labels</span><span class=p>[</span><span class=n>i</span><span class=p>]])</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><table align=left><td align=center><img src=/img/in-post/data-mining/ch11/tensorflow11.1.png alt="Fashion MNIST sprite" width=600></td><td align=center><img src=/img/in-post/data-mining/ch11/tensorflow11.2.png alt="Fashion MNIST sprite" width=600></td></table><hr><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># --------建立模型--------</span>
</span></span><span class=line><span class=cl>    <span class=c1># 建立神经网络所需要模型的各层</span>
</span></span><span class=line><span class=cl>    <span class=c1># tf.keras.layers.Flatten将图像的格式从二维数组(28 * 28)转换为一维数组(28 * 28 = 784)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 可以将这个图层看作是图像中取消堆叠的像素行，并将它们排列起来</span>
</span></span><span class=line><span class=cl>    <span class=c1># 这个层没有参数需要学习; 它只是重新格式化数据。</span>
</span></span><span class=line><span class=cl>    <span class=c1>#</span>
</span></span><span class=line><span class=cl>    <span class=c1># 然后是两个稠密层（完全连接的层），中间一层有128个节点，</span>
</span></span><span class=line><span class=cl>    <span class=c1># 最后一层返回长度为10的对数数组。每个神经元包含一个得分，指示当前图像对这一类的评分</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=o>=</span> <span class=n>keras</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>Flatten</span><span class=p>(</span><span class=n>input_shape</span><span class=o>=</span><span class=p>(</span><span class=mi>28</span><span class=p>,</span> <span class=mi>28</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>            <span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>Dense</span><span class=p>(</span><span class=mi>128</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s2>&#34;relu&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>Dense</span><span class=p>(</span><span class=mi>10</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># --------编译模型--------</span>
</span></span><span class=line><span class=cl>    <span class=c1># 损失函数：这可以衡量训练期间模型的准确程度，希望最小化这个函数，以便将模型“引导”到正确的方向</span>
</span></span><span class=line><span class=cl>    <span class=c1># 优化器：如何基于它看到的数据和它的损失函数更新模型</span>
</span></span><span class=line><span class=cl>    <span class=c1># 指标：用于检测训练和测试步骤。下面的例子使用精确度，即正确分类的图像的分数</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>compile</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>=</span><span class=s2>&#34;adam&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span><span class=o>=</span><span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>losses</span><span class=o>.</span><span class=n>SparseCategoricalCrossentropy</span><span class=p>(</span><span class=n>from_logits</span><span class=o>=</span><span class=kc>True</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>metrics</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;accuracy&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># --------训练模型--------</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>train_images</span><span class=p>,</span> <span class=n>train_labels</span><span class=p>,</span> <span class=n>epochs</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># --------评估表现--------</span>
</span></span><span class=line><span class=cl>    <span class=n>test_loss</span><span class=p>,</span> <span class=n>test_acc</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>evaluate</span><span class=p>(</span><span class=n>test_images</span><span class=p>,</span> <span class=n>test_labels</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Test accuracy:&#34;</span><span class=p>,</span> <span class=n>test_acc</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>probability_model</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>Sequential</span><span class=p>([</span><span class=n>model</span><span class=p>,</span> <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>Softmax</span><span class=p>()])</span>
</span></span><span class=line><span class=cl>    <span class=c1># prediction是由10个数字组成的数组。它们表示模型对图像对应于10种不同衣服各自的置信度</span>
</span></span><span class=line><span class=cl>    <span class=n>predictions</span> <span class=o>=</span> <span class=n>probability_model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>test_images</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>predictions</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>pciBusID: 0000:02:00.0 name: GeForce GTX 960M computeCapability: 5.0
coreClock: 1.176GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s
Epoch 1/10
1875/1875 [==============================] - 3s 2ms/step - loss: 0.4919 - accuracy: 0.8271
Epoch 2/10
1875/1875 [==============================] - 3s 1ms/step - loss: 0.3758 - accuracy: 0.8648
Epoch 3/10
1875/1875 [==============================] - 2s 1ms/step - loss: 0.3346 - accuracy: 0.8770
Epoch 4/10
1875/1875 [==============================] - 2s 1ms/step - loss: 0.3099 - accuracy: 0.8860
Epoch 5/10
1875/1875 [==============================] - 2s 1ms/step - loss: 0.2927 - accuracy: 0.8927
Epoch 6/10
1875/1875 [==============================] - 2s 1ms/step - loss: 0.2807 - accuracy: 0.8962
Epoch 7/10
1875/1875 [==============================] - 2s 1ms/step - loss: 0.2655 - accuracy: 0.9010
Epoch 8/10
1875/1875 [==============================] - 2s 1ms/step - loss: 0.2548 - accuracy: 0.9044
Epoch 9/10
1875/1875 [==============================] - 3s 1ms/step - loss: 0.2440 - accuracy: 0.9095
Epoch 10/10
1875/1875 [==============================] - 2s 1ms/step - loss: 0.2373 - accuracy: 0.9113
313/313 - 0s - loss: 0.3479 - accuracy: 0.8798

Test accuracy: 0.879800021648407

[1.3496768e-07 1.5826453e-10 1.7375668e-09 2.1999605e-10 5.5648923e-07
1.9829762e-03 1.9957926e-07 1.8424643e-04 9.3086570e-09 9.9783188e-01]
</code></pre><p>从输出可以看出 loss 函数正在逐渐减小，训练的准确率在不断的增加，这正是我们所要的</p><p>在训练集中的准确率为 91.1%， 而在测试集中只有 88%，这是出现了过拟合(overfitting)，关于过拟合的证明和避免过拟合的方法，等过几天单独写一个 post 学习一下</p><hr><p>定义两个函数用来绘图，更直观地看出预测结果</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># --------验证模型--------</span>
</span></span><span class=line><span class=cl>    <span class=c1># 制作图表来观察十个类别预测的完整集合</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>plot_image</span><span class=p>(</span><span class=n>i</span><span class=p>,</span> <span class=n>predictions_array</span><span class=p>,</span> <span class=n>true_label</span><span class=p>,</span> <span class=n>img</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>predictions_array</span><span class=p>,</span> <span class=n>true_label</span><span class=p>,</span> <span class=n>img</span> <span class=o>=</span> <span class=n>predictions_array</span><span class=p>,</span> <span class=n>true_label</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>img</span><span class=p>[</span><span class=n>i</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>xticks</span><span class=p>([])</span>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>yticks</span><span class=p>([])</span>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>img</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=n>plt</span><span class=o>.</span><span class=n>cm</span><span class=o>.</span><span class=n>binary</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>predicted_label</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>predictions_array</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>predicted_label</span> <span class=o>==</span> <span class=n>true_label</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>color</span> <span class=o>=</span> <span class=s2>&#34;blue&#34;</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>color</span> <span class=o>=</span> <span class=s2>&#34;red&#34;</span>
</span></span><span class=line><span class=cl>        <span class=c1># 置信度百分比</span>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;</span><span class=si>{}</span><span class=s2> </span><span class=si>{:2.0f}</span><span class=s2>% (</span><span class=si>{}</span><span class=s2>)&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>class_names</span><span class=p>[</span><span class=n>predicted_label</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                <span class=mi>100</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>predictions_array</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=n>class_names</span><span class=p>[</span><span class=n>true_label</span><span class=p>],</span>
</span></span><span class=line><span class=cl>            <span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>color</span><span class=o>=</span><span class=n>color</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 绘制置信度柱状图</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>plot_value_array</span><span class=p>(</span><span class=n>i</span><span class=p>,</span> <span class=n>predictions_array</span><span class=p>,</span> <span class=n>true_label</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>predictions_array</span><span class=p>,</span> <span class=n>true_label</span> <span class=o>=</span> <span class=n>predictions_array</span><span class=p>,</span> <span class=n>true_label</span><span class=p>[</span><span class=n>i</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>xticks</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=mi>10</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>yticks</span><span class=p>([])</span>
</span></span><span class=line><span class=cl>        <span class=n>thisplot</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>bar</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=mi>10</span><span class=p>),</span> <span class=n>predictions_array</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&#34;#777777&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>ylim</span><span class=p>([</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=n>predicted_label</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>predictions_array</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># 错误的预测标签为红色</span>
</span></span><span class=line><span class=cl>        <span class=n>thisplot</span><span class=p>[</span><span class=n>predicted_label</span><span class=p>]</span><span class=o>.</span><span class=n>set_color</span><span class=p>(</span><span class=s2>&#34;red&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># 正确的标签为蓝色</span>
</span></span><span class=line><span class=cl>        <span class=n>thisplot</span><span class=p>[</span><span class=n>true_label</span><span class=p>]</span><span class=o>.</span><span class=n>set_color</span><span class=p>(</span><span class=s2>&#34;blue&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>6</span><span class=p>,</span> <span class=mi>3</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plot_image</span><span class=p>(</span><span class=n>i</span><span class=p>,</span> <span class=n>predictions</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>test_labels</span><span class=p>,</span> <span class=n>test_images</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plot_value_array</span><span class=p>(</span><span class=n>i</span><span class=p>,</span> <span class=n>predictions</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>test_labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>i</span> <span class=o>=</span> <span class=mi>12</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>6</span><span class=p>,</span> <span class=mi>3</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plot_image</span><span class=p>(</span><span class=n>i</span><span class=p>,</span> <span class=n>predictions</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>test_labels</span><span class=p>,</span> <span class=n>test_images</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plot_value_array</span><span class=p>(</span><span class=n>i</span><span class=p>,</span> <span class=n>predictions</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>test_labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>num_rows</span> <span class=o>=</span> <span class=mi>5</span>
</span></span><span class=line><span class=cl>    <span class=n>num_cols</span> <span class=o>=</span> <span class=mi>3</span>
</span></span><span class=line><span class=cl>    <span class=n>num_images</span> <span class=o>=</span> <span class=n>num_rows</span> <span class=o>*</span> <span class=n>num_cols</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>2</span> <span class=o>*</span> <span class=mi>2</span> <span class=o>*</span> <span class=n>num_cols</span><span class=p>,</span> <span class=mi>2</span> <span class=o>*</span> <span class=n>num_rows</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_images</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=n>num_rows</span><span class=p>,</span> <span class=mi>2</span> <span class=o>*</span> <span class=n>num_cols</span><span class=p>,</span> <span class=mi>2</span> <span class=o>*</span> <span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>plot_image</span><span class=p>(</span><span class=n>i</span><span class=p>,</span> <span class=n>predictions</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>test_labels</span><span class=p>,</span> <span class=n>test_images</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=n>num_rows</span><span class=p>,</span> <span class=mi>2</span> <span class=o>*</span> <span class=n>num_cols</span><span class=p>,</span> <span class=mi>2</span> <span class=o>*</span> <span class=n>i</span> <span class=o>+</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>plot_value_array</span><span class=p>(</span><span class=n>i</span><span class=p>,</span> <span class=n>predictions</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>test_labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><table class=tfo-notebook-buttons align=center><tr align=center><img src=/img/in-post/data-mining/ch11/tensorflow11.3.png></tr><tr align=center><img src=/img/in-post/data-mining/ch11/tensorflow11.4.png></tr><tr align=center><img src=/img/in-post/data-mining/ch11/tensorflow11.5.png></tr></table><hr><p>示范如何使用模型来得到预测结果</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># --------使用模型--------</span>
</span></span><span class=line><span class=cl>    <span class=n>img</span> <span class=o>=</span> <span class=n>test_images</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>img</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 转换成keras支持的格式</span>
</span></span><span class=line><span class=cl>    <span class=n>img</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>expand_dims</span><span class=p>(</span><span class=n>img</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>img</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 为该图像预测</span>
</span></span><span class=line><span class=cl>    <span class=n>predictions_single</span> <span class=o>=</span> <span class=n>probability_model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>img</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>predictions_single</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plot_value_array</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>predictions_single</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>test_labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>_</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>xticks</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=mi>10</span><span class=p>),</span> <span class=n>class_names</span><span class=p>,</span> <span class=n>rotation</span><span class=o>=</span><span class=mi>45</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=c1># 返回预测的种类</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;result: &#34;</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>predictions_single</span><span class=p>[</span><span class=mi>0</span><span class=p>]))</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>(28, 28)
(1, 28, 28)
[[3.3822223e-05 3.9569712e-13 9.9579656e-01 1.2699689e-10 3.9967773e-03
1.0960948e-12 1.7281482e-04 5.0896191e-17 7.9589724e-11 1.4832706e-12]]
result: 2

# 这张图片忘了保存了
</code></pre><hr><p>试着增加步数观察是否能得到更好的结果</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># 仅修改这一行代码，其它不变，重新运行</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>train_images</span><span class=p>,</span> <span class=n>train_labels</span><span class=p>,</span> <span class=n>epochs</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>313/313 - 0s - loss: 0.8228 - accuracy: 0.8824
Test accuracy: 0.8823999762535095

[3.4202448e-25 0.0000000e+00 1.0021874e-24 0.0000000e+00 5.4433387e-31
1.8526166e-17 5.1352536e-34 4.5777732e-13 1.4344803e-28 1.0000000e+00]

(28, 28)
(1, 28, 28)
[[2.1121348e-16 0.0000000e+00 1.0000000e+00 1.0520916e-32 5.9910987e-09
1.4628578e-34 1.1571613e-14 0.0000000e+00 6.4996830e-38 0.0000000e+00]]
result: 2
</code></pre><table class=tfo-notebook-buttons align=center><tr align=center><img src=/img/in-post/data-mining/ch11/tensorflow11.6.png></tr><tr align=center><img src=/img/in-post/data-mining/ch11/tensorflow11.7.png></tr><tr align=center><img src=/img/in-post/data-mining/ch11/tensorflow11.8.png></tr></table><p>在增加到 100 步后，最后一步的输出为</p><pre><code>Epoch 100/100
1875/1875 [==============================] - 3s 2ms/step - loss: 0.0570 - accuracy: 0.9790
</code></pre><p>在训练集上的精确度达到了 97.9%，而在测试集中也只达到了 88.2%，有微小的进步</p><p>这个实验条理清晰地展示了深度学习的基本步骤：</p><ul><li>加载、了解、预处理数据集</li><li>建立模型</li><li>建立模型</li><li>训练模型</li><li>评估表现</li><li>验证模型</li><li>使用模型做预测</li></ul><hr><p>这本书就快看完了，正愁不知道下本书看啥的我又发现了一个学习宝库<code>TensorFlow</code>。就决定是你了！</p><p>笔记本好难用，还是 pycharm 适合我。。。但还是得学用笔记本啊～～</p><h2 id=第十二章>第十二章</h2><p>本章主要介绍了 python 使用 MapReduce 来进行大数据处理</p><h3 id=mapreduce-例子>MapReduce 例子</h3><p>MapReduce 主要分为两步：映射（Map）和规约（Reduce）</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># -*- coding: utf-8 -*-</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>collections</span> <span class=kn>import</span> <span class=n>defaultdict</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.datasets</span> <span class=kn>import</span> <span class=n>fetch_20newsgroups</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>joblib</span> <span class=kn>import</span> <span class=n>Parallel</span><span class=p>,</span> <span class=n>delayed</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>timeit</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 计算documents中的单词出现词素</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>map_word_count</span><span class=p>(</span><span class=n>document_id</span><span class=p>,</span> <span class=n>document</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>counts</span> <span class=o>=</span> <span class=n>defaultdict</span><span class=p>(</span><span class=nb>int</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>document</span><span class=o>.</span><span class=n>split</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>counts</span><span class=p>[</span><span class=n>word</span><span class=p>]</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>counts</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>yield</span> <span class=n>word</span><span class=p>,</span> <span class=n>counts</span><span class=p>[</span><span class=n>word</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 将map得到的结果，即每篇文章中单词出现的次数整合起来</span>
</span></span><span class=line><span class=cl><span class=c1># 如文章1中单词&#34;apple&#34;出现了2次，文章2中单词&#34;apple&#34;出现了5次，则返回结果为[&#34;apple&#34;:[2,5],...]</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>shuffle_words</span><span class=p>(</span><span class=n>results_generators</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>records</span> <span class=o>=</span> <span class=n>defaultdict</span><span class=p>(</span><span class=nb>list</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 遍历每一篇文章</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>results</span> <span class=ow>in</span> <span class=n>results_generators</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># 遍历每个单词</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>word</span><span class=p>,</span> <span class=n>count</span> <span class=ow>in</span> <span class=n>results</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>records</span><span class=p>[</span><span class=n>word</span><span class=p>]</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>count</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 每次生成一个单词</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>records</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>yield</span> <span class=n>word</span><span class=p>,</span> <span class=n>records</span><span class=p>[</span><span class=n>word</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 将单词所对应的列表叠加起来得到单词出现次数</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>reduce_counts</span><span class=p>(</span><span class=n>word</span><span class=p>,</span> <span class=n>list_of_counts</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>word</span><span class=p>,</span> <span class=nb>sum</span><span class=p>(</span><span class=n>list_of_counts</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>dataset</span> <span class=o>=</span> <span class=n>fetch_20newsgroups</span><span class=p>(</span><span class=n>subset</span><span class=o>=</span><span class=s2>&#34;train&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>documents</span> <span class=o>=</span> <span class=n>dataset</span><span class=o>.</span><span class=n>data</span>
</span></span><span class=line><span class=cl>    <span class=n>start</span> <span class=o>=</span> <span class=n>timeit</span><span class=o>.</span><span class=n>default_timer</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=c1># 生成器，输出(单词，出现次数的键值对)</span>
</span></span><span class=line><span class=cl>    <span class=n>map_results</span> <span class=o>=</span> <span class=nb>map</span><span class=p>(</span><span class=n>map_word_count</span><span class=p>,</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>documents</span><span class=p>)),</span> <span class=n>documents</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>shuffle_results</span> <span class=o>=</span> <span class=n>shuffle_words</span><span class=p>(</span><span class=n>map_results</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>reduce_results</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=n>reduce_counts</span><span class=p>(</span><span class=n>word</span><span class=p>,</span> <span class=n>list_of_counts</span><span class=p>)</span> <span class=k>for</span> <span class=n>word</span><span class=p>,</span> <span class=n>list_of_counts</span> <span class=ow>in</span> <span class=n>shuffle_results</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>end</span> <span class=o>=</span> <span class=n>timeit</span><span class=o>.</span><span class=n>default_timer</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>reduce_results</span><span class=p>[:</span><span class=mi>5</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>reduce_results</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;----------&#34;</span><span class=p>,</span> <span class=nb>str</span><span class=p>(</span><span class=n>end</span> <span class=o>-</span> <span class=n>start</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>pydev debugger: process 7540 is connecting
[('From:', 11536), ('lerxst@wam.umd.edu', 2), (&quot;(where's&quot;, 3), ('my', 7679), ('thing)', 9)]
280308
---------- 4.087287616999674
</code></pre><hr><p>接下来导入 joblib 库，将 map 工作分配出去，使用 4 个进程进行计算</p><p>Input:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>map_word_count</span><span class=p>(</span><span class=n>document_id</span><span class=p>,</span> <span class=n>document</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>counts</span> <span class=o>=</span> <span class=n>defaultdict</span><span class=p>(</span><span class=nb>int</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>document</span><span class=o>.</span><span class=n>split</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>counts</span><span class=p>[</span><span class=n>word</span><span class=p>]</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=nb>list</span><span class=p>(</span><span class=n>counts</span><span class=o>.</span><span class=n>items</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>start</span> <span class=o>=</span> <span class=n>timeit</span><span class=o>.</span><span class=n>default_timer</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>map_results</span> <span class=o>=</span> <span class=n>Parallel</span><span class=p>(</span><span class=n>n_jobs</span><span class=o>=</span><span class=mi>4</span><span class=p>)(</span>
</span></span><span class=line><span class=cl>        <span class=n>delayed</span><span class=p>(</span><span class=n>map_word_count</span><span class=p>)(</span><span class=n>i</span><span class=p>,</span> <span class=n>document</span><span class=p>)</span> <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>document</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>documents</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>shuffle_results</span> <span class=o>=</span> <span class=n>shuffle_words</span><span class=p>(</span><span class=n>map_results</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>reduce_results</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=n>reduce_counts</span><span class=p>(</span><span class=n>word</span><span class=p>,</span> <span class=n>list_of_counts</span><span class=p>)</span> <span class=k>for</span> <span class=n>word</span><span class=p>,</span> <span class=n>list_of_counts</span> <span class=ow>in</span> <span class=n>shuffle_results</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>end</span> <span class=o>=</span> <span class=n>timeit</span><span class=o>.</span><span class=n>default_timer</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>reduce_results</span><span class=p>[:</span><span class=mi>5</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>reduce_results</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;----------&#34;</span><span class=p>,</span> <span class=nb>str</span><span class=p>(</span><span class=n>end</span> <span class=o>-</span> <span class=n>start</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><pre><code>pydev debugger: process 7566 is connecting
pydev debugger: process 7556 is connecting
pydev debugger: process 7552 is connecting
pydev debugger: process 7561 is connecting
[('From:', 11536), ('lerxst@wam.umd.edu', 2), (&quot;(where's&quot;, 3), ('my', 7679), ('thing)', 9)]
280308
---------- 3.5958340090001
</code></pre><p>可以看到运行时间确实减少了（数据集太少了效果不怎么样）</p><h3 id=mapreduce-应用>MapReduce 应用</h3><p>书中使用 blogs 的数据集，有 19320 个人的 blog 信息</p><p>手头上的电脑配置有点不行了，跑的属实费劲，就放在这了（其实是迫不及待想去做做 tensorflow 的练习了嘿嘿）</p><h2 id=接下来的方向>接下来的方向</h2><p>书中根据每一章的内容，都有更进一步的实践，我会选几个单独做一下练习</p><p>Done</p><h2 id=参考链接>参考链接</h2><ol><li><a href=https://docs.python.org/zh-cn/3.8/index.html target=_blank rel="noopener noreffer">python-3.8.2-doc</a></li><li><a href=https://pandas.pydata.org/docs/user_guide/index.html target=_blank rel="noopener noreffer">pandas-doc</a></li><li><a href=https://numpy.org/devdocs/ target=_blank rel="noopener noreffer">numpy-doc</a></li><li><a href=https://scikit-learn.org/stable/index.html target=_blank rel="noopener noreffer">scikit-learn</a></li><li><a href=https://tensorflow.google.cn/ target=_blank rel="noopener noreffer">tensorflow</a></li></ol></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>更新于 2022-03-30&nbsp;<a class=git-hash href=https://github.com/SaltFishPr/saltfishpr.github.io/commit/72f5f5d2fc16b3d20212d6fd89d5ffc6bdefe8e2 target=_blank title="commit by SaltFish(526191197@qq.com) 72f5f5d2fc16b3d20212d6fd89d5ffc6bdefe8e2: update tags and categories">
<i class="fas fa-hashtag fa-fw"></i>72f5f5d</a></span></div><div class=post-info-license></div></div><div class=post-info-line><div class=post-info-md><span><a class=link-to-markdown href=/posts/2020-03-09-data-mining/index.md target=_blank>阅读原始文档</a></span></div><div class=post-info-share><span><a href=javascript:void(0); title="分享到 Twitter" data-sharer=twitter data-url=https://saltfishpr.github.io/posts/2020-03-09-data-mining/ data-title=数据挖掘入门与实践 data-via=saltfishpr data-hashtags="python,data science"><i class="fab fa-twitter fa-fw"></i></a><a href=javascript:void(0); title="分享到 Facebook" data-sharer=facebook data-url=https://saltfishpr.github.io/posts/2020-03-09-data-mining/ data-hashtag=python><i class="fab fa-facebook-square fa-fw"></i></a><a href=javascript:void(0); title="分享到 Hacker News" data-sharer=hackernews data-url=https://saltfishpr.github.io/posts/2020-03-09-data-mining/ data-title=数据挖掘入门与实践><i class="fab fa-hacker-news fa-fw"></i></a><a href=javascript:void(0); title="分享到 微博" data-sharer=weibo data-url=https://saltfishpr.github.io/posts/2020-03-09-data-mining/ data-title=数据挖掘入门与实践><i class="fab fa-weibo fa-fw"></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/python/>python</a>,&nbsp;<a href=/tags/data-science/>data science</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>返回</a></span>&nbsp;|&nbsp;<span><a href=/>主页</a></span></section></div><div class=post-nav><a href=/posts/2020-03-06-python-encode/ class=prev rel=prev title="Python 字符串和编码"><i class="fas fa-angle-left fa-fw"></i>Python 字符串和编码</a>
<a href=/posts/2020-03-10-build-a-github-pages/ class=next rel=next title="Github Pages 个人博客搭建">Github Pages 个人博客搭建<i class="fas fa-angle-right fa-fw"></i></a></div></div><div id=comments><div id=gitalk class=comment></div><noscript>Please enable JavaScript to view the comments powered by <a href=https://github.com/gitalk/gitalk></a>Gitalk</a>.</noscript></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line>由 <a href=https://gohugo.io/ target=_blank rel="noopener noreffer" title="Hugo 0.96.0">Hugo</a> 强力驱动 | 主题 - <a href=https://github.com/dillonzq/LoveIt target=_blank rel="noopener noreffer" title="LoveIt 0.2.10"><i class="far fa-kiss-wink-heart fa-fw"></i> LoveIt</a></div><div class=footer-line><i class="far fa-copyright fa-fw"></i><span itemprop=copyrightYear>2019 - 2022</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=https://github.com/SaltFishPr target=_blank>SaltFish</a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title=回到顶部><i class="fas fa-arrow-up fa-fw"></i>
</a><a href=# id=view-comments class=fixed-button title=查看评论><i class="fas fa-comment fa-fw"></i></a></div><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.css><script type=text/javascript src=https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/smooth-scroll@16.1.3/dist/smooth-scroll.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/autocomplete.js@0.37.1/dist/autocomplete.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lunr@2.3.8/lunr.min.js></script><script type=text/javascript src=/lib/lunr/lunr.stemmer.support.min.e741f5c0c369709ed4d7eaf24714f9c9e8a4145b50fc3a0c04eade421d9c9220fc02fdf0e16811aebb09617ba9ed0884adcf49fb08aa16b472a7db3a8bb51d33.js integrity="sha512-50H1wMNpcJ7U1+ryRxT5yeikFFtQ/DoMBOreQh2ckiD8Av3w4WgRrrsJYXup7QiErc9J+wiqFrRyp9s6i7UdMw=="></script><script type=text/javascript src=/lib/lunr/lunr.zh.min.dff76b91492564a0b642919c23a0dbceff8f52abd7a1c784536184a7ebef985c2f826b573c4812a7eb4b7ee4283ecff8a49bc9341aa2c2c79c6fc3587b43878f.js integrity="sha512-3/drkUklZKC2QpGcI6Dbzv+PUqvXoceEU2GEp+vvmFwvgmtXPEgSp+tLfuQoPs/4pJvJNBqiwsecb8NYe0OHjw=="></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lazysizes@5.2.2/lazysizes.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/sharer.js@0.4.0/sharer.min.js></script><script type=text/javascript>window.config={code:{copyTitle:"复制到剪贴板",maxShownLines:10},comment:{gitalk:{admin:["SaltFishPr"],clientID:"60fcbf378ba98da93c38",clientSecret:"97006a937aa9fd569bd7f7c6f1dfa69e39c45a2a",id:"2020-03-09T00:00:00+08:00",owner:"SaltFishPr",repo:"saltfishpr.github.io",title:"数据挖掘入门与实践"}},search:{highlightTag:"em",lunrIndexURL:"/index.json",lunrLanguageCode:"zh",lunrSegmentitURL:"/lib/lunr/lunr.segmentit.js",maxResultLength:10,noResultsFound:"没有找到结果",snippetLength:50,type:"lunr"}}</script><script type=text/javascript src=/js/theme.min.69ac882c686e101963f9cd3dc6167cee800004e4e9f40dae6f6fbeb3b03fb81ead782f98cc6e6eeec42b70a1b7047c7902e8f0ba3171660e2c2dc59d62965c7a.js integrity="sha512-aayILGhuEBlj+c09xhZ87oAABOTp9A2ub2++s7A/uB6teC+YzG5u7sQrcKG3BHx5AujwujFxZg4sLcWdYpZceg=="></script></body></html>